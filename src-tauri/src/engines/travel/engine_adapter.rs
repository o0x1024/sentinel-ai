//! Travelå¼•æ“é€‚é…å™¨
//!
//! å®ç°BaseExecutionEngine trait,å¯¹æ¥AIæœåŠ¡ã€å·¥å…·è°ƒç”¨ç­‰
//! æ”¯æŒå¤šæ¨¡å¼æ‰§è¡Œ:
//! - ç²¾ç®€DAGæ¨¡å¼ (Tokenä¼˜åŒ–)
//! - å®Œæ•´OODAæ¨¡å¼
//! - æµå¼DAGæ¨¡å¼ (è¾¹è§„åˆ’è¾¹æ‰§è¡Œ) [v3.0]
//! - è‡ªé€‚åº”é‡è§„åˆ’æ¨¡å¼ [v3.0]

use super::types::*;
use super::complexity_analyzer::ComplexityAnalyzer;
use super::ooda_executor::OodaExecutor;
use super::engine_dispatcher::EngineDispatcher;
use super::dag_planner::DagPlanner;
use super::parallel_executor::ParallelExecutor;
use super::context_manager::ContextManager;
use super::resource_integration::ResourceTracker;
use super::vision_integration::{VisionIntegration, VisionIntegrationConfig};
use super::memory_integration::TravelMemoryIntegration;
// v3.0 å¢å¼ºæ¨¡å—
use super::streaming_executor::{StreamingDagExecutor, StreamingExecutorConfig};
use super::replanning_engine::{ReplanningEngine, ReplanningConfig, TaskExecutionSummary};
use super::autonomous_observe::{AutonomousObserver};
use crate::engines::memory::get_global_memory;
use crate::agents::traits::{
    AgentExecutionResult, AgentSession, AgentTask, PerformanceCharacteristics,
};
use crate::engines::traits::BaseExecutionEngine;
use crate::services::ai::AiService;
use crate::services::mcp::McpService;
use crate::utils::ordered_message::{emit_message_chunk_arc, ArchitectureType, ChunkType};
use crate::utils::message_emitter::StandardMessageEmitter;
use anyhow::Result;
use async_trait::async_trait;
use std::collections::HashMap;
use std::sync::Arc;
use std::time::Instant;
use uuid::Uuid;

/// Travelå¼•æ“
pub struct TravelEngine {
    config: TravelConfig,
    complexity_analyzer: ComplexityAnalyzer,
    ooda_executor: OodaExecutor,
    ai_service: Option<Arc<AiService>>,
    prompt_repo: Option<Arc<crate::services::prompt_db::PromptRepository>>,
    framework_adapter: Option<Arc<dyn crate::tools::FrameworkToolAdapter>>,
    app_handle: Option<tauri::AppHandle>,
    /// ä¸Šä¸‹æ–‡ç®¡ç†å™¨ (Tokenä¼˜åŒ–)
    context_manager: ContextManager,
    /// èµ„æºè¿½è¸ªå™¨
    resource_tracker: ResourceTracker,
    /// MCP æœåŠ¡ (ç”¨äº VisionExplorer)
    mcp_service: Option<Arc<McpService>>,
    /// Vision Explorer é›†æˆ
    vision_integration: Option<Arc<VisionIntegration>>,
    /// è¢«åŠ¨æ‰«æçŠ¶æ€ (ç”¨äº VisionExplorer å¯åŠ¨ä»£ç†)
    passive_scan_state: Option<Arc<crate::commands::passive_scan_commands::PassiveScanState>>,
    /// è¢«åŠ¨æ‰«ææ•°æ®åº“æœåŠ¡ (ç”¨äº VisionExplorer è·å–ä»£ç†è¯·æ±‚)
    passive_db: Option<Arc<sentinel_passive::PassiveDatabaseService>>,
}

impl TravelEngine {
    /// åˆ›å»ºæ–°çš„Travelå¼•æ“
    pub fn new(config: TravelConfig) -> Self {
        let complexity_analyzer = ComplexityAnalyzer::new(config.complexity_config.clone());
        
        // è·å–å…¨å±€è®°å¿†å®ä¾‹å¹¶åˆ›å»º TravelMemoryIntegration
        let global_memory = get_global_memory();
        let memory_integration = TravelMemoryIntegration::new(global_memory);
        
        // åˆ›å»º OodaExecutor å¹¶æ³¨å…¥è®°å¿†é›†æˆ
        let ooda_executor = OodaExecutor::new(config.clone())
            .with_memory_integration(memory_integration);
        
        let context_manager = ContextManager::new(config.context_config.clone());
        let resource_tracker = ResourceTracker::new()
            .with_auto_cleanup(config.parallel_config.enable_resource_tracking);

        log::info!("TravelEngine initialized with memory integration enabled");

        Self {
            config,
            complexity_analyzer,
            ooda_executor,
            ai_service: None,
            prompt_repo: None,
            framework_adapter: None,
            app_handle: None,
            context_manager,
            resource_tracker,
            mcp_service: None,
            vision_integration: None,
            passive_scan_state: None,
            passive_db: None,
        }
    }

    /// ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»º
    pub fn with_defaults() -> Self {
        Self::new(TravelConfig::default())
    }
    
    /// åˆ¤æ–­æ˜¯å¦åº”ä½¿ç”¨ç²¾ç®€DAGæ¨¡å¼
    fn should_use_lite_mode(&self, complexity: &TaskComplexity) -> bool {
        if !self.config.lite_mode.enabled {
            return false;
        }
        self.config.lite_mode.applicable_complexity.contains(complexity)
    }
    
    /// åˆ¤æ–­æ˜¯å¦åº”ä½¿ç”¨æµå¼æ‰§è¡Œæ¨¡å¼
    fn should_use_streaming_mode(&self, task: &AgentTask) -> bool {
        // å¦‚æœä»»åŠ¡å‚æ•°ä¸­æ˜ç¡®æŒ‡å®šä½¿ç”¨æµå¼æ¨¡å¼
        if let Some(mode) = task.parameters.get("execution_mode").and_then(|v| v.as_str()) {
            return mode == "streaming" || mode == "streaming_dag";
        }
        // å¦‚æœé…ç½®ä¸­å¯ç”¨äº†æµå¼æ¨¡å¼ä¸”ä»»åŠ¡å¯èƒ½éœ€è¦é‡è§„åˆ’
        task.parameters.get("enable_replan").and_then(|v| v.as_bool()).unwrap_or(false)
    }
    
    /// åˆ¤æ–­æ˜¯å¦åº”ä½¿ç”¨è‡ªé€‚åº”é‡è§„åˆ’æ¨¡å¼
    fn should_use_adaptive_replan(&self, task: &AgentTask, complexity: &TaskComplexity) -> bool {
        // å¤æ‚ä»»åŠ¡é»˜è®¤å¯ç”¨è‡ªé€‚åº”é‡è§„åˆ’
        if matches!(complexity, TaskComplexity::Complex) {
            return true;
        }
        // æˆ–è€…ä»»åŠ¡å‚æ•°ä¸­æ˜ç¡®æŒ‡å®š
        task.parameters.get("adaptive_replan").and_then(|v| v.as_bool()).unwrap_or(false)
    }

    /// å‘é€æ¶ˆæ¯åˆ°å‰ç«¯
    fn emit_message(
        &self,
        execution_id: &str,
        message_id: &str,
        conversation_id: Option<&str>,
        chunk_type: ChunkType,
        content: &str,
        structured_data: Option<serde_json::Value>,
    ) {
        if let Some(app_handle) = &self.app_handle {
            emit_message_chunk_arc(
                &Arc::new(app_handle.clone()),
                execution_id,
                message_id,
                conversation_id,
                chunk_type,
                content,
                false,
                Some("TravelEngine"),
                None,
                Some(ArchitectureType::Travel),
                structured_data,
            );
        }
    }

    /// è®¾ç½®AIæœåŠ¡
    pub fn with_ai_service(mut self, ai_service: Arc<AiService>) -> Self {
        self.complexity_analyzer = self.complexity_analyzer.with_ai_service(ai_service.clone());
        self.ai_service = Some(ai_service);
        self.update_engine_dispatcher();
        self.update_vision_integration();
        self
    }
    
    /// è®¾ç½® PromptRepository
    pub fn with_prompt_repo(mut self, repo: Arc<crate::services::prompt_db::PromptRepository>) -> Self {
        log::info!("TravelEngine: Setting prompt repository");
        self.prompt_repo = Some(repo);
        self.update_engine_dispatcher();
        self
    }
    
    /// è®¾ç½® FrameworkToolAdapter
    pub fn with_framework_adapter(mut self, adapter: Arc<dyn crate::tools::FrameworkToolAdapter>) -> Self {
        self.framework_adapter = Some(adapter);
        self.update_engine_dispatcher();
        self
    }
    
    /// è®¾ç½® AppHandle
    pub fn with_app_handle(mut self, app: tauri::AppHandle) -> Self {
        self.app_handle = Some(app);
        self.update_engine_dispatcher();
        self.update_vision_integration();  // ç¡®ä¿ VisionIntegration è·å¾— AppHandle
        self
    }
    
    /// è®¾ç½® MCP æœåŠ¡ (ç”¨äº VisionExplorer)
    pub fn with_mcp_service(mut self, mcp_service: Arc<McpService>) -> Self {
        self.mcp_service = Some(mcp_service);
        self.update_vision_integration();
        self
    }

    /// è®¾ç½®è¢«åŠ¨æ‰«æçŠ¶æ€ (ç”¨äº VisionExplorer å¯åŠ¨ä»£ç†)
    pub fn with_passive_scan_state(mut self, state: Arc<crate::commands::passive_scan_commands::PassiveScanState>) -> Self {
        self.passive_scan_state = Some(state);
        self.update_vision_integration();
        self
    }

    /// è®¾ç½®è¢«åŠ¨æ‰«ææ•°æ®åº“æœåŠ¡ (ç”¨äº VisionExplorer è·å–ä»£ç†è¯·æ±‚)
    pub fn with_passive_db(mut self, db: Arc<sentinel_passive::PassiveDatabaseService>) -> Self {
        self.passive_db = Some(db);
        self.update_vision_integration();
        self
    }
    
    /// æ›´æ–° VisionIntegration
    fn update_vision_integration(&mut self) {
        // éœ€è¦ AI æœåŠ¡å’Œ MCP æœåŠ¡æ‰èƒ½åˆ›å»º VisionIntegration
        if let (Some(ai_service), Some(mcp_service)) = (&self.ai_service, &self.mcp_service) {
            let config = ai_service.get_config();
            let vision_config = VisionIntegrationConfig {
                enabled: true,
                max_iterations: 30,
                timeout_secs: 180,
                auto_start: false,
                inject_to_threat_intel: true,
                auto_observe: true,
                viewport_width: 1920,
                viewport_height: 1080,
                // ä» TravelConfig è¯»å–å¤šæ¨¡æ€é…ç½®
                enable_multimodal: self.config.enable_multimodal,
                // æ¶ˆæ¯å‚æ•°ä¼šåœ¨è¿è¡Œæ—¶é€šè¿‡ set_message_info åŠ¨æ€è®¾ç½®
                execution_id: None,
                message_id: None,
                conversation_id: None,
            };
            
            let mut vision = VisionIntegration::new(
                vision_config,
                Some(mcp_service.clone()),
                config.provider.clone(),
                config.model.clone(),
            );
            
            // ä¼ å…¥ä»£ç†å¯åŠ¨ä¾èµ–
            if let Some(app) = &self.app_handle {
                vision = vision.with_app_handle(app.clone());
            }
            if let Some(state) = &self.passive_scan_state {
                vision = vision.with_passive_scan_state(state.clone());
            }
            // ä¼ å…¥è¢«åŠ¨æ‰«ææ•°æ®åº“æœåŠ¡ï¼ˆç”¨äºè·å–ä»£ç†æ•è·çš„æµé‡ï¼‰
            if let Some(db) = &self.passive_db {
                vision = vision.with_passive_db(db.clone());
            }
            
            self.vision_integration = Some(Arc::new(vision));
            log::info!("TravelEngine: VisionIntegration initialized with MCP service");
        } else if self.ai_service.is_some() && self.mcp_service.is_none() {
            log::debug!("TravelEngine: Waiting for MCP service to initialize VisionIntegration");
        }
    }
    
    /// æ›´æ–° engine_dispatcher çš„ä¾èµ–
    fn update_engine_dispatcher(&mut self) {
        let mut dispatcher = EngineDispatcher::new();
        
        if let Some(ai_service) = &self.ai_service {
            dispatcher = dispatcher.with_ai_service(ai_service.clone());
        }
        
        if let Some(repo) = &self.prompt_repo {
            log::info!("TravelEngine: Passing prompt_repo to engine_dispatcher");
            dispatcher = dispatcher.with_prompt_repo(repo.clone());
        } else {
            log::warn!("TravelEngine: No prompt_repo available to pass to engine_dispatcher");
        }
        
        if let Some(adapter) = &self.framework_adapter {
            dispatcher = dispatcher.with_framework_adapter(adapter.clone());
        }
        
        if let Some(app) = &self.app_handle {
            dispatcher = dispatcher.with_app_handle(app.clone());
        }
        
        // ä½¿ç”¨ std::mem::replace æ¥é¿å…ç§»åŠ¨é—®é¢˜
        let old_executor = std::mem::replace(&mut self.ooda_executor, OodaExecutor::new(self.config.clone()));
        self.ooda_executor = old_executor.with_engine_dispatcher(dispatcher);
    }

    /// æ‰§è¡ŒTravelæµç¨‹ (æ”¯æŒåŒæ¨¡å¼)
    pub async fn execute(
        &self,
        task: &AgentTask,
        _session: &mut dyn AgentSession,
    ) -> Result<AgentExecutionResult> {
        log::info!("Travel engine executing task: {}", task.description);
        let start_time = Instant::now();

        // 1. åˆ†æä»»åŠ¡å¤æ‚åº¦
        let task_complexity = self
            .complexity_analyzer
            .analyze_task_complexity(&task.description, Some(&task.parameters))
            .await?;

        log::info!("Task complexity determined: {:?}", task_complexity);

        // 2. å‡†å¤‡æ‰§è¡Œä¸Šä¸‹æ–‡
        let mut context = self.prepare_context(task)?;

        // 3. æå–æ¶ˆæ¯ç›¸å…³çš„ID
        let execution_id = task.parameters.get("execution_id")
            .and_then(|v| v.as_str())
            .map(|s| s.to_string())
            .unwrap_or_else(|| Uuid::new_v4().to_string());
        
        let message_id = task.parameters.get("message_id")
            .and_then(|v| v.as_str())
            .map(|s| s.to_string())
            .unwrap_or_else(|| Uuid::new_v4().to_string());
        
        let conversation_id = task.parameters.get("conversation_id")
            .and_then(|v| v.as_str())
            .map(|s| s.to_string());

        // 4. æ¸…ç†ä¹‹å‰çš„èµ„æºè¿½è¸ª
        self.resource_tracker.clear_all().await;

        // 5. æ ¹æ®å¤æ‚åº¦å’Œé…ç½®é€‰æ‹©æ‰§è¡Œæ¨¡å¼
        let result = if self.should_use_streaming_mode(task) {
            // æµå¼æ‰§è¡Œæ¨¡å¼ - è¾¹è§„åˆ’è¾¹æ‰§è¡Œï¼Œæ”¯æŒå®æ—¶é‡è§„åˆ’
            log::info!("Travel: Using STREAMING DAG mode with replanning");
            self.emit_message(
                &execution_id,
                &message_id,
                conversation_id.as_deref(),
                ChunkType::Thinking,
                "[MODE] ä½¿ç”¨æµå¼DAGæ‰§è¡Œæ¨¡å¼ (æ”¯æŒåŠ¨æ€é‡è§„åˆ’)",
                Some(serde_json::json!({
                    "mode": "streaming_dag",
                    "complexity": format!("{:?}", task_complexity),
                    "features": ["streaming", "replanning", "parallel"]
                })),
            );
            
            self.execute_streaming_mode(task, &mut context, &execution_id, &message_id, conversation_id.as_deref()).await
        } else if self.should_use_lite_mode(&task_complexity) {
            // ä¼˜åŒ–åçš„ DAG æ¨¡å¼
            let use_adaptive = self.should_use_adaptive_replan(task, &task_complexity);
            log::info!("Travel: Using LITE DAG mode (adaptive_replan={})", use_adaptive);
            self.emit_message(
                &execution_id,
                &message_id,
                conversation_id.as_deref(),
                ChunkType::Thinking,
                &format!("[MODE] ä½¿ç”¨ä¼˜åŒ–åçš„DAGæ‰§è¡Œæ¨¡å¼{}", 
                    if use_adaptive { " (å¯ç”¨è‡ªé€‚åº”é‡è§„åˆ’)" } else { "" }),
                Some(serde_json::json!({
                    "mode": "lite_dag",
                    "complexity": format!("{:?}", task_complexity),
                    "adaptive_replan": use_adaptive
                })),
            );
            
            if use_adaptive {
                self.execute_lite_mode_with_replan(task, &mut context, &execution_id, &message_id, conversation_id.as_deref()).await
            } else {
                self.execute_lite_mode(task, &mut context, &execution_id, &message_id, conversation_id.as_deref()).await
            }
        } else {
            log::info!("Travel: Using FULL OODA mode for complex task");
            self.emit_message(
                &execution_id,
                &message_id,
                conversation_id.as_deref(),
                ChunkType::Thinking,
                "[MODE] ä½¿ç”¨å®Œæ•´çš„OODAæ‰§è¡Œæ¨¡å¼",
                Some(serde_json::json!({
                    "mode": "full_ooda",
                    "complexity": format!("{:?}", task_complexity)
                })),
            );
            
            self.execute_full_ooda_mode(task, task_complexity, &mut context, &execution_id, &message_id, conversation_id.clone()).await
        };

        // 6. æ¸…ç†èµ„æº
        if self.resource_tracker.has_resource_leak().await {
            log::warn!("Travel: Detected resource leaks, attempting cleanup");
            if let Some(adapter) = &self.framework_adapter {
                match self.resource_tracker.execute_cleanup(adapter).await {
                    Ok(report) => {
                        if report.has_leaks {
                            log::warn!("Travel: Some resources could not be cleaned: {:?}", report.leaked_resources);
                        } else {
                            log::info!("Travel: All resources cleaned successfully");
                        }
                    }
                    Err(e) => {
                        log::error!("Travel: Resource cleanup failed: {}", e);
                    }
                }
            }
        }

        let duration = start_time.elapsed().as_millis() as u64;
        log::info!("Travel: Task completed in {}ms", duration);

        result
    }

    /// ç²¾ç®€DAGæ¨¡å¼æ‰§è¡Œ (Tokenä¼˜åŒ–)
    async fn execute_lite_mode(
        &self,
        task: &AgentTask,
        context: &mut HashMap<String, serde_json::Value>,
        execution_id: &str,
        message_id: &str,
        conversation_id: Option<&str>,
    ) -> Result<AgentExecutionResult> {
        let start_time = Instant::now();
        
        // ã€é‡è¦ã€‘å¯¹äº Web ä»»åŠ¡ï¼Œå…ˆæ£€æŸ¥æ˜¯å¦éœ€è¦ VisionExplorer å‰ç½®æ¢ç´¢
        // æ³¨æ„ï¼šå…ˆå…‹éš† target å’Œ task_typeï¼Œé¿å…å€Ÿç”¨å†²çª
        let target = context.get("target")
            .and_then(|v| v.as_str())
            .unwrap_or("")
            .to_string();
        let task_type = context.get("task_type")
            .and_then(|v| v.as_str())
            .unwrap_or("")
            .to_string();
        
        // åˆ¤æ–­æ˜¯å¦éœ€è¦å‰ç½®è§†è§‰æ¢ç´¢
        let needs_vision_exploration = self.should_use_vision_exploration(&target, &task_type, context).await;
        
        if needs_vision_exploration {
            log::info!("Travel Lite: Target requires VisionExplorer pre-exploration");
            self.emit_message(
                execution_id,
                message_id,
                conversation_id,
                ChunkType::Thinking,
                "[VISION] ç›®æ ‡æ²¡æœ‰æ•è·æµé‡, å¼€å§‹è§†è§‰æ¢ç´¢...",
                None,
            );
            
            // æ‰§è¡Œè§†è§‰æ¢ç´¢
            if let Err(e) = self.execute_vision_exploration(&target, execution_id, message_id, conversation_id, context).await {
                log::warn!("è§†è§‰æ¢ç´¢å¤±è´¥: {}, å°†ç»§ç»­ä½¿ç”¨DAGè®¡åˆ’", e);
                self.emit_message(
                    execution_id,
                    message_id,
                    conversation_id,
                    ChunkType::Content,
                    &format!("[WARNING] è§†è§‰æ¢ç´¢è·³è¿‡: {}", e),
                    None,
                );
            }
        }
        
        // æ£€æŸ¥ç¼“å­˜
        let task_hash = ContextManager::generate_task_hash(&task.description, context);
        if let Some(cached_plan) = self.context_manager.get_cached_plan(&task_hash).await {
            log::info!("Travel Lite: Using cached plan");
            self.emit_message(
                execution_id,
                message_id,
                conversation_id,
                ChunkType::Content,
                "ğŸ“¦ ä½¿ç”¨ç¼“å­˜çš„æ‰§è¡Œè®¡åˆ’",
                None,
            );
            
            return self.execute_dag_plan(cached_plan, context, execution_id, message_id, conversation_id).await;
        }

        // éœ€è¦ AI æœåŠ¡æ¥ç”Ÿæˆ DAG è®¡åˆ’
        let ai_service = self.ai_service.as_ref()
            .ok_or_else(|| anyhow::anyhow!("AI service required for DAG planning"))?;

        // åˆ›å»º DAG è§„åˆ’å™¨
        let mut planner = DagPlanner::new(ai_service.clone(), self.config.lite_mode.clone());
        
        if let Some(adapter) = &self.framework_adapter {
            planner = planner.with_tool_adapter(adapter.clone());
        }
        if let Some(repo) = &self.prompt_repo {
            planner = planner.with_prompt_repo(repo.clone());
        }

        self.emit_message(
            execution_id,
            message_id,
            conversation_id,
            ChunkType::Thinking,
            "[PLANNING] ç”ŸæˆDAGæ‰§è¡Œè®¡åˆ’...",
            None,
        );

        // ç”Ÿæˆ DAG è®¡åˆ’ (å•æ¬¡ LLM è°ƒç”¨)
        let plan = planner.generate_plan(&task.description, context).await?;

        self.emit_message(
            execution_id,
            message_id,
            conversation_id,
            ChunkType::PlanInfo,
            &format!("[SUCCESS] è®¡åˆ’ç”Ÿæˆå®Œæˆ, åŒ…å« {} ä¸ªä»»åŠ¡", plan.tasks.len()),
            Some(serde_json::json!({
                "task_count": plan.tasks.len(),
                "tasks": plan.tasks.iter().map(|t| &t.tool_name).collect::<Vec<_>>()
            })),
        );

        // ç¼“å­˜è®¡åˆ’
        if self.config.lite_mode.enable_plan_cache {
            self.context_manager.cache_plan(
                &task_hash,
                plan.clone(),
                self.config.lite_mode.plan_cache_ttl,
            ).await;
        }

        self.execute_dag_plan(plan, context, execution_id, message_id, conversation_id).await
    }

    /// åˆ¤æ–­æ˜¯å¦éœ€è¦è§†è§‰æ¢ç´¢å‰ç½®
    /// 
    /// æ¡ä»¶ï¼š
    /// 1. ç›®æ ‡æ˜¯ Web URL (http/https)
    /// 2. ä»»åŠ¡ç±»å‹æ˜¯ web_pentest æˆ– api_pentest
    /// 3. æ•°æ®åº“ä¸­æ²¡æœ‰è¯¥åŸŸåçš„è¯·æ±‚è®°å½•
    /// 4. VisionExplorer å¯ç”¨ (Playwright MCP å·²è¿æ¥)
    async fn should_use_vision_exploration(
        &self,
        target: &str,
        task_type: &str,
        context: &HashMap<String, serde_json::Value>,
    ) -> bool {
        // 1. æ£€æŸ¥æ˜¯å¦æ˜¯ Web URL
        if !target.starts_with("http://") && !target.starts_with("https://") {
            return false;
        }
        
        // 2. æ£€æŸ¥ä»»åŠ¡ç±»å‹
        let web_task_types = ["web_pentest", "api_pentest", "web_recon", "api_discovery"];
        if !web_task_types.contains(&task_type) {
            return false;
        }
        
        // 3. æ£€æŸ¥ VisionExplorer æ˜¯å¦å¯ç”¨
        let vision_available = if let Some(vision) = &self.vision_integration {
            vision.is_playwright_available().await
        } else {
            false
        };
        
        if !vision_available {
            log::debug!("Vision exploration not available: Playwright MCP not connected");
            return false;
        }
        
        // 4. æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²æœ‰è¯·æ±‚è®°å½•
        if let Some(db) = &self.passive_db {
            let domain = target
                .trim_start_matches("http://")
                .trim_start_matches("https://")
                .split('/')
                .next()
                .unwrap_or(target)
                .split(':')
                .next()
                .unwrap_or(target);
            
            match db.list_proxy_requests_by_host(domain, 1).await {
                Ok(requests) => {
                    if requests.is_empty() {
                        log::info!("No existing requests for domain {}, vision exploration needed", domain);
                        return true;
                    } else {
                        log::info!("Found existing requests for domain {}, skipping vision exploration", domain);
                        return false;
                    }
                }
                Err(e) => {
                    log::warn!("Failed to check existing requests: {}, assuming vision exploration needed", e);
                    return true;
                }
            }
        }
        
        // å¦‚æœæ²¡æœ‰ passive_dbï¼Œé»˜è®¤éœ€è¦è§†è§‰æ¢ç´¢
        true
    }
    
    /// æ‰§è¡Œè§†è§‰æ¢ç´¢å‰ç½®ä»»åŠ¡
    async fn execute_vision_exploration(
        &self,
        target: &str,
        execution_id: &str,
        message_id: &str,
        conversation_id: Option<&str>,
        context: &mut HashMap<String, serde_json::Value>,
    ) -> Result<()> {
        let vision = self.vision_integration.as_ref()
            .ok_or_else(|| anyhow::anyhow!("VisionIntegration not available"))?;
        
        // è®¾ç½®æ¶ˆæ¯å‚æ•°
        vision.set_message_info(execution_id, message_id, conversation_id).await;
        
        // å¦‚æœæœ‰å–æ¶ˆä»¤ç‰Œï¼Œä¼ é€’ç»™ VisionExplorer
        if let Some(token) = crate::managers::cancellation_manager::get_token(execution_id).await {
            vision.set_cancellation_token(token).await;
        }
        
        self.emit_message(
            execution_id,
            message_id,
            conversation_id,
            ChunkType::Thinking,
            "[VISION] å¼€å§‹VLMé©±åŠ¨çš„ç½‘ç«™æ¢ç´¢...",
            Some(serde_json::json!({
                "target": target,
                "phase": "pre_exploration"
            })),
        );
        
        // æ‰§è¡Œè§†è§‰æ¢ç´¢
        let recon_result = vision.enhance_observe_phase(target).await?;
        
        log::info!(
            "è§†è§‰æ¢ç´¢å®Œæˆ: {} API, {} è¡¨å•å‘ç°",
            recon_result.api_endpoints.len(),
            recon_result.forms.len()
        );
        
        // æ³¨å…¥æ¢ç´¢ç»“æœåˆ°ä¸Šä¸‹æ–‡
        context.insert(
            "vision_exploration_result".to_string(),
            serde_json::to_value(&recon_result).unwrap_or(serde_json::json!({})),
        );
        context.insert(
            "vision_api_count".to_string(),
            serde_json::json!(recon_result.api_endpoints.len()),
        );
        context.insert(
            "vision_form_count".to_string(),
            serde_json::json!(recon_result.forms.len()),
        );
        
        self.emit_message(
            execution_id,
            message_id,
            conversation_id,
            ChunkType::Content,
            &format!(
                "âœ… è§†è§‰æ¢ç´¢å®Œæˆ: {} API, {} è¡¨å•, è¦†ç›–ç‡: {:.1}%",
                recon_result.api_endpoints.len(),
                recon_result.forms.len(),
                recon_result.coverage * 100.0
            ),
            Some(serde_json::json!({
                "apis_discovered": recon_result.api_endpoints.len(),
                "forms_discovered": recon_result.forms.len(),
                "coverage": recon_result.coverage,
                "attack_surface": recon_result.attack_surface
            })),
        );
        
        Ok(())
    }

    /// æ‰§è¡Œ DAG è®¡åˆ’
    async fn execute_dag_plan(
        &self,
        mut plan: DagPlan,
        context: &mut HashMap<String, serde_json::Value>,
        execution_id: &str,
        message_id: &str,
        conversation_id: Option<&str>,
    ) -> Result<AgentExecutionResult> {
        let start_time = Instant::now();

        // åˆ›å»ºå¹¶è¡Œæ‰§è¡Œå™¨
        let mut executor = ParallelExecutor::new(self.config.parallel_config.clone());
        
        if let Some(adapter) = &self.framework_adapter {
            executor = executor.with_tool_adapter(adapter.clone());
        }
        
        if let Some(app) = &self.app_handle {
            executor = executor.with_message_context(
                Arc::new(app.clone()),
                execution_id.to_string(),
                message_id.to_string(),
                conversation_id.map(|s| s.to_string()),
            );
        }

        // æ‰§è¡Œ DAG
        let result = executor.execute_dag(&mut plan).await?;

        let duration = start_time.elapsed().as_millis() as u64;

        // æ„å»ºç»“æœ
        let success = result.success;
        let output = result.final_output.clone().unwrap_or(serde_json::json!({}));

        self.emit_message(
            execution_id,
            message_id,
            conversation_id,
            ChunkType::Content,
            &format!(
                "ğŸ“Š DAG æ‰§è¡Œå®Œæˆ: {} æˆåŠŸ, {} å¤±è´¥ ({}ms èŠ‚çœ ~{} tokens)",
                result.metrics.completed_tasks,
                result.metrics.failed_tasks,
                duration,
                result.metrics.tokens_saved
            ),
            Some(serde_json::json!({
                "metrics": result.metrics
            })),
        );

        Ok(AgentExecutionResult {
            id: plan.id,
            success,
            data: Some(serde_json::json!({
                "output": output,
                "mode": "lite_dag",
                "metrics": result.metrics,
                "task_results": result.task_results,
            })),
            error: if success { None } else { Some("Some tasks failed".to_string()) },
            execution_time_ms: duration,
            resources_used: HashMap::new(),
            artifacts: Vec::new(),
        })
    }

    /// æµå¼DAGæ¨¡å¼æ‰§è¡Œ - è¾¹è§„åˆ’è¾¹æ‰§è¡Œï¼Œæ”¯æŒå®æ—¶é‡è§„åˆ’
    async fn execute_streaming_mode(
        &self,
        task: &AgentTask,
        context: &mut HashMap<String, serde_json::Value>,
        execution_id: &str,
        message_id: &str,
        conversation_id: Option<&str>,
    ) -> Result<AgentExecutionResult> {
        let start_time = Instant::now();
        
        let ai_service = self.ai_service.as_ref()
            .ok_or_else(|| anyhow::anyhow!("AI service not available"))?;
        
        // åˆ›å»ºæµå¼æ‰§è¡Œå™¨é…ç½®
        let streaming_config = StreamingExecutorConfig {
            max_concurrency: self.config.parallel_config.max_concurrency as usize,
            task_timeout: self.config.parallel_config.task_timeout,
            enable_streaming_plan: true,
            plan_batch_size: 3,
            max_replan_count: 5,
            condition_eval_timeout: 5000,
        };
        
        // åˆ›å»ºæµå¼æ‰§è¡Œå™¨
        let mut executor = StreamingDagExecutor::new(ai_service.clone(), streaming_config);
        
        if let Some(adapter) = &self.framework_adapter {
            executor = executor.with_tool_adapter(adapter.clone());
        }
        
        if let Some(app) = &self.app_handle {
            executor = executor.with_message_context(
                Arc::new(app.clone()),
                execution_id.to_string(),
                message_id.to_string(),
                conversation_id.map(|s| s.to_string()),
            );
        }
        
        // è·å–å–æ¶ˆä»¤ç‰Œ
        if let Some(token) = crate::managers::cancellation_manager::get_token(execution_id).await {
            executor = executor.with_cancellation_token(token);
        }
        
        // æ‰§è¡Œæµå¼ä»»åŠ¡
        let result = executor.execute_streaming(&task.description, context).await?;
        
        let duration = start_time.elapsed().as_millis() as u64;
        
        self.emit_message(
            execution_id,
            message_id,
            conversation_id,
            ChunkType::Content,
            &format!(
                "ğŸ“Š æµå¼æ‰§è¡Œå®Œæˆ: {} æˆåŠŸ, {} å¤±è´¥, {} æ¬¡é‡è§„åˆ’ ({}ms)",
                result.metrics.completed_tasks,
                result.metrics.failed_tasks,
                result.execution_snapshot.as_ref()
                    .map(|s| s.error_history.len())
                    .unwrap_or(0),
                duration
            ),
            Some(serde_json::json!({
                "metrics": result.metrics,
                "replan_count": result.execution_snapshot.as_ref()
                    .map(|s| s.attempted_approaches.len())
                    .unwrap_or(0)
            })),
        );
        
        Ok(AgentExecutionResult {
            id: result.plan_id,
            success: result.success,
            data: Some(serde_json::json!({
                "output": result.final_output,
                "mode": "streaming_dag",
                "metrics": result.metrics,
                "task_results": result.task_results,
            })),
            error: if result.success { None } else { Some("Some tasks failed".to_string()) },
            execution_time_ms: duration,
            resources_used: HashMap::new(),
            artifacts: Vec::new(),
        })
    }

    /// å¸¦è‡ªé€‚åº”é‡è§„åˆ’çš„ Lite DAG æ¨¡å¼
    async fn execute_lite_mode_with_replan(
        &self,
        task: &AgentTask,
        context: &mut HashMap<String, serde_json::Value>,
        execution_id: &str,
        message_id: &str,
        conversation_id: Option<&str>,
    ) -> Result<AgentExecutionResult> {
        let start_time = Instant::now();
        
        let ai_service = self.ai_service.as_ref()
            .ok_or_else(|| anyhow::anyhow!("AI service not available"))?;
        
        // å…ˆæ‰§è¡Œå‰ç½®æ¢ç´¢
        let target = context.get("target")
            .and_then(|v| v.as_str())
            .unwrap_or("")
            .to_string();
        let task_type = context.get("task_type")
            .and_then(|v| v.as_str())
            .unwrap_or("")
            .to_string();
        
        let needs_vision = self.should_use_vision_exploration(&target, &task_type, context).await;
        if needs_vision {
            let _ = self.execute_vision_exploration(&target, execution_id, message_id, conversation_id, context).await;
        }
        
        // ç”Ÿæˆåˆå§‹è®¡åˆ’
        let mut planner = DagPlanner::new(ai_service.clone(), self.config.lite_mode.clone());
        if let Some(repo) = &self.prompt_repo {
            planner = planner.with_prompt_repo(repo.clone());
        }
        if let Some(adapter) = &self.framework_adapter {
            planner = planner.with_tool_adapter(adapter.clone());
        }
        
        let mut plan = planner.generate_plan(&task.description, context).await?;
        
        // åˆ›å»ºé‡è§„åˆ’å¼•æ“
        let replan_config = ReplanningConfig::default();
        let mut replan_engine = ReplanningEngine::new(ai_service.clone(), replan_config);
        if let Some(repo) = &self.prompt_repo {
            replan_engine = replan_engine.with_prompt_repo(repo.clone());
        }
        if let Some(adapter) = &self.framework_adapter {
            replan_engine = replan_engine.with_tool_adapter(adapter.clone());
        }
        
        // åˆ›å»ºæ‰§è¡Œå¿«ç…§
        let mut snapshot = ExecutionSnapshot::default();
        let mut task_summaries: Vec<TaskExecutionSummary> = Vec::new();
        let mut total_replan_count = 0u32;
        let max_replans = 5u32;
        
        loop {
            // æ‰§è¡Œå½“å‰è®¡åˆ’
            self.emit_message(
                execution_id,
                message_id,
                conversation_id,
                ChunkType::PlanInfo,
                &format!("[PLAN v{}] æ‰§è¡Œè®¡åˆ’: {} ä¸ªä»»åŠ¡", total_replan_count + 1, plan.tasks.len()),
                None,
            );
            
            let result = self.execute_dag_plan_with_tracking(
                &mut plan,
                context,
                execution_id,
                message_id,
                conversation_id,
                &mut task_summaries,
                &mut snapshot,
            ).await?;
            
            // è¯„ä¼°æ˜¯å¦éœ€è¦é‡è§„åˆ’
            if result.success || total_replan_count >= max_replans {
                let duration = start_time.elapsed().as_millis() as u64;
                return Ok(AgentExecutionResult {
                    id: plan.id,
                    success: result.success,
                    data: Some(serde_json::json!({
                        "output": result.final_output,
                        "mode": "lite_dag_adaptive",
                        "metrics": result.metrics,
                        "replan_count": total_replan_count,
                    })),
                    error: if result.success { None } else { Some("Max replans reached".to_string()) },
                    execution_time_ms: duration,
                    resources_used: HashMap::new(),
                    artifacts: Vec::new(),
                });
            }
            
            // è¯„ä¼°é‡è§„åˆ’éœ€æ±‚
            let evaluation = replan_engine.evaluate_replan_need(&plan, &snapshot, &task_summaries).await?;
            
            if !evaluation.should_replan {
                let duration = start_time.elapsed().as_millis() as u64;
                return Ok(AgentExecutionResult {
                    id: plan.id,
                    success: result.success,
                    data: Some(serde_json::json!({
                        "output": result.final_output,
                        "mode": "lite_dag_adaptive",
                        "metrics": result.metrics,
                        "replan_count": total_replan_count,
                    })),
                    error: if result.success { None } else { Some("Tasks failed but no replan triggered".to_string()) },
                    execution_time_ms: duration,
                    resources_used: HashMap::new(),
                    artifacts: Vec::new(),
                });
            }
            
            // æ‰§è¡Œé‡è§„åˆ’
            self.emit_message(
                execution_id,
                message_id,
                conversation_id,
                ChunkType::Thinking,
                &format!("[REPLAN] è§¦å‘é‡è§„åˆ’: {:?}", evaluation.reason),
                Some(serde_json::json!({
                    "reason": format!("{:?}", evaluation.reason),
                    "progress_score": evaluation.progress_score,
                })),
            );
            
            plan = replan_engine.replan(&task.description, context, &snapshot, &evaluation).await?;
            total_replan_count += 1;
            
            self.emit_message(
                execution_id,
                message_id,
                conversation_id,
                ChunkType::PlanInfo,
                &format!("[REPLAN] æ–°è®¡åˆ’ç”Ÿæˆ: {} ä¸ªä»»åŠ¡", plan.tasks.len()),
                None,
            );
        }
    }

    /// æ‰§è¡Œ DAG è®¡åˆ’å¹¶è·Ÿè¸ªçŠ¶æ€ (ç”¨äºé‡è§„åˆ’)
    async fn execute_dag_plan_with_tracking(
        &self,
        plan: &mut DagPlan,
        context: &mut HashMap<String, serde_json::Value>,
        execution_id: &str,
        message_id: &str,
        conversation_id: Option<&str>,
        task_summaries: &mut Vec<TaskExecutionSummary>,
        snapshot: &mut ExecutionSnapshot,
    ) -> Result<DagExecutionResult> {
        let start_time = Instant::now();
        
        let mut executor = ParallelExecutor::new(self.config.parallel_config.clone());
        
        if let Some(adapter) = &self.framework_adapter {
            executor = executor.with_tool_adapter(adapter.clone());
        }
        
        if let Some(app) = &self.app_handle {
            executor = executor.with_message_context(
                Arc::new(app.clone()),
                execution_id.to_string(),
                message_id.to_string(),
                conversation_id.map(|s| s.to_string()),
            );
        }
        
        let result = executor.execute_dag(plan).await?;
        
        // æ›´æ–°ä»»åŠ¡æ‘˜è¦
        for (task_id, task_result) in &result.task_results {
            let task = plan.tasks.iter().find(|t| t.id == *task_id);
            task_summaries.push(TaskExecutionSummary {
                task_id: task_id.clone(),
                tool_name: task.map(|t| t.tool_name.clone()).unwrap_or_default(),
                success: !result.failed_tasks.contains(task_id),
                duration_ms: 0,
                result_summary: Some(task_result.to_string().chars().take(200).collect()),
            });
        }
        
        // æ›´æ–°å¿«ç…§
        for (task_id, task_result) in &result.task_results {
            if !result.failed_tasks.contains(task_id) {
                snapshot.completed_tasks.insert(task_id.clone(), task_result.clone());
            }
        }
        
        for failed_id in &result.failed_tasks {
            if let Some(task) = plan.tasks.iter().find(|t| t.id == *failed_id) {
                snapshot.error_history.push(ErrorRecord {
                    task_id: failed_id.clone(),
                    tool_name: task.tool_name.clone(),
                    error: task.error.clone().unwrap_or_default(),
                    timestamp: std::time::SystemTime::now(),
                    context: None,
                });
            }
        }
        
        Ok(result)
    }

    /// å®Œæ•´OODAæ¨¡å¼æ‰§è¡Œ
    async fn execute_full_ooda_mode(
        &self,
        task: &AgentTask,
        task_complexity: TaskComplexity,
        context: &mut HashMap<String, serde_json::Value>,
        execution_id: &str,
        message_id: &str,
        conversation_id: Option<String>,
    ) -> Result<AgentExecutionResult> {
        // åˆå§‹åŒ–æ‰§è¡Œè½¨è¿¹
        let mut trace = TravelTrace::new(task.description.clone(), task_complexity.clone());

        let mut arch_emitter = None;
        if let Some(app_handle) = &self.app_handle {
            let emitter = StandardMessageEmitter::new(
                Arc::new(app_handle.clone()),
                execution_id.to_string(),
                message_id.to_string(),
                conversation_id.clone(),
                ArchitectureType::Travel,
            );
            emitter.emit_start(Some(serde_json::json!({
                "task": task.description,
                "complexity": format!("{:?}", task_complexity),
            })));
            arch_emitter = Some(emitter);
        }

        // ä¸ºOodaExecutoré…ç½®æ¶ˆæ¯å‘é€
        let mut executor = OodaExecutor::new(self.config.clone());
        
        if let Some(app_handle) = &self.app_handle {
            executor = executor.with_app_handle(Arc::new(app_handle.clone()));
        }
        
        // è®¾ç½® VisionIntegration
        if let Some(vision) = &self.vision_integration {
            executor = executor.with_vision_integration(vision.clone());
            log::info!("TravelEngine: VisionIntegration passed to OodaExecutor");
        }
        
        // è·å–å–æ¶ˆä»¤ç‰Œå¹¶ä¼ é€’ç»™ OodaExecutor
        if let Some(token) = crate::managers::cancellation_manager::get_token(&execution_id).await {
            log::info!("TravelEngine: CancellationToken passed to OodaExecutor for {}", execution_id);
            executor = executor.with_cancellation_token(token);
        }
        
        executor = executor
            .with_message_ids(execution_id.to_string(), message_id.to_string(), conversation_id.clone());
        
        // è®¾ç½®dispatcherå’Œå…¶ä»–ä¾èµ–
        let mut dispatcher = EngineDispatcher::new();
        if let Some(ai_service) = &self.ai_service {
            dispatcher = dispatcher.with_ai_service(ai_service.clone());
        }
        if let Some(repo) = &self.prompt_repo {
            dispatcher = dispatcher.with_prompt_repo(repo.clone());
        }
        if let Some(adapter) = &self.framework_adapter {
            dispatcher = dispatcher.with_framework_adapter(adapter.clone());
        }
        if let Some(app) = &self.app_handle {
            dispatcher = dispatcher.with_app_handle(app.clone());
        }
        
        executor = executor.with_engine_dispatcher(dispatcher);

        // æ‰§è¡ŒOODAå¾ªç¯
        for cycle_num in 1..=self.config.max_ooda_cycles {
            log::info!("Starting OODA cycle {}/{}", cycle_num, self.config.max_ooda_cycles);

            // æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»§ç»­å¾ªç¯
            if self.should_stop_cycles(&trace, context) {
                log::info!("Stopping OODA cycles: task completed or max cycles reached");
                break;
            }

            // æ‰§è¡Œå•æ¬¡OODAå¾ªç¯
            match executor
                .execute_cycle(cycle_num, &task.description, task_complexity.clone(), context)
                .await
            {
                Ok(cycle) => {
                    let cycle_success = cycle.status == OodaCycleStatus::Completed;
                    trace.add_cycle(cycle);

                    // æ›´æ–°æŒ‡æ ‡
                    self.update_trace_metrics(&mut trace);

                    // å¦‚æœå¾ªç¯æˆåŠŸä¸”ä»»åŠ¡å®Œæˆ,é€€å‡º
                    if cycle_success && self.is_task_complete(context) {
                        log::info!("Task completed successfully after {} cycles", cycle_num);
                        break;
                    }
                }
                Err(e) => {
                    log::error!("OODA cycle {} failed: {}", cycle_num, e);
                    trace.fail(format!("Cycle {} failed: {}", cycle_num, e));
                    break;
                }
            }
        }

        // å®Œæˆè½¨è¿¹
        if trace.status == TravelStatus::Running {
            if trace.ooda_cycles.len() >= self.config.max_ooda_cycles as usize {
                trace.status = TravelStatus::MaxCyclesReached;
            } else {
                let final_result = context
                    .get("execution_result")
                    .cloned()
                    .unwrap_or(serde_json::json!({}));
                trace.complete(final_result);
            }
        }

        let result = self.trace_to_result(trace)?;

        if let Some(emitter) = &arch_emitter {
            if result.success {
                emitter.emit_complete(result.data.clone());
            } else {
                let err = result
                    .error
                    .clone()
                    .unwrap_or_else(|| "Travel execution failed".to_string());
                emitter.emit_error(&err);
            }
        }

        Ok(result)
    }

    /// å‡†å¤‡æ‰§è¡Œä¸Šä¸‹æ–‡
    fn prepare_context(&self, task: &AgentTask) -> Result<HashMap<String, serde_json::Value>> {
        let mut context = HashMap::new();

        // ä»ä»»åŠ¡å‚æ•°ä¸­æå–ä¿¡æ¯
        for (key, value) in &task.parameters {
            context.insert(key.clone(), value.clone());
        }

        // æ·»åŠ ç›®æ ‡ä¿¡æ¯
        if let Some(target) = task.parameters.get("target") {
            context.insert(
                "target_info".to_string(),
                serde_json::json!({
                    "target": target,
                    "authorized": task.parameters.get("authorized").and_then(|v| v.as_bool()).unwrap_or(false),
                }),
            );
        }

        Ok(context)
    }

    /// åˆ¤æ–­æ˜¯å¦åº”è¯¥åœæ­¢å¾ªç¯
    fn should_stop_cycles(&self, trace: &TravelTrace, context: &HashMap<String, serde_json::Value>) -> bool {
        // å¦‚æœå·²ç»è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°
        if trace.ooda_cycles.len() >= self.config.max_ooda_cycles as usize {
            return true;
        }

        // å¦‚æœä»»åŠ¡å·²å®Œæˆ
        if self.is_task_complete(context) {
            return true;
        }

        // å¦‚æœä¸Šä¸€ä¸ªå¾ªç¯å¤±è´¥
        if let Some(last_cycle) = trace.ooda_cycles.last() {
            if last_cycle.status == OodaCycleStatus::Failed {
                return true;
            }
        }

        false
    }

    /// åˆ¤æ–­ä»»åŠ¡æ˜¯å¦å®Œæˆ
    fn is_task_complete(&self, context: &HashMap<String, serde_json::Value>) -> bool {
        // æ£€æŸ¥æ˜¯å¦æœ‰æ‰§è¡Œç»“æœ
        if let Some(result) = context.get("execution_result") {
            if let Some(status) = result.get("status").and_then(|v| v.as_str()) {
                return status == "success" || status == "completed";
            }
            // å¦‚æœæœ‰ç»“æœå°±è®¤ä¸ºå®Œæˆ
            return true;
        }
        false
    }

    /// æ›´æ–°è½¨è¿¹æŒ‡æ ‡
    fn update_trace_metrics(&self, trace: &mut TravelTrace) {
        if let Some(last_cycle) = trace.ooda_cycles.last() {
            // ç»Ÿè®¡å·¥å…·è°ƒç”¨
            for phase in &last_cycle.phase_history {
                trace.metrics.total_tool_calls += phase.tool_calls.len() as u32;
            }

            // ç»Ÿè®¡æŠ¤æ æ£€æŸ¥
            for phase in &last_cycle.phase_history {
                trace.metrics.guardrail_checks += phase.guardrail_checks.len() as u32;
                trace.metrics.guardrail_failures += phase
                    .guardrail_checks
                    .iter()
                    .filter(|c| c.result == GuardrailCheckStatus::Failed)
                    .count() as u32;
            }

            // ç»Ÿè®¡å›é€€
            for phase in &last_cycle.phase_history {
                if phase.status == PhaseExecutionStatus::RolledBack {
                    trace.metrics.rollback_count += 1;
                }
            }
        }

        // è®¡ç®—æ€»æ‰§è¡Œæ—¶é—´
        if let Some(started) = trace.started_at.elapsed().ok() {
            trace.metrics.total_duration_ms = started.as_millis() as u64;
        }
    }

    /// å°†TravelTraceè½¬æ¢ä¸ºAgentExecutionResult
    fn trace_to_result(&self, trace: TravelTrace) -> Result<AgentExecutionResult> {
        let success = trace.status == TravelStatus::Completed;

        // æå–æœ€ç»ˆç»“æœ
        let output = if let Some(final_result) = &trace.final_result {
            final_result.clone()
        } else {
            serde_json::json!({
                "status": format!("{:?}", trace.status),
                "cycles": trace.ooda_cycles.len(),
                "message": "Travel execution completed",
            })
        };

        // æå–é”™è¯¯ä¿¡æ¯
        let error = if !success {
            Some(format!("Travel execution failed with status: {:?}", trace.status))
        } else {
            None
        };

        Ok(AgentExecutionResult {
            id: trace.trace_id.clone(),
            success,
            data: Some(serde_json::json!({
                "output": output,
                "trace_id": trace.trace_id,
                "task_complexity": format!("{:?}", trace.task_complexity),
                "total_cycles": trace.metrics.total_cycles,
                "total_tool_calls": trace.metrics.total_tool_calls,
                "guardrail_checks": trace.metrics.guardrail_checks,
                "guardrail_failures": trace.metrics.guardrail_failures,
                "rollback_count": trace.metrics.rollback_count,
                "duration_ms": trace.metrics.total_duration_ms,
                "status": format!("{:?}", trace.status),
            })),
            error,
            execution_time_ms: trace.metrics.total_duration_ms,
            resources_used: HashMap::new(),
            artifacts: Vec::new(),
        })
    }
}

// å®ç°BaseExecutionEngine trait
#[async_trait]
impl BaseExecutionEngine for TravelEngine {
    fn get_name(&self) -> &str {
        "Travel"
    }

    fn get_description(&self) -> &str {
        "OODA (Observe-Orient-Decide-Act) loop based security testing agent with intelligent task complexity analysis and multi-engine dispatch"
    }

    fn get_version(&self) -> &str {
        "1.0.0"
    }

    fn get_supported_scenarios(&self) -> Vec<String> {
        vec![
            "penetration_testing".to_string(),
            "vulnerability_assessment".to_string(),
            "security_scanning".to_string(),
            "threat_analysis".to_string(),
            "red_team_operations".to_string(),
            "code_audit".to_string(),
            "network_reconnaissance".to_string(),
        ]
    }

    fn get_performance_characteristics(&self) -> PerformanceCharacteristics {
        // Tokenæ•ˆç‡æ ¹æ®é…ç½®åŠ¨æ€è°ƒæ•´
        let token_efficiency = if self.config.lite_mode.enabled { 85 } else { 70 };
        let execution_speed = if self.config.parallel_config.enabled { 75 } else { 60 };
        let concurrency = if self.config.parallel_config.enabled { 90 } else { 80 };
        
        PerformanceCharacteristics {
            token_efficiency,     // 85 ç²¾ç®€æ¨¡å¼ / 70 å®Œæ•´æ¨¡å¼
            execution_speed,      // 75 å¹¶è¡Œæ‰§è¡Œ / 60 ä¸²è¡Œ
            resource_usage: 70,   // 70 æœ‰èµ„æºè¿½è¸ª / 60 æ— è¿½è¸ª
            concurrency_capability: concurrency, // 90 å¹¶è¡Œ / 80 ä¸²è¡Œ
            complexity_handling: 95, // ä¼˜ç§€,ä¸“ä¸ºå¤æ‚å®‰å…¨æµ‹è¯•è®¾è®¡
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_engine_metadata() {
        let engine = TravelEngine::with_defaults();
        assert_eq!(engine.get_name(), "Travel");
        assert!(engine
            .get_supported_scenarios()
            .contains(&"penetration_testing".to_string()));
    }

    // #[test]
    // fn test_prepare_context() {
    //     let engine = TravelEngine::with_defaults();
    //     let mut task = AgentTask {
    //         id: "test".to_string(),
    //         description: "Test task".to_string(),
    //         parameters: HashMap::new(),
    //         target: Some("localhost".to_string()),
    //         user_id: "test".to_string(),
    //         priority: TaskPriority::Normal,
    //         timeout: Some(10000),
    //     };

    //     task.parameters.insert(
    //         "target".to_string(),
    //         serde_json::Value::String("localhost".to_string()),
    //     );

    //     let context = engine.prepare_context(&task).unwrap();
    //     assert!(context.contains_key("target"));
    //     assert!(context.contains_key("target_info"));
    // }
}
