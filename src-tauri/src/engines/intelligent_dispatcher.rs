//! æ™ºèƒ½è°ƒåº¦å™¨æ¨¡å—
//! 
//! è¿™æ˜¯ä¸€ä¸ªLLMé©±åŠ¨çš„åŠ¨æ€æ¶æ„é€‰æ‹©å’Œæ‰§è¡Œç³»ç»Ÿï¼Œè´Ÿè´£ï¼š
//! - æ™ºèƒ½åˆ†æç”¨æˆ·æŸ¥è¯¢ç‰¹å¾
//! - åŠ¨æ€é€‰æ‹©æœ€é€‚åˆçš„Agentæ¶æ„
//! - ç”Ÿæˆä¼˜åŒ–çš„Promptæ¨¡æ¿
//! - åˆ›å»ºå’Œæ‰§è¡Œæ™ºèƒ½å·¥ä½œæµ

use std::collections::HashMap;
use std::sync::Arc;
use tokio::sync::RwLock;
use serde::{Deserialize, Serialize};
use chrono::{DateTime, Utc};
use uuid::Uuid;
use anyhow::Result;
use log::{info, warn};


use crate::services::ai::AiServiceManager;
use crate::services::mcp::McpService;
use crate::ai_adapter::core::AiAdapterManager;
use serde_json::{Value, Map};

/// æŸ¥è¯¢ç‰¹å¾åˆ†æç»“æœï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QueryFeatures {
    /// ä»»åŠ¡ç±»å‹
    pub task_type: String,
    /// å­ç±»åˆ«
    pub sub_category: String,
    /// å¹¶è¡ŒåŒ–æ½œåŠ› (high|medium|low)
    pub parallelization_potential: String,
    /// å¤æ‚åº¦ç­‰çº§ (simple|medium|complex)
    pub complexity_level: String,
    /// æ—¶é—´æ•æ„Ÿæ€§ (high|medium|low)
    pub time_sensitivity: String,
    /// ä¾èµ–å¤æ‚åº¦ (simple|medium|complex)
    pub dependency_complexity: String,
    /// é¢„ä¼°æ­¥éª¤æ•°
    pub estimated_steps: u32,
    /// èµ„æºéœ€æ±‚ (light|medium|heavy)
    pub resource_requirements: String,
    /// å…³é”®æŒ‡æ ‡
    pub key_indicators: Vec<String>,
    /// ç›®æ ‡åŸŸåæˆ–IP
    pub target_domain: Option<String>,
}

/// æ¶æ„é€‰æ‹©ç»“æœï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ArchitectureSelection {
    /// é€‰æ‹©çš„æ¶æ„
    pub selected_architecture: String,
    /// ç½®ä¿¡åº¦åˆ†æ•°
    pub confidence_score: f32,
    /// é€‰æ‹©ç†ç”±
    pub selection_reasoning: String,
    /// æ¶æ„é…ç½®
    pub architecture_config: ArchitectureConfig,
    /// å¤‡é€‰æ¶æ„
    pub fallback_architecture: String,
}

/// æ¶æ„é…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ArchitectureConfig {
    /// æœ€å¤§å¹¶è¡Œä»»åŠ¡æ•°
    pub max_parallel_tasks: u32,
    /// æ¯ä¸ªä»»åŠ¡è¶…æ—¶æ—¶é—´
    pub timeout_per_task: u32,
    /// é‡è¯•ç­–ç•¥
    pub retry_policy: String,
    /// èµ„æºé™åˆ¶
    pub resource_limits: Option<ResourceConfig>,
}

/// èµ„æºé…ç½®
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ResourceConfig {
    /// CPUæ ¸å¿ƒæ•°
    pub cpu_cores: u32,
    /// å†…å­˜é™åˆ¶(GB)
    pub memory_gb: u32,
    /// ç½‘ç»œå¹¶å‘æ•°
    pub network_concurrent: u32,
}

/// åŠ¨æ€ç”Ÿæˆçš„Prompté›†åˆï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DynamicPrompts {
    /// è§„åˆ’å™¨Prompt
    pub planner: String,
    /// æ‰§è¡Œå™¨Prompt
    pub executor: String,
    /// åˆ†æå™¨Prompt
    pub analyzer: Option<String>,
    /// å·¥å…·é€‰æ‹©å™¨Prompt
    pub tool_selector: Option<String>,
}

/// æ™ºèƒ½è°ƒåº¦å™¨
pub struct IntelligentDispatcher {
    /// AIæœåŠ¡ç®¡ç†å™¨
    ai_service_manager: Arc<AiServiceManager>,
    /// MCPæœåŠ¡
    mcp_service: Arc<McpService>,
    /// å·¥ä½œæµå¼•æ“
    workflow_engine: Arc<WorkflowEngine>,
    /// æŸ¥è¯¢åˆ†æå™¨
    query_analyzer: QueryAnalyzer,
    /// æ¶æ„é€‰æ‹©å™¨
    architecture_selector: ArchitectureSelector,
    /// åŠ¨æ€Promptç”Ÿæˆå™¨
    prompt_generator: DynamicPromptGenerator,
    /// æ‰§è¡Œå†å²
    execution_history: Arc<RwLock<Vec<ExecutionRecord>>>,
}

/// æ‰§è¡Œè®°å½•
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExecutionRecord {
    pub query: String,
    pub features: QueryFeatures,
    pub selected_architecture: String,
    pub execution_time: u64,
    pub success_rate: f32,
    pub parallel_efficiency: f32,
    pub timestamp: DateTime<Utc>,
}

impl IntelligentDispatcher {
    /// åˆ›å»ºæ–°çš„æ™ºèƒ½è°ƒåº¦å™¨
    pub async fn new(
        ai_service_manager: Arc<AiServiceManager>,
        mcp_service: Arc<McpService>,
        workflow_engine: Arc<WorkflowEngine>,
    ) -> Result<Self> {
        // åˆ›å»ºå¸¦æœ‰AIæœåŠ¡ç®¡ç†å™¨çš„æŸ¥è¯¢åˆ†æå™¨ï¼Œä»¥ä¾¿ä½¿ç”¨é…ç½®çš„æ„å›¾åˆ†ææ¨¡å‹
        use crate::ai_adapter::providers::deepseek::DeepSeekProvider;
        use crate::ai_adapter::types::ProviderConfig;
        
        // ä»æ•°æ®åº“è·å–DeepSeeké…ç½®
        let ai_config = match ai_service_manager.get_provider_config("deepseek").await {
            Ok(Some(config)) => config,
            Ok(None) => {
                tracing::warn!("No DeepSeek configuration found in database, using default");
                crate::services::ai::AiConfig {
                    provider: "deepseek".to_string(),
                    model: "deepseek-chat".to_string(),
                    api_key: None,
                    api_base: Some("https://api.deepseek.com".to_string()),
                    organization: None,
                    temperature: Some(0.7),
                    max_tokens: Some(4096),
                }
            },
            Err(e) => {
                tracing::error!("Failed to get DeepSeek configuration: {}", e);
                return Err(anyhow::anyhow!("Failed to initialize IntelligentDispatcher: {}", e));
            }
        };
        
        let config = ProviderConfig {
            name: ai_config.provider,
            api_key: ai_config.api_key,
            api_base: ai_config.api_base,
            api_version: None,
            organization: ai_config.organization,
            project: None,
            timeout: None,
            retry_strategy: None,
            extra_headers: None,
            extra_params: None,
        };
        
        let provider = DeepSeekProvider::new(config).unwrap();
        let query_analyzer = QueryAnalyzer::new_with_service_manager(
            Box::new(provider),
            ai_service_manager.clone()
        );
        
        let architecture_selector = ArchitectureSelector::new(ai_service_manager.clone());
        let prompt_generator = DynamicPromptGenerator::new();
        
        Ok(Self {
            ai_service_manager,
            mcp_service,
            registry,
            workflow_engine,
            query_analyzer,
            architecture_selector,
            prompt_generator,
            execution_history: Arc::new(RwLock::new(Vec::new())),
        })
    }
    
    /// æ™ºèƒ½å¤„ç†ç”¨æˆ·æŸ¥è¯¢
    pub async fn process_query(&mut self, user_input: String) -> Result<DispatchResult> {
        info!("ğŸ” å¼€å§‹æ™ºèƒ½åˆ†æç”¨æˆ·æŸ¥è¯¢: {}", user_input);
        info!("ğŸ“‹ æ‰§è¡Œæ­¥éª¤: 1.æŸ¥è¯¢åˆ†æ -> 2.æ¶æ„é€‰æ‹© -> 3.Promptç”Ÿæˆ -> 4.å·¥ä½œæµåˆ›å»º -> 5.å·¥ä½œæµæ‰§è¡Œ");
        
        // 1. æŸ¥è¯¢åˆ†æé˜¶æ®µ
        info!("ğŸ”„ æ­¥éª¤1: å¼€å§‹æŸ¥è¯¢ç‰¹å¾åˆ†æ...");
        let analysis_result = self.query_analyzer.analyze_query(&user_input).await
            .map_err(|e| anyhow::anyhow!("æŸ¥è¯¢åˆ†æå¤±è´¥: {}", e))?;
        let query_features = self.convert_analysis_to_features(&analysis_result);
        info!("âœ… æ­¥éª¤1å®Œæˆ: æŸ¥è¯¢ç‰¹å¾åˆ†æ - ä»»åŠ¡ç±»å‹: {}, å¤æ‚åº¦: {}, ç›®æ ‡åŸŸ: {:?}, é¢„ä¼°æ­¥éª¤: {}", 
              query_features.task_type, 
              query_features.complexity_level,
              query_features.target_domain,
              query_features.estimated_steps);
        
        // 2. æ¶æ„é€‰æ‹©é˜¶æ®µ
        info!("ğŸ”„ æ­¥éª¤2: å¼€å§‹æ™ºèƒ½æ¶æ„é€‰æ‹©...");
        let selection_result = self.architecture_selector.select_architecture(&analysis_result).await
            .map_err(|e| anyhow::anyhow!("æ¶æ„é€‰æ‹©å¤±è´¥: {}", e))?;
        let architecture_selection = self.convert_selection_to_legacy(&selection_result);
        info!("âœ… æ­¥éª¤2å®Œæˆ: æ¶æ„é€‰æ‹© - é€‰æ‹©æ¶æ„: {}, ç½®ä¿¡åº¦: {:.2}, é€‰æ‹©ç†ç”±: {}", 
              architecture_selection.selected_architecture, 
              architecture_selection.confidence_score,
              architecture_selection.selection_reasoning);
        
        // 3. åŠ¨æ€Promptç”Ÿæˆé˜¶æ®µ
        info!("ğŸ”„ æ­¥éª¤3: å¼€å§‹åŠ¨æ€Promptç”Ÿæˆ...");
        let prompt_result = self.prompt_generator.generate_prompt(
            &analysis_result,
            &selection_result,
            &user_input,
            None
        ).await
            .map_err(|e| anyhow::anyhow!("Promptç”Ÿæˆå¤±è´¥: {}", e))?;
        let custom_prompts = self.convert_prompt_to_legacy(&prompt_result);
        info!("âœ… æ­¥éª¤3å®Œæˆ: åŠ¨æ€Promptç”Ÿæˆ - è§„åˆ’å™¨Prompté•¿åº¦: {}, æ‰§è¡Œå™¨Prompté•¿åº¦: {}",
              custom_prompts.planner.len(),
              custom_prompts.executor.len());
        
        // 4. åˆ›å»ºæ™ºèƒ½å·¥ä½œæµ
        info!("ğŸ”„ æ­¥éª¤4: å¼€å§‹åˆ›å»º{}æ™ºèƒ½å·¥ä½œæµ...", architecture_selection.selected_architecture);
        let workflow = self.create_intelligent_workflow(
            &architecture_selection,
            &query_features,
            &custom_prompts,
            &user_input
        ).await?;
        info!("âœ… æ­¥éª¤4å®Œæˆ: å·¥ä½œæµåˆ›å»º - å·¥ä½œæµID: {}, æ­¥éª¤æ•°: {}",
              workflow.metadata.id,
              workflow.steps.len());
        
        // 5. æ‰§è¡Œå·¥ä½œæµ
        info!("ğŸ”„ æ­¥éª¤5: å¼€å§‹æ‰§è¡Œæ™ºèƒ½å·¥ä½œæµ...");
        let execution_id = self.workflow_engine.execute_workflow(&workflow, None).await?;
        info!("âœ… æ­¥éª¤5å¯åŠ¨: å·¥ä½œæµæ‰§è¡Œå·²å¯åŠ¨ - æ‰§è¡ŒID: {}", execution_id);
        
        // 6. è®°å½•æ‰§è¡Œå†å²
        info!("ğŸ“ è®°å½•æ‰§è¡Œå†å²åˆ°å†…å­˜ç¼“å­˜...");
        self.record_execution(&user_input, &query_features, &architecture_selection).await;
        
        // 7. åˆ›å»ºè°ƒåº¦ç»“æœ
        let result = DispatchResult {
            request_id: Uuid::new_v4().to_string(),
            execution_id: execution_id.clone(),
            decision: DispatchDecision {
                architecture: self.map_to_agent_architecture(&architecture_selection.selected_architecture),
                task_type: self.map_to_task_type(&query_features.task_type),
                complexity: self.map_to_complexity(&query_features.complexity_level),
                reasoning: architecture_selection.selection_reasoning,
                confidence: architecture_selection.confidence_score,
                estimated_duration: Some(self.estimate_duration(&query_features)),
                suggested_workflow: Some(workflow),
            },
            status: WorkflowStatus::Running,
            started_at: Utc::now(),
            completed_at: None,
            result: None,
            error: None,
        };
        
        info!("ğŸ‰ æ™ºèƒ½è°ƒåº¦å®Œæˆ! è¯·æ±‚ID: {}, æ‰§è¡ŒID: {}, é¢„ä¼°æ—¶é•¿: {}ç§’",
              result.request_id,
              execution_id,
              result.decision.estimated_duration.unwrap_or(0));
        
        Ok(result)
    }
    
    
    /// åˆ›å»ºæ™ºèƒ½å·¥ä½œæµ
    async fn create_intelligent_workflow(
        &self,
        architecture_selection: &ArchitectureSelection,
        query_features: &QueryFeatures,
        custom_prompts: &DynamicPrompts,
        user_input: &str,
    ) -> Result<WorkflowDefinition> {
        info!("ğŸ—ï¸ æ ¹æ®æ¶æ„ç±»å‹åˆ›å»ºå·¥ä½œæµ: {}", architecture_selection.selected_architecture);
        
        let workflow = match architecture_selection.selected_architecture.as_str() {
            "LlmCompiler" => {
                info!("ğŸ”§ åˆ›å»ºLLMCompilerå¹¶è¡Œæ‰§è¡Œå·¥ä½œæµ...");
                self.create_llm_compiler_workflow(query_features, custom_prompts, user_input).await?
            },
            "ReWoo" => {
                info!("ğŸ”§ åˆ›å»ºReWOOæ¨ç†é“¾å·¥ä½œæµ...");
                self.create_rewoo_workflow(query_features, custom_prompts, user_input).await?
            },
            "PlanAndExecute" | _ => {
                info!("ğŸ”§ åˆ›å»ºPlan-ExecuteåŸºç¡€å·¥ä½œæµ...");
                self.create_plan_execute_workflow(query_features, custom_prompts, user_input).await?
            },
        };
        
        info!("âœ… å·¥ä½œæµåˆ›å»ºæˆåŠŸ: {} - {}", workflow.metadata.name, workflow.metadata.description);
        Ok(workflow)
    }
    
    /// åˆ›å»ºLLMCompilerå·¥ä½œæµ
    async fn create_llm_compiler_workflow(
        &self,
        query_features: &QueryFeatures,
        custom_prompts: &DynamicPrompts,
        user_input: &str,
    ) -> Result<WorkflowDefinition> {
        let target = query_features.target_domain.clone().unwrap_or("æœªæŒ‡å®š".to_string());
        
        let workflow = WorkflowDefinition {
            metadata: WorkflowMetadata {
                id: Uuid::new_v4().to_string(),
                name: "LLMCompilerå¹¶è¡Œæ¨ç†å·¥ä½œæµ".to_string(),
                version: "2.0.0".to_string(),
                description: "åŸºäºLLMCompileræ¶æ„çš„æµå¼å¹¶è¡Œæ‰§è¡Œå·¥ä½œæµï¼ŒåŒ…å«Plannerã€Task Fetching Unitã€Joinerä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶".to_string(),
                author: Some("IntelligentDispatcher".to_string()),
                tags: vec!["llm-compiler".to_string(), "streaming".to_string(), "parallel".to_string(), "dag".to_string()],
                created_at: Utc::now(),
                updated_at: Utc::now(),
            },
            steps: vec![
                // 1. Planneræ¨¡å— - æµå¼ç”Ÿæˆä»»åŠ¡DAG
                WorkflowStep {
                    id: "planner".to_string(),
                    name: "è§„åˆ’å™¨".to_string(),
                    agent_type: "llm_compiler_planner".to_string(),
                    action: "stream_task_dag".to_string(),
                    inputs: {
                        let mut inputs = HashMap::new();
                        inputs.insert("user_request".to_string(), Value::String(user_input.to_string()));
                        inputs.insert("target_domain".to_string(), Value::String(target.clone()));
                        inputs.insert("custom_prompt".to_string(), Value::String(custom_prompts.planner.clone()));
                        inputs.insert("query_features".to_string(), serde_json::to_value(query_features)?); 
                        inputs.insert("max_parallel_tasks".to_string(), Value::Number(query_features.estimated_steps.into()));
                        inputs.insert("complexity_level".to_string(), Value::String(query_features.complexity_level.clone()));
                        inputs
                    },
                    outputs: {
                        let mut outputs = HashMap::new();
                        outputs.insert("task_dag_stream".to_string(), "task_dag_stream".to_string());
                        outputs.insert("task_dependencies".to_string(), "task_dependencies".to_string());
                        outputs.insert("variable_mappings".to_string(), "variable_mappings".to_string());
                        outputs.insert("execution_graph".to_string(), "execution_graph".to_string());
                        outputs
                    },
                    depends_on: vec![],
                    condition: None,
                    retry: Some(RetryConfig {
                        max_attempts: 3,
                        delay: 5,
                        backoff: BackoffStrategy::Exponential { multiplier: 2.0 },
                        retry_on: vec!["planning_error".to_string(), "dag_generation_error".to_string()],
                    }),
                    timeout: Some(300),
                    parallel: false,
                    config: Some(serde_json::json!({
                        "enable_streaming": true,
                        "dag_max_depth": 10,
                        "enable_variable_substitution": true,
                        "planning_strategy": "streaming_decomposition",
                        "output_parser_mode": "eager"
                    })),
                },
                
                // 2. Task Fetching Unitæ¨¡å— - å¹¶è¡Œè°ƒåº¦æ‰§è¡Œ
                WorkflowStep {
                    id: "task_fetching_unit".to_string(),
                    name: "ä»»åŠ¡è·å–å•å…ƒ".to_string(),
                    agent_type: "llm_compiler_scheduler".to_string(),
                    action: "schedule_and_execute_tasks".to_string(),
                    inputs: {
                        let mut inputs = HashMap::new();
                        inputs.insert("task_dag_stream".to_string(), Value::String("{{planner.task_dag_stream}}".to_string()));
                        inputs.insert("task_dependencies".to_string(), Value::String("{{planner.task_dependencies}}".to_string()));
                        inputs.insert("variable_mappings".to_string(), Value::String("{{planner.variable_mappings}}".to_string()));
                        inputs.insert("execution_graph".to_string(), Value::String("{{planner.execution_graph}}".to_string()));
                        inputs.insert("custom_prompt".to_string(), Value::String(custom_prompts.executor.clone()));
                        inputs
                    },
                    outputs: {
                        let mut outputs = HashMap::new();
                        outputs.insert("task_results".to_string(), "task_results".to_string());
                        outputs.insert("execution_history".to_string(), "execution_history".to_string());
                        outputs.insert("variable_values".to_string(), "variable_values".to_string());
                        outputs.insert("parallel_execution_stats".to_string(), "parallel_execution_stats".to_string());
                        outputs.insert("dependency_resolution_log".to_string(), "dependency_resolution_log".to_string());
                        outputs
                    },
                    depends_on: vec!["planner".to_string()],
                    condition: None,
                    retry: Some(RetryConfig {
                        max_attempts: 2,
                        delay: 3,
                        backoff: BackoffStrategy::Fixed,
                        retry_on: vec!["task_execution_error".to_string(), "dependency_error".to_string()],
                    }),
                    timeout: Some(1800), // 30åˆ†é’Ÿæ‰§è¡Œè¶…æ—¶
                    parallel: true, // æ ¸å¿ƒå¹¶è¡Œæ‰§è¡Œæ¨¡å—
                    config: Some(serde_json::json!({
                        "max_concurrent_tasks": if query_features.parallelization_potential == "high" { 8 } else { 4 },
                        "enable_eager_scheduling": true,
                        "dependency_check_interval": 100, // ms
                        "enable_variable_substitution": true,
                        "task_timeout": 300,
                        "enable_result_streaming": true,
                        "scheduler_strategy": "dependency_aware"
                    })),
                },
                
                // 3. Joineræ¨¡å— - åŠ¨æ€é‡è§„åˆ’æˆ–å®Œæˆ
                WorkflowStep {
                    id: "joiner".to_string(),
                    name: "è¿æ¥å™¨".to_string(),
                    agent_type: "llm_compiler_joiner".to_string(),
                    action: "decide_replan_or_complete".to_string(),
                    inputs: {
                        let mut inputs = HashMap::new();
                        inputs.insert("user_request".to_string(), Value::String(user_input.to_string()));
                        inputs.insert("task_results".to_string(), Value::String("{{task_fetching_unit.task_results}}".to_string()));
                        inputs.insert("execution_history".to_string(), Value::String("{{task_fetching_unit.execution_history}}".to_string()));
                        inputs.insert("variable_values".to_string(), Value::String("{{task_fetching_unit.variable_values}}".to_string()));
                        inputs.insert("execution_graph".to_string(), Value::String("{{planner.execution_graph}}".to_string()));
                        inputs.insert("parallel_execution_stats".to_string(), Value::String("{{task_fetching_unit.parallel_execution_stats}}".to_string()));
                        inputs.insert("custom_prompt".to_string(), Value::String(custom_prompts.analyzer.clone().unwrap_or_else(|| "åŸºäºæ‰§è¡Œå†å²å†³å®šæ˜¯å¦é‡è§„åˆ’æˆ–å®Œæˆ".to_string())));
                        inputs
                    },
                    outputs: {
                        let mut outputs = HashMap::new();
                        outputs.insert("decision".to_string(), "decision".to_string()); // "complete" or "replan"
                        outputs.insert("final_answer".to_string(), "final_answer".to_string());
                        outputs.insert("replan_instructions".to_string(), "replan_instructions".to_string());
                        outputs.insert("completion_confidence".to_string(), "completion_confidence".to_string());
                        outputs.insert("execution_summary".to_string(), "execution_summary".to_string());
                        outputs
                    },
                    depends_on: vec!["task_fetching_unit".to_string()],
                    condition: None,
                    retry: Some(RetryConfig {
                        max_attempts: 2,
                        delay: 2,
                        backoff: BackoffStrategy::Fixed,
                        retry_on: vec!["decision_error".to_string(), "completion_error".to_string()],
                    }),
                    timeout: Some(300),
                    parallel: false,
                    config: Some(serde_json::json!({
                        "completion_threshold": 0.8,
                        "enable_dynamic_replanning": true,
                        "max_replan_iterations": 3,
                        "decision_strategy": "graph_history_based",
                        "enable_confidence_scoring": true
                    })),
                },
                
                // 4. æ¡ä»¶é‡è§„åˆ’æ­¥éª¤ï¼ˆå¯é€‰ï¼‰
                WorkflowStep {
                    id: "replan".to_string(),
                    name: "é‡æ–°è§„åˆ’".to_string(),
                    agent_type: "llm_compiler_planner".to_string(),
                    action: "replan_from_progress".to_string(),
                    inputs: {
                        let mut inputs = HashMap::new();
                        inputs.insert("user_request".to_string(), Value::String(user_input.to_string()));
                        inputs.insert("replan_instructions".to_string(), Value::String("{{joiner.replan_instructions}}".to_string()));
                        inputs.insert("execution_history".to_string(), Value::String("{{task_fetching_unit.execution_history}}".to_string()));
                        inputs.insert("variable_values".to_string(), Value::String("{{task_fetching_unit.variable_values}}".to_string()));
                        inputs.insert("custom_prompt".to_string(), Value::String(custom_prompts.planner.clone()));
                        inputs
                    },
                    outputs: {
                        let mut outputs = HashMap::new();
                        outputs.insert("updated_task_dag".to_string(), "updated_task_dag".to_string());
                        outputs.insert("new_dependencies".to_string(), "new_dependencies".to_string());
                        outputs.insert("replan_success".to_string(), "replan_success".to_string());
                        outputs
                    },
                    depends_on: vec!["joiner".to_string()],
                    condition: Some("{{joiner.decision}} == 'replan'".to_string()),
                    retry: Some(RetryConfig {
                        max_attempts: 2,
                        delay: 3,
                        backoff: BackoffStrategy::Fixed,
                        retry_on: vec!["replan_error".to_string()],
                    }),
                    timeout: Some(300),
                    parallel: false,
                    config: Some(serde_json::json!({
                        "enable_incremental_planning": true,
                        "preserve_completed_tasks": true,
                        "replan_strategy": "progressive_enhancement"
                    })),
                },
            ],
            variables: {
                let mut variables = HashMap::new();
                variables.insert("global_execution_state".to_string(), Value::Object(serde_json::Map::new()));
                variables.insert("task_variable_registry".to_string(), Value::Object(serde_json::Map::new()));
                variables.insert("replan_counter".to_string(), Value::Number(0.into()));
                variables
            },
            error_handling: Some(ErrorHandling {
                default_strategy: ErrorStrategy::Retry,
                step_strategies: {
                    let mut strategies = HashMap::new();
                    strategies.insert("task_fetching_unit".to_string(), ErrorStrategy::Continue);
                    strategies.insert("joiner".to_string(), ErrorStrategy::Retry);
                    strategies
                },
                on_error: Some("graceful_degradation_with_partial_results".to_string()),
            }),
            notifications: Some(NotificationConfig {
                on_success: vec![
                    NotificationTarget {
                        target_type: "workflow_completion".to_string(),
                        config: serde_json::json!({
                            "message": "LLMCompilerå·¥ä½œæµæ‰§è¡ŒæˆåŠŸ",
                            "channel": "info",
                            "include_stats": true
                        }),
                    }
                ],
                on_failure: vec![
                    NotificationTarget {
                        target_type: "error_analysis".to_string(),
                        config: serde_json::json!({
                            "message": "LLMCompilerå·¥ä½œæµæ‰§è¡Œå¤±è´¥",
                            "channel": "error",
                            "log_file": "llm_compiler_errors.log",
                            "include_dag_state": true
                        }),
                    }
                ],
                on_progress: vec![
                    NotificationTarget {
                        target_type: "parallel_progress".to_string(),
                        config: serde_json::json!({
                            "message": "LLMCompilerå¹¶è¡Œæ‰§è¡Œè¿›åº¦",
                            "channel": "progress",
                            "update_interval": 5000
                        }),
                    }
                ],
            }),
        };
        
        Ok(workflow)
    }
    
    /// åˆ›å»ºReWOOå·¥ä½œæµ
    async fn create_rewoo_workflow(
        &self,
        query_features: &QueryFeatures,
        custom_prompts: &DynamicPrompts,
        user_input: &str,
    ) -> Result<WorkflowDefinition> {
        let workflow = WorkflowDefinition {
            metadata: WorkflowMetadata {
                id: Uuid::new_v4().to_string(),
                name: "ReWOOæ¨ç†å·¥ä½œæµ".to_string(),
                version: "2.0.0".to_string(),
                description: "åŸºäºReWOOæ¶æ„çš„æ¨ç†å·¥ä½œæµï¼ŒåŒ…å«Plannerã€Workerã€Solverä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—".to_string(),
                author: Some("IntelligentDispatcher".to_string()),
                tags: vec!["rewoo".to_string(), "reasoning".to_string(), "planner".to_string(), "worker".to_string(), "solver".to_string()],
                created_at: Utc::now(),
                updated_at: Utc::now(),
            },
            steps: vec![
                // 1. Planneræ¨¡å— - ç”Ÿæˆå¸¦å˜é‡æ›¿æ¢çš„è®¡åˆ’
                WorkflowStep {
                    id: "planner".to_string(),
                    name: "è§„åˆ’å™¨".to_string(),
                    agent_type: "rewoo_planner".to_string(),
                    action: "generate_task_plan".to_string(),
                    inputs: {
                        let mut inputs = HashMap::new();
                        inputs.insert("user_request".to_string(), Value::String(user_input.to_string()));
                        inputs.insert("custom_prompt".to_string(), Value::String(custom_prompts.planner.clone()));
                        inputs.insert("query_features".to_string(), serde_json::to_value(query_features)?);
                        inputs
                    },
                    outputs: {
                        let mut outputs = HashMap::new();
                        outputs.insert("task_list".to_string(), "task_list".to_string());
                        outputs.insert("variable_mappings".to_string(), "variable_mappings".to_string());
                        outputs.insert("execution_plan".to_string(), "execution_plan".to_string());
                        outputs.insert("task_dependencies".to_string(), "task_dependencies".to_string());
                        outputs
                    },
                    depends_on: vec![],
                    condition: None,
                    retry: Some(RetryConfig {
                        max_attempts: 3,
                        delay: 5,
                        backoff: BackoffStrategy::Exponential { multiplier: 2.0 },
                        retry_on: vec!["planning_error".to_string(), "timeout".to_string()],
                    }),
                    timeout: Some(300),
                    parallel: false,
                    config: Some(serde_json::json!({
                        "max_tasks": 10,
                        "enable_variable_substitution": true,
                        "planning_strategy": "decomposition",
                        "task_complexity_threshold": query_features.complexity_level
                    })),
                },
                
                // 2. Workeræ¨¡å— - æ‰§è¡Œå·¥å…·å¹¶æ”¶é›†ç»“æœ
                WorkflowStep {
                    id: "worker".to_string(),
                    name: "å·¥ä½œå™¨".to_string(),
                    agent_type: "rewoo_worker".to_string(),
                    action: "execute_tasks".to_string(),
                    inputs: {
                        let mut inputs = HashMap::new();
                        inputs.insert("task_list".to_string(), Value::String("{{planner.task_list}}".to_string()));
                        inputs.insert("variable_mappings".to_string(), Value::String("{{planner.variable_mappings}}".to_string()));
                        inputs.insert("execution_plan".to_string(), Value::String("{{planner.execution_plan}}".to_string()));
                        inputs.insert("task_dependencies".to_string(), Value::String("{{planner.task_dependencies}}".to_string()));
                        inputs.insert("custom_prompt".to_string(), Value::String(custom_prompts.executor.clone()));
                        inputs
                    },
                    outputs: {
                        let mut outputs = HashMap::new();
                        outputs.insert("task_results".to_string(), "task_results".to_string());
                        outputs.insert("tool_outputs".to_string(), "tool_outputs".to_string());
                        outputs.insert("execution_status".to_string(), "execution_status".to_string());
                        outputs.insert("variable_values".to_string(), "variable_values".to_string());
                        outputs.insert("intermediate_results".to_string(), "intermediate_results".to_string());
                        outputs
                    },
                    depends_on: vec!["planner".to_string()],
                    condition: None,
                    retry: Some(RetryConfig {
                        max_attempts: 2,
                        delay: 3,
                        backoff: BackoffStrategy::Fixed,
                        retry_on: vec!["tool_error".to_string(), "execution_error".to_string()],
                    }),
                    timeout: Some(1800), // 30åˆ†é’Ÿæ‰§è¡Œè¶…æ—¶
                    parallel: query_features.parallelization_potential == "high",
                    config: Some(serde_json::json!({
                        "enable_tool_calling": true,
                        "max_concurrent_tasks": if query_features.parallelization_potential == "high" { 5 } else { 2 },
                        "enable_variable_substitution": true,
                        "tool_timeout": 300,
                        "enable_result_caching": true
                    })),
                },
                
                // 3. Solveræ¨¡å— - åŸºäºå·¥å…·è¾“å‡ºç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
                WorkflowStep {
                    id: "solver".to_string(),
                    name: "æ±‚è§£å™¨".to_string(),
                    agent_type: "rewoo_solver".to_string(),
                    action: "solve_and_respond".to_string(),
                    inputs: {
                        let mut inputs = HashMap::new();
                        inputs.insert("user_request".to_string(), Value::String(user_input.to_string()));
                        inputs.insert("task_results".to_string(), Value::String("{{worker.task_results}}".to_string()));
                        inputs.insert("tool_outputs".to_string(), Value::String("{{worker.tool_outputs}}".to_string()));
                        inputs.insert("variable_values".to_string(), Value::String("{{worker.variable_values}}".to_string()));
                        inputs.insert("intermediate_results".to_string(), Value::String("{{worker.intermediate_results}}".to_string()));
                        inputs.insert("execution_plan".to_string(), Value::String("{{planner.execution_plan}}".to_string()));
                        inputs.insert("custom_prompt".to_string(), Value::String(custom_prompts.analyzer.clone().unwrap_or_else(|| "åŸºäºå·¥å…·è¾“å‡ºç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ".to_string())));
                        inputs
                    },
                    outputs: {
                        let mut outputs = HashMap::new();
                        outputs.insert("final_answer".to_string(), "final_answer".to_string());
                        outputs.insert("reasoning_chain".to_string(), "reasoning_chain".to_string());
                        outputs.insert("confidence_score".to_string(), "confidence_score".to_string());
                        outputs.insert("solution_quality".to_string(), "solution_quality".to_string());
                        outputs.insert("response_metadata".to_string(), "response_metadata".to_string());
                        outputs
                    },
                    depends_on: vec!["worker".to_string()],
                    condition: None,
                    retry: Some(RetryConfig {
                        max_attempts: 2,
                        delay: 2,
                        backoff: BackoffStrategy::Fixed,
                        retry_on: vec!["reasoning_error".to_string(), "synthesis_error".to_string()],
                    }),
                    timeout: Some(300),
                    parallel: false,
                    config: Some(serde_json::json!({
                        "enable_reasoning_validation": true,
                        "confidence_threshold": 0.7,
                        "enable_answer_synthesis": true,
                        "max_reasoning_depth": 5,
                        "enable_quality_assessment": true
                    })),
                },
            ],
            variables: {
                let mut variables = HashMap::new();
                variables.insert("execution_context".to_string(), Value::Object(serde_json::Map::new()));
                variables.insert("global_state".to_string(), Value::Object(serde_json::Map::new()));
                variables
            },
            error_handling: Some(ErrorHandling {
                default_strategy: ErrorStrategy::Retry,
                step_strategies: HashMap::new(),
                on_error: Some("graceful_degradation".to_string()),
            }),
            notifications: Some(NotificationConfig {
                on_success: vec![
                    NotificationTarget {
                        target_type: "workflow_status".to_string(),
                        config: serde_json::json!({
                            "message": "ReWOOå·¥ä½œæµæ‰§è¡ŒæˆåŠŸ",
                            "channel": "info"
                        }),
                    }
                ],
                on_failure: vec![
                    NotificationTarget {
                        target_type: "error_log".to_string(),
                        config: serde_json::json!({
                            "message": "ReWOOå·¥ä½œæµæ‰§è¡Œå¤±è´¥",
                            "channel": "error",
                            "log_file": "rewoo_errors.log"
                        }),
                    }
                ],
                on_progress: vec![
                    NotificationTarget {
                        target_type: "progress_update".to_string(),
                        config: serde_json::json!({
                            "message": "ReWOOå·¥ä½œæµè¿›åº¦æ›´æ–°",
                            "channel": "progress"
                        }),
                    }
                ],
            }),
        };
        
        Ok(workflow)
    }
    
    /// åˆ›å»ºPlan-Executeå·¥ä½œæµ
    /// åŸºäºLangGraphæ¶æ„è®¾è®¡ï¼ŒåŒ…å«plannerã€agentã€replanèŠ‚ç‚¹å’Œæ¡ä»¶è¾¹ç¼˜
    async fn create_plan_execute_workflow(
        &self,
        query_features: &QueryFeatures,
        custom_prompts: &DynamicPrompts,
        user_input: &str,
    ) -> Result<WorkflowDefinition> {
        let workflow = WorkflowDefinition {
            metadata: WorkflowMetadata {
                id: Uuid::new_v4().to_string(),
                name: "æ™ºèƒ½Plan-Executeå·¥ä½œæµ".to_string(),
                version: "1.0.0".to_string(),
                description: "åŸºäºLangGraphæ¶æ„çš„è®¡åˆ’æ‰§è¡Œå·¥ä½œæµï¼Œæ”¯æŒåŠ¨æ€é‡è§„åˆ’".to_string(),
                author: Some("IntelligentDispatcher".to_string()),
                tags: vec!["plan-execute".to_string(), "langgraph".to_string(), "intelligent".to_string()],
                created_at: Utc::now(),
                updated_at: Utc::now(),
            },
            steps: vec![
                // 1. PlannerèŠ‚ç‚¹ - åˆ›å»ºåˆå§‹è®¡åˆ’
                WorkflowStep {
                    id: "planner".to_string(),
                    name: "è§„åˆ’å™¨".to_string(),
                    agent_type: "plan_and_execute".to_string(),
                    action: "create_plan".to_string(),
                    inputs: {
                        let mut inputs = HashMap::new();
                        inputs.insert("user_input".to_string(), Value::String(user_input.to_string()));
                        inputs.insert("custom_prompt".to_string(), Value::String(custom_prompts.planner.clone()));
                        inputs.insert("query_features".to_string(), serde_json::to_value(query_features)?);
                        inputs
                    },
                    outputs: {
                        let mut outputs = HashMap::new();
                        outputs.insert("plan".to_string(), "plan".to_string());
                        outputs.insert("plan_steps".to_string(), "plan_steps".to_string());
                        outputs.insert("current_step_index".to_string(), "current_step_index".to_string());
                        outputs
                    },
                    depends_on: vec![],
                    condition: None,
                    retry: Some(RetryConfig {
                        max_attempts: 3,
                        delay: 5,
                        backoff: BackoffStrategy::Exponential { multiplier: 2.0 },
                        retry_on: vec!["timeout".to_string(), "network_error".to_string()],
                    }),
                    timeout: Some(300),
                    parallel: false,
                    config: Some(serde_json::json!({
                        "max_plan_steps": 10,
                        "enable_parallel_planning": query_features.parallelization_potential == "high"
                    })),
                },
                
                // 2. AgentèŠ‚ç‚¹ - æ‰§è¡Œè®¡åˆ’æ­¥éª¤
                WorkflowStep {
                    id: "agent".to_string(),
                    name: "æ‰§è¡Œä»£ç†".to_string(),
                    agent_type: "plan_and_execute".to_string(),
                    action: "execute_step".to_string(),
                    inputs: {
                        let mut inputs = HashMap::new();
                        inputs.insert("plan".to_string(), Value::String("{{planner.plan}}".to_string()));
                        inputs.insert("current_step".to_string(), Value::String("{{planner.plan_steps[planner.current_step_index]}}".to_string()));
                        inputs.insert("execution_context".to_string(), Value::String("{{execution_context}}".to_string()));
                        inputs.insert("custom_prompt".to_string(), Value::String(custom_prompts.executor.clone()));
                        inputs
                    },
                    outputs: {
                        let mut outputs = HashMap::new();
                        outputs.insert("step_result".to_string(), "step_result".to_string());
                        outputs.insert("execution_status".to_string(), "execution_status".to_string());
                        outputs.insert("step_outputs".to_string(), "step_outputs".to_string());
                        outputs.insert("next_step_index".to_string(), "next_step_index".to_string());
                        outputs
                    },
                    depends_on: vec!["planner".to_string()],
                    condition: None,
                    retry: Some(RetryConfig {
                        max_attempts: 2,
                        delay: 3,
                        backoff: BackoffStrategy::Fixed,
                        retry_on: vec!["execution_error".to_string(), "tool_error".to_string()],
                    }),
                    timeout: Some(1800), // 30åˆ†é’Ÿæ‰§è¡Œè¶…æ—¶
                    parallel: query_features.parallelization_potential == "high",
                    config: Some(serde_json::json!({
                        "enable_tool_calling": true,
                        "max_tool_calls_per_step": 5,
                        "enable_parallel_execution": query_features.parallelization_potential == "high"
                    })),
                },
                
                // 3. ReplanèŠ‚ç‚¹ - é‡æ–°è§„åˆ’å’Œå†³ç­–
                WorkflowStep {
                    id: "replan".to_string(),
                    name: "é‡è§„åˆ’å™¨".to_string(),
                    agent_type: "plan_and_execute".to_string(),
                    action: "replan_and_decide".to_string(),
                    inputs: {
                        let mut inputs = HashMap::new();
                        inputs.insert("original_plan".to_string(), Value::String("{{planner.plan}}".to_string()));
                        inputs.insert("execution_results".to_string(), Value::String("{{agent.step_result}}".to_string()));
                        inputs.insert("current_step_index".to_string(), Value::String("{{agent.next_step_index}}".to_string()));
                        inputs.insert("execution_status".to_string(), Value::String("{{agent.execution_status}}".to_string()));
                        inputs.insert("user_input".to_string(), Value::String(user_input.to_string()));
                        inputs.insert("custom_prompt".to_string(), Value::String(custom_prompts.planner.clone()));
                        inputs
                    },
                    outputs: {
                        let mut outputs = HashMap::new();
                        outputs.insert("should_continue".to_string(), "should_continue".to_string());
                        outputs.insert("updated_plan".to_string(), "updated_plan".to_string());
                        outputs.insert("next_action".to_string(), "next_action".to_string());
                        outputs.insert("completion_status".to_string(), "completion_status".to_string());
                        outputs.insert("final_result".to_string(), "final_result".to_string());
                        outputs
                    },
                    depends_on: vec!["agent".to_string()],
                    condition: None,
                    retry: Some(RetryConfig {
                        max_attempts: 2,
                        delay: 2,
                        backoff: BackoffStrategy::Fixed,
                        retry_on: vec!["decision_error".to_string()],
                    }),
                    timeout: Some(180),
                    parallel: false,
                    config: Some(serde_json::json!({
                        "max_replan_attempts": 3,
                        "enable_adaptive_planning": true,
                        "decision_threshold": 0.8
                    })),
                },
                
                // 4. æ¡ä»¶åˆ†æ”¯èŠ‚ç‚¹ - æ ¹æ®replanç»“æœå†³å®šä¸‹ä¸€æ­¥
                WorkflowStep {
                    id: "decision_branch".to_string(),
                    name: "å†³ç­–åˆ†æ”¯".to_string(),
                    agent_type: "workflow_controller".to_string(),
                    action: "conditional_branch".to_string(),
                    inputs: {
                        let mut inputs = HashMap::new();
                        inputs.insert("should_continue".to_string(), Value::String("{{replan.should_continue}}".to_string()));
                        inputs.insert("next_action".to_string(), Value::String("{{replan.next_action}}".to_string()));
                        inputs.insert("completion_status".to_string(), Value::String("{{replan.completion_status}}".to_string()));
                        inputs
                    },
                    outputs: {
                        let mut outputs = HashMap::new();
                        outputs.insert("branch_decision".to_string(), "branch_decision".to_string());
                        outputs.insert("workflow_status".to_string(), "workflow_status".to_string());
                        outputs
                    },
                    depends_on: vec!["replan".to_string()],
                    // æ¡ä»¶é€»è¾‘ï¼šå¦‚æœshould_continueä¸ºtrueï¼Œè¿”å›åˆ°agentèŠ‚ç‚¹ï¼›å¦åˆ™ç»“æŸ
                    condition: Some("{{replan.should_continue}} == true ? 'continue' : 'end'".to_string()),
                    retry: None,
                    timeout: Some(30),
                    parallel: false,
                    config: Some(serde_json::json!({
                        "continue_target": "agent",
                        "end_target": "__end__",
                        "max_iterations": 20
                    })),
                },
            ],
            variables: {
                let mut variables = HashMap::new();
                variables.insert("max_iterations".to_string(), Value::Number(serde_json::Number::from(20)));
                variables.insert("current_iteration".to_string(), Value::Number(serde_json::Number::from(0)));
                variables.insert("execution_context".to_string(), serde_json::json!({
                    "complexity_level": query_features.complexity_level,
                    "parallelization_potential": query_features.parallelization_potential,
                    "estimated_duration": self.estimate_duration(query_features)
                }));
                variables
            },
            error_handling: Some(ErrorHandling {
                default_strategy: ErrorStrategy::Retry,
                step_strategies: {
                    let mut strategies = HashMap::new();
                    strategies.insert("planner".to_string(), ErrorStrategy::Retry);
                    strategies.insert("agent".to_string(), ErrorStrategy::Continue);
                    strategies.insert("replan".to_string(), ErrorStrategy::Stop);
                    strategies.insert("decision_branch".to_string(), ErrorStrategy::Stop);
                    strategies
                },
                on_error: Some("log_and_notify".to_string()),
            }),
            notifications: Some(NotificationConfig {
                on_success: vec![NotificationTarget {
                    target_type: "log".to_string(),
                    config: serde_json::json!({"level": "info", "message": "Plan-Executeå·¥ä½œæµæ‰§è¡ŒæˆåŠŸ"}),
                }],
                on_failure: vec![NotificationTarget {
                    target_type: "log".to_string(),
                    config: serde_json::json!({"level": "error", "message": "Plan-Executeå·¥ä½œæµæ‰§è¡Œå¤±è´¥"}),
                }],
                on_progress: vec![NotificationTarget {
                    target_type: "log".to_string(),
                    config: serde_json::json!({"level": "debug", "message": "Plan-Executeå·¥ä½œæµæ‰§è¡Œè¿›åº¦æ›´æ–°"}),
                }],
            }),
        };
        
        Ok(workflow)
    }
    
    /// è®°å½•æ‰§è¡Œå†å²
    async fn record_execution(
        &self,
        query: &str,
        features: &QueryFeatures,
        selection: &ArchitectureSelection,
    ) {
        let record = ExecutionRecord {
            query: query.to_string(),
            features: features.clone(),
            selected_architecture: selection.selected_architecture.clone(),
            execution_time: 0,
            success_rate: 0.0,
            parallel_efficiency: 0.0,
            timestamp: Utc::now(),
        };
        
        let mut history = self.execution_history.write().await;
        history.push(record);
        // ä¿æŒæœ€è¿‘100æ¡è®°å½•
        if history.len() > 100 {
            history.remove(0);
        }
    }
    

    
    /// è·å–æ‰§è¡ŒçŠ¶æ€
    pub async fn get_execution_status(&self, execution_id: &str) -> Result<ExecutionStatus> {
        // ä»å·¥ä½œæµå¼•æ“è·å–æ‰§è¡ŒçŠ¶æ€
        match self.workflow_engine.get_execution_status(execution_id).await {
            Ok(status) => {
                Ok(ExecutionStatus {
                    execution_id: execution_id.to_string(),
                    request_id: execution_id.to_string(), // ç®€åŒ–å¤„ç†
                    status: format!("{:?}", status.status),
                    progress: status.progress.unwrap_or(0),
                    current_step: status.current_step.unwrap_or("æœªçŸ¥".to_string()),
                    completed_steps: status.completed_steps.unwrap_or(0),
                    total_steps: status.total_steps.unwrap_or(0),
                    started_at: status.started_at.to_rfc3339(),
                    completed_at: status.completed_at.map(|t| t.to_rfc3339()),
                    result: status.result,
                    error: status.error,
                })
            }
            Err(e) => Err(anyhow::anyhow!("è·å–æ‰§è¡ŒçŠ¶æ€å¤±è´¥: {}", e))
        }
    }
    
    /// è·å–æ‰§è¡Œå†å²
    pub async fn get_execution_history(
        &self,
        user_id: Option<&str>,
        architecture: Option<&str>,
        status: Option<&str>,
        page: u32,
        page_size: u32,
        start_time: Option<&str>,
        end_time: Option<&str>,
    ) -> Result<ExecutionHistoryResult> {
        let history = self.execution_history.read().await;
        
        // ç®€å•çš„è¿‡æ»¤å’Œåˆ†é¡µé€»è¾‘
        let mut filtered: Vec<_> = history.iter().collect();
        
        // æ ¹æ®æ¶æ„è¿‡æ»¤
        if let Some(arch) = architecture {
            filtered.retain(|record| record.selected_architecture == arch);
        }
        
        // åˆ†é¡µ
        let total = filtered.len() as u32;
        let start = ((page - 1) * page_size) as usize;
        let end = (start + page_size as usize).min(filtered.len());
        
        let records: Vec<ExecutionHistoryRecord> = filtered[start..end].iter().map(|record| {
            ExecutionHistoryRecord {
                request_id: Uuid::new_v4().to_string(),
                execution_id: Uuid::new_v4().to_string(),
                user_input: record.query.clone(),
                architecture: record.selected_architecture.clone(),
                task_type: record.features.task_type.clone(),
                complexity: record.features.complexity_level.clone(),
                status: "completed".to_string(),
                execution_time: record.execution_time,
                success_rate: record.success_rate,
                started_at: record.timestamp.to_rfc3339(),
                completed_at: Some(record.timestamp.to_rfc3339()),
            }
        }).collect();
        
        Ok(ExecutionHistoryResult {
            records,
            total,
            total_pages: (total + page_size - 1) / page_size,
        })
    }
    
    /// å–æ¶ˆæ‰§è¡Œ
    pub async fn cancel_execution(&mut self, execution_id: &str) -> Result<()> {
        // è°ƒç”¨å·¥ä½œæµå¼•æ“å–æ¶ˆæ‰§è¡Œ
        self.workflow_engine.cancel_execution(execution_id).await
            .map_err(|e| anyhow::anyhow!("å–æ¶ˆæ‰§è¡Œå¤±è´¥: {}", e))
    }
    
    /// è·å–ç»Ÿè®¡ä¿¡æ¯
    pub async fn get_statistics(&self) -> Result<DispatcherStats> {
        let history = self.execution_history.read().await;
        
        let total_requests = history.len() as u32;
        let successful_requests = history.iter().filter(|r| r.success_rate > 0.8).count() as u32;
        let failed_requests = total_requests - successful_requests;
        
        let average_execution_time = if !history.is_empty() {
            history.iter().map(|r| r.execution_time as f64).sum::<f64>() / history.len() as f64
        } else {
            0.0
        };
        
        let mut architecture_usage = HashMap::new();
        for record in history.iter() {
            *architecture_usage.entry(record.selected_architecture.clone()).or_insert(0) += 1;
        }
        
        Ok(DispatcherStats {
            total_requests,
            successful_requests,
            failed_requests,
            average_execution_time,
            architecture_usage,
            uptime_seconds: 0, // ç®€åŒ–å¤„ç†
        })
    }
}

/// æ‰§è¡ŒçŠ¶æ€ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExecutionStatus {
    pub execution_id: String,
    pub request_id: String,
    pub status: String,
    pub progress: u32,
    pub current_step: String,
    pub completed_steps: u32,
    pub total_steps: u32,
    pub started_at: String,
    pub completed_at: Option<String>,
    pub result: Option<String>,
    pub error: Option<String>,
}

/// æ‰§è¡Œå†å²ç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExecutionHistoryResult {
    pub records: Vec<ExecutionHistoryRecord>,
    pub total: u32,
    pub total_pages: u32,
}

/// æ‰§è¡Œå†å²è®°å½•
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExecutionHistoryRecord {
    pub request_id: String,
    pub execution_id: String,
    pub user_input: String,
    pub architecture: String,
    pub task_type: String,
    pub complexity: String,
    pub status: String,
    pub execution_time: u64,
    pub success_rate: f32,
    pub started_at: String,
    pub completed_at: Option<String>,
}

/// è°ƒåº¦å™¨ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DispatcherStats {
    pub total_requests: u32,
    pub successful_requests: u32,
    pub failed_requests: u32,
    pub average_execution_time: f64,
    pub architecture_usage: HashMap<String, u32>,
    pub uptime_seconds: u64,
}