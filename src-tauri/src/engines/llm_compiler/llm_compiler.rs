//! LLMCompiler Engine - æ™ºèƒ½å·¥å…·ç¼–æ’å¼•æ“
//!
//! åŸºäºLangGraph LLMCompileræ¶æ„å®ç°çš„æ™ºèƒ½å·¥å…·ç¼–æ’ç³»ç»Ÿ
//! è¿™æ˜¯ä¸»å¼•æ“æ–‡ä»¶ï¼Œè´Ÿè´£åè°ƒå„ä¸ªç»„ä»¶çš„å·¥ä½œ

use anyhow::Result;
use std::sync::Arc;
use tracing::{info, warn, error, debug};
use uuid::Uuid;
use chrono::Utc;

use crate::services::ai::AiService;
use crate::tools::ToolSystem;
use crate::services::database::DatabaseService;
use crate::services::prompt_db::PromptRepository;
use crate::models::prompt::{ArchitectureType, StageType};

use super::types::*;
use super::planner::LlmCompilerPlanner;
use super::task_fetcher::TaskFetchingUnit;
use super::executor::ParallelExecutorPool;
use super::joiner::IntelligentJoiner;

/// LLMCompilerå¼•æ“ - ä¸»åè°ƒå™¨
pub struct LlmCompilerEngine {
    /// Plannerç»„ä»¶ - æ™ºèƒ½è§„åˆ’å™¨
    planner: Arc<LlmCompilerPlanner>,
    /// Task Fetching Unit - ä»»åŠ¡è°ƒåº¦å•å…ƒ
    task_fetcher: Arc<TaskFetchingUnit>,
    /// Parallel Executor Pool - å¹¶è¡Œæ‰§è¡Œå™¨æ± 
    executor_pool: Arc<ParallelExecutorPool>,
    /// Intelligent Joiner - æ™ºèƒ½å†³ç­–å™¨
    joiner: Arc<tokio::sync::Mutex<IntelligentJoiner>>,
    /// AIæœåŠ¡ - ç”¨äºç”Ÿæˆæœ€ç»ˆå“åº”
    ai_service: Arc<AiService>,
    /// é…ç½®
    config: LlmCompilerConfig,
    /// åŠ¨æ€Promptä»“åº“
    prompt_repo: Option<PromptRepository>,
}

impl LlmCompilerEngine {
    /// åˆ›å»ºæ–°çš„LLMCompilerå¼•æ“å®ä¾‹
    pub fn new(
        ai_service: Arc<AiService>,
        tool_system: Arc<ToolSystem>,
        config: LlmCompilerConfig,
        db_service: Arc<DatabaseService>,
    ) -> Self {
        // åˆå§‹åŒ–å„ä¸ªç»„ä»¶
        let pool = db_service.get_pool().expect("DB pool not initialized");
        let planner = Arc::new(LlmCompilerPlanner::new(
            ai_service.clone(),
            tool_system.clone(),
            config.clone(),
            Some(PromptRepository::new(pool.clone())),
        ));
        
        let task_fetcher = Arc::new(TaskFetchingUnit::new(config.clone()));
        
        let executor_pool = Arc::new(ParallelExecutorPool::new(
            tool_system.clone(),
            config.clone(),
        ));
        
        let joiner = Arc::new(tokio::sync::Mutex::new(IntelligentJoiner::new(
            (*ai_service).clone(),
            config.clone(),
            Some(PromptRepository::new(pool.clone())),
        )));
        
        Self {
            planner,
            task_fetcher,
            executor_pool,
            joiner,
            ai_service,
            config,
            prompt_repo: Some(PromptRepository::new(pool.clone())),
        }
    }

    /// æ‰§è¡Œå·¥ä½œæµ - ä¸»å…¥å£ç‚¹
    pub async fn execute_workflow(
        &self,
        user_query: &str,
        context: Option<std::collections::HashMap<String, serde_json::Value>>,
    ) -> Result<WorkflowExecutionResult> {
        info!("å¼€å§‹æ‰§è¡ŒLLMCompilerå·¥ä½œæµ: {}", user_query);
        
        let context = context.unwrap_or_default();
        let mut execution_summary = ExecutionSummary {
            total_tasks: 0,
            successful_tasks: 0,
            failed_tasks: 0,
            total_duration_ms: 0,
            replanning_count: 0,
            key_findings: Vec::new(),
            efficiency_metrics: EfficiencyMetrics {
                average_parallelism: 0.0,
                resource_utilization: 0.0,
                task_success_rate: 0.0,
                average_task_duration_ms: 0.0,
            },
        };
        
        let workflow_start = std::time::Instant::now();
        let mut current_plan: Option<DagExecutionPlan> = None;
        let mut all_results: Vec<TaskExecutionResult> = Vec::new();
        
        // ä¸»æ‰§è¡Œå¾ªç¯
        for round in 1..=self.config.max_iterations {
            info!("å¼€å§‹æ‰§è¡Œè½®æ¬¡: {}/{}", round, self.config.max_iterations);
            // æ›´æ–°æ€»è½®æ¬¡ï¼ˆè¿™é‡Œç”¨replanning_countæ¥è·Ÿè¸ªï¼‰
            if round > 1 {
                execution_summary.replanning_count = round - 1;
            }
            
            // 1. è§„åˆ’é˜¶æ®µ
            let execution_plan = if let Some(ref plan) = current_plan {
                // å¦‚æœæœ‰ç°æœ‰è®¡åˆ’ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è§„åˆ’
                if self.config.enable_replanning && round > 1 {
                    info!("æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è§„åˆ’...");
                    // è¿™é‡Œå¯ä»¥æ·»åŠ é‡æ–°è§„åˆ’çš„é€»è¾‘
                    plan.clone()
                } else {
                    plan.clone()
                }
            } else {
                // ç”Ÿæˆåˆå§‹è®¡åˆ’
                info!("ç”Ÿæˆåˆå§‹æ‰§è¡Œè®¡åˆ’...");
                let plan = self.planner.generate_dag_plan(user_query, &context).await?;
                current_plan = Some(plan.clone());
                plan
            };
            
            info!("æ‰§è¡Œè®¡åˆ’åŒ…å« {} ä¸ªä»»åŠ¡", execution_plan.nodes.len());
            
            // 2. ä»»åŠ¡è°ƒåº¦é˜¶æ®µ
            self.task_fetcher.initialize_plan(&execution_plan).await?;
            
            // 3. å¹¶è¡Œæ‰§è¡Œé˜¶æ®µ
            let round_results = self.execute_parallel_round().await?;
            
            if round_results.is_empty() {
                warn!("è½®æ¬¡ {} æ²¡æœ‰æ‰§è¡Œä»»ä½•ä»»åŠ¡", round);
                break;
            }
            
            // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            let completed_count = round_results.iter().filter(|r| r.status == TaskStatus::Completed).count();
            let failed_count = round_results.iter().filter(|r| r.status == TaskStatus::Failed).count();
            
            execution_summary.successful_tasks += completed_count;
            execution_summary.failed_tasks += failed_count;
            execution_summary.total_tasks += round_results.len();
            
            let round_duration: u64 = round_results.iter().map(|r| r.duration_ms).sum();
            execution_summary.total_duration_ms += round_duration;
            
            all_results.extend(round_results.clone());
            
            info!(
                "è½®æ¬¡ {} å®Œæˆ: æˆåŠŸ {} ä¸ªä»»åŠ¡, å¤±è´¥ {} ä¸ªä»»åŠ¡, è€—æ—¶ {}ms",
                round, completed_count, failed_count, round_duration
            );
            
            // 4. æ™ºèƒ½å†³ç­–é˜¶æ®µ
            let mut joiner = self.joiner.lock().await;
            let decision = joiner.analyze_and_decide(
                user_query,
                &execution_plan,
                &round_results,
                round,
            ).await?;
            
            // è®°å½•å†³ç­–ä¿¡æ¯ï¼ˆå¯ä»¥æ·»åŠ åˆ°key_findingsä¸­ï¼‰
            match &decision {
                JoinerDecision::Complete { response, .. } => {
                    execution_summary.key_findings.push(format!("å†³ç­–: å®Œæˆæ‰§è¡Œ - {}", response));
                }
                JoinerDecision::Continue { feedback, .. } => {
                    execution_summary.key_findings.push(format!("å†³ç­–: ç»§ç»­æ‰§è¡Œ - {}", feedback));
                }
            }
            
            match decision {
                JoinerDecision::Complete { response, .. } => {
                    info!("Joinerå†³å®šå®Œæˆæ‰§è¡Œ: {}", response);
                    break;
                }
                JoinerDecision::Continue { feedback, .. } => {
                    info!("Joinerå†³å®šç»§ç»­æ‰§è¡Œ: {}", feedback);
                    // ç»§ç»­ä¸‹ä¸€è½®
                }
            }
            
            // æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¾…æ‰§è¡Œçš„ä»»åŠ¡
            if !self.task_fetcher.has_pending_tasks().await {
                info!("æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œç»“æŸæ‰§è¡Œ");
                break;
            }
        }
        
        let total_duration = workflow_start.elapsed();
        execution_summary.total_duration_ms = total_duration.as_millis() as u64;
        
        // è®¡ç®—æœ€ç»ˆæ•ˆç‡æŒ‡æ ‡
        execution_summary.efficiency_metrics = self.calculate_efficiency_metrics(&execution_summary);
        
        info!(
            "å·¥ä½œæµæ‰§è¡Œå®Œæˆ: {} ä¸ªä»»åŠ¡, æˆåŠŸ {}, å¤±è´¥ {}, è€—æ—¶ {}ms",
            execution_summary.total_tasks,
            execution_summary.successful_tasks,
            execution_summary.failed_tasks,
            execution_summary.total_duration_ms
        );
        
        // ç”Ÿæˆæœ€ç»ˆç»“æœ
        let final_response = self.generate_final_response(
            user_query,
            &all_results,
            &execution_summary,
        ).await?;
        
        Ok(WorkflowExecutionResult {
            success: true,
            response: final_response,
            execution_summary: execution_summary.clone(),
            task_results: all_results,
            efficiency_metrics: execution_summary.efficiency_metrics,
            error: None,
        })
    }

    /// æ‰§è¡Œä¸€è½®å¹¶è¡Œä»»åŠ¡
    async fn execute_parallel_round(&self) -> Result<Vec<TaskExecutionResult>> {
        let mut results = Vec::new();
        
        // è·å–æ‰€æœ‰å°±ç»ªçš„ä»»åŠ¡
        let ready_tasks = self.task_fetcher.fetch_ready_tasks(self.config.max_concurrency).await;
        
        if ready_tasks.is_empty() {
            return Ok(results);
        }
        
        info!("å¼€å§‹å¹¶è¡Œæ‰§è¡Œ {} ä¸ªå°±ç»ªä»»åŠ¡", ready_tasks.len());
        
        // æ ‡è®°ä»»åŠ¡ä¸ºæ‰§è¡Œä¸­å¹¶å¯åŠ¨æ‰§è¡Œ
        let mut handles = Vec::new();
        for task in ready_tasks {
            let executor = self.executor_pool.clone();
            let handle = tokio::spawn(async move {
                executor.execute_task(task).await
            });
            handles.push(handle);
        }
        
        // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for handle in handles {
            match handle.await {
                Ok(result) => {
                    // æ›´æ–°ä»»åŠ¡çŠ¶æ€
                    self.task_fetcher.complete_task(result.clone()).await?;
                    results.push(result);
                }
                Err(e) => {
                    error!("ä»»åŠ¡æ‰§è¡Œå¥æŸ„é”™è¯¯: {}", e);
                }
            }
        }
        
        Ok(results)
    }

    /// ç”Ÿæˆæœ€ç»ˆå“åº”
    async fn generate_final_response(
        &self,
        user_query: &str,
        task_results: &[TaskExecutionResult],
        execution_summary: &ExecutionSummary,
    ) -> Result<String> {
        // æ”¶é›†æ‰€æœ‰æˆåŠŸä»»åŠ¡çš„è¾“å‡º
        let successful_outputs: Vec<&std::collections::HashMap<String, serde_json::Value>> = task_results
            .iter()
            .filter(|r| r.status == TaskStatus::Completed)
            .map(|r| &r.outputs)
            .collect();
        
        if successful_outputs.is_empty() {
            return Ok("æŠ±æ­‰ï¼Œæ²¡æœ‰æˆåŠŸæ‰§è¡Œä»»ä½•ä»»åŠ¡ï¼Œæ— æ³•æä¾›æœ‰æ•ˆç»“æœã€‚".to_string());
        }
        
        // æ„å»ºå“åº”ç”Ÿæˆæç¤º
        // æŠ¥å‘Šç”Ÿæˆ Promptï¼šä¼˜å…ˆä»åŠ¨æ€æ¨¡æ¿(LLMCompiler/Report or Execution)è·å–
        let response_prompt = if let Some(repo) = &self.prompt_repo {
            if let Ok(Some(dynamic)) = repo.get_active_prompt(ArchitectureType::LLMCompiler, StageType::Execution).await {
                dynamic
            } else {
                self.build_default_response_prompt(user_query, &successful_outputs, execution_summary)
            }
        } else {
            self.build_default_response_prompt(user_query, &successful_outputs, execution_summary)
        };
        
        // è°ƒç”¨AIç”Ÿæˆæœ€ç»ˆå“åº”
        info!("å¼€å§‹è°ƒç”¨AIç”Ÿæˆæœ€ç»ˆå“åº”ï¼Œæç¤ºè¯é•¿åº¦: {} å­—ç¬¦", response_prompt.len());
        debug!("AIå“åº”ç”Ÿæˆæç¤ºè¯: {}", response_prompt);
        
        match self.ai_service.send_message_stream_with_prompt(&response_prompt, None, None).await {
            Ok(ai_response) => {
                if ai_response.trim().is_empty() {
                    warn!("AIè¿”å›äº†ç©ºå“åº”ï¼Œä½¿ç”¨é»˜è®¤å“åº”");
                    Ok(self.generate_default_response(task_results, execution_summary))
                } else {
                    info!("AIå“åº”ç”ŸæˆæˆåŠŸï¼Œå“åº”é•¿åº¦: {} å­—ç¬¦", ai_response.len());
                    Ok(ai_response)
                }
            }
            Err(e) => {
                error!("AIå“åº”ç”Ÿæˆå¤±è´¥: {}, ä½¿ç”¨é»˜è®¤å“åº”", e);
                Ok(self.generate_default_response(task_results, execution_summary))
            }
        }
    }

    fn build_default_response_prompt(
        &self,
        user_query: &str,
        successful_outputs: &[&std::collections::HashMap<String, serde_json::Value>],
        execution_summary: &ExecutionSummary,
    ) -> String {
        format!(
            r#"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®‰å…¨åˆ†æä¸“å®¶ï¼Œè¯·åŸºäºä»¥ä¸‹LLMCompilerå·¥ä½œæµæ‰§è¡Œç»“æœï¼Œä¸ºç”¨æˆ·æŸ¥è¯¢ç”Ÿæˆä¸€ä¸ªå®Œæ•´ã€å‡†ç¡®ã€ä¸“ä¸šçš„åˆ†ææŠ¥å‘Šã€‚

**ç”¨æˆ·æŸ¥è¯¢**: {}

**æ‰§è¡Œç»Ÿè®¡**:
- æ€»ä»»åŠ¡æ•°: {}
- æˆåŠŸä»»åŠ¡: {}
- å¤±è´¥ä»»åŠ¡: {}
- æ€»è€—æ—¶: {}ms
- ä»»åŠ¡æˆåŠŸç‡: {:.1}%

**æ‰§è¡Œç»“æœè¯¦æƒ…**:
{}

{}"#,
            user_query,
            execution_summary.total_tasks,
            execution_summary.successful_tasks,
            execution_summary.failed_tasks,
            execution_summary.total_duration_ms,
            if execution_summary.total_tasks > 0 {
                (execution_summary.successful_tasks as f32 / execution_summary.total_tasks as f32) * 100.0
            } else {
                0.0
            },
            self.format_outputs_for_response(&successful_outputs),
            if execution_summary.failed_tasks > 0 {
                format!("\n## âŒ æ‰§è¡Œé—®é¢˜\næœ¬æ¬¡æ‰§è¡Œä¸­æœ‰ {} ä¸ªä»»åŠ¡å¤±è´¥ï¼Œè¯·åœ¨æŠ¥å‘Šä¸­è¯´æ˜å¯èƒ½çš„åŸå› å’Œå½±å“ã€‚", execution_summary.failed_tasks)
            } else {
                String::new()
            }
        )
    }

    /// æ ¼å¼åŒ–è¾“å‡ºç”¨äºå“åº”ç”Ÿæˆ
    fn format_outputs_for_response(
        &self,
        outputs: &[&std::collections::HashMap<String, serde_json::Value>],
    ) -> String {
        if outputs.is_empty() {
            return "æš‚æ— æˆåŠŸæ‰§è¡Œçš„ä»»åŠ¡è¾“å‡º".to_string();
        }

        outputs
            .iter()
            .enumerate()
            .map(|(i, output)| {
                let mut formatted_output = Vec::new();
                
                // æ ¼å¼åŒ–æ¯ä¸ªè¾“å‡ºå­—æ®µ
                for (key, value) in output.iter() {
                    let formatted_value = match value {
                        serde_json::Value::String(s) => s.clone(),
                        serde_json::Value::Number(n) => n.to_string(),
                        serde_json::Value::Bool(b) => b.to_string(),
                        serde_json::Value::Array(arr) => {
                            if arr.len() <= 5 {
                                format!("[{}]", arr.iter()
                                    .map(|v| match v {
                                        serde_json::Value::String(s) => s.clone(),
                                        _ => v.to_string()
                                    })
                                    .collect::<Vec<_>>()
                                    .join(", "))
                            } else {
                                format!("[{} ä¸ªé¡¹ç›®]", arr.len())
                            }
                        },
                        serde_json::Value::Object(_) => "[å¯¹è±¡æ•°æ®]".to_string(),
                        serde_json::Value::Null => "null".to_string(),
                    };
                    
                    formatted_output.push(format!("  - {}: {}", key, formatted_value));
                }
                
                format!(
                    "### ä»»åŠ¡ {}\n{}",
                    i + 1,
                    formatted_output.join("\n")
                )
            })
            .collect::<Vec<_>>()
            .join("\n\n")
    }

    /// ç”Ÿæˆé»˜è®¤å“åº”ï¼ˆå½“AIå“åº”å¤±è´¥æ—¶ï¼‰
    fn generate_default_response(
        &self,
        task_results: &[TaskExecutionResult],
        execution_summary: &ExecutionSummary,
    ) -> String {
        let successful_tasks = task_results.iter().filter(|r| r.status == TaskStatus::Completed).count();
        let failed_tasks = task_results.iter().filter(|r| r.status == TaskStatus::Failed).count();
        
        format!(
            "æ‰§è¡Œå®Œæˆï¼\n\n\
            ğŸ“Š æ‰§è¡Œç»Ÿè®¡:\n\
            - æ€»ä»»åŠ¡: {}\n\
            - æˆåŠŸä»»åŠ¡: {}\n\
            - å¤±è´¥ä»»åŠ¡: {}\n\
            - æ€»è€—æ—¶: {}ms\n\n\
            ğŸ“‹ ä¸»è¦ç»“æœ:\n\
            {}\n\n\
            {}",
            execution_summary.total_tasks,
            successful_tasks,
            failed_tasks,
            execution_summary.total_duration_ms,
            self.summarize_task_outputs(task_results),
            if failed_tasks > 0 {
                "âš ï¸ éƒ¨åˆ†ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥è¾“å…¥å‚æ•°æˆ–ç½‘ç»œè¿æ¥ã€‚"
            } else {
                "âœ… æ‰€æœ‰ä»»åŠ¡æ‰§è¡ŒæˆåŠŸï¼"
            }
        )
    }

    /// æ€»ç»“ä»»åŠ¡è¾“å‡º
    fn summarize_task_outputs(&self, task_results: &[TaskExecutionResult]) -> String {
        let mut summaries = Vec::new();
        
        for result in task_results {
            if result.status == TaskStatus::Completed {
                let summary = if let Some(result_value) = result.outputs.get("result") {
                    format!("- {}: {}", result.task_id, result_value)
                } else {
                    format!("- {}: æ‰§è¡ŒæˆåŠŸ", result.task_id)
                };
                summaries.push(summary);
            } else if result.status == TaskStatus::Failed {
                let error_msg = result.error.as_deref().unwrap_or("æœªçŸ¥é”™è¯¯");
                summaries.push(format!("- {}: æ‰§è¡Œå¤±è´¥ - {}", result.task_id, error_msg));
            }
        }
        
        if summaries.is_empty() {
            "æ— å¯ç”¨ç»“æœ".to_string()
        } else {
            summaries.join("\n")
        }
    }

    /// è®¡ç®—æ•ˆç‡æŒ‡æ ‡
    fn calculate_efficiency_metrics(&self, execution_summary: &ExecutionSummary) -> EfficiencyMetrics {
        let total_tasks = execution_summary.total_tasks;
        
        let task_success_rate = if total_tasks > 0 {
            execution_summary.successful_tasks as f32 / total_tasks as f32
        } else {
            0.0
        };
        
        let average_task_duration_ms = if execution_summary.successful_tasks > 0 {
            execution_summary.total_duration_ms as f32 / execution_summary.successful_tasks as f32
        } else {
            0.0
        };
        
        // ç®€åŒ–çš„å¹¶è¡Œæ•ˆç‡è®¡ç®—ï¼ˆåŸºäºé‡è§„åˆ’æ¬¡æ•°+1ä½œä¸ºè½®æ¬¡ï¼‰
        let total_rounds = execution_summary.replanning_count + 1;
        let average_parallelism = if total_rounds > 0 {
            total_tasks as f32 / total_rounds as f32
        } else {
            0.0
        }.min(self.config.max_concurrency as f32);
        
        let resource_utilization = if self.config.max_concurrency > 0 {
            average_parallelism / self.config.max_concurrency as f32
        } else {
            0.0
        }.min(1.0);
        
        EfficiencyMetrics {
            average_parallelism,
            resource_utilization,
            task_success_rate,
            average_task_duration_ms,
        }
    }

    /// è·å–å¼•æ“çŠ¶æ€
    pub async fn get_engine_status(&self) -> EngineStatus {
        let task_stats = self.task_fetcher.get_execution_stats().await;
        // æš‚æ—¶æ³¨é‡Šæ‰ç§æœ‰ç±»å‹çš„è°ƒç”¨
        // let executor_metrics = self.executor_pool.get_execution_metrics().await;
        
        EngineStatus {
            is_running: task_stats.executing_tasks > 0,
            pending_tasks: task_stats.waiting_tasks + task_stats.ready_tasks,
            executing_tasks: task_stats.executing_tasks,
            completed_tasks: task_stats.completed_tasks,
            failed_tasks: task_stats.failed_tasks,
            available_capacity: self.executor_pool.available_permits(),
            total_capacity: self.config.max_concurrency,
        }
    }

    /// å–æ¶ˆå½“å‰æ‰§è¡Œ
    pub async fn cancel_execution(&self) -> Result<()> {
        info!("å–æ¶ˆå½“å‰æ‰§è¡Œ");
        self.task_fetcher.cancel_pending_tasks().await?;
        Ok(())
    }

    /// é‡ç½®å¼•æ“çŠ¶æ€
    pub async fn reset(&self) -> Result<()> {
        info!("é‡ç½®å¼•æ“çŠ¶æ€");
        // æ¸…ç©ºä»»åŠ¡é˜Ÿåˆ—
        self.task_fetcher.cancel_pending_tasks().await?;
        // æ³¨æ„ï¼šjoineræ²¡æœ‰resetæ–¹æ³•ï¼Œè¿™é‡Œå¯ä»¥é‡æ–°åˆ›å»ºæˆ–è€…æ·»åŠ resetæ–¹æ³•
        Ok(())
    }
}

/// å·¥ä½œæµæ‰§è¡Œç»“æœ
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct WorkflowExecutionResult {
    /// æ˜¯å¦æˆåŠŸ
    pub success: bool,
    /// æœ€ç»ˆå“åº”
    pub response: String,
    /// æ‰§è¡Œæ‘˜è¦
    pub execution_summary: ExecutionSummary,
    /// ä»»åŠ¡ç»“æœåˆ—è¡¨
    pub task_results: Vec<TaskExecutionResult>,
    /// æ•ˆç‡æŒ‡æ ‡
    pub efficiency_metrics: EfficiencyMetrics,
    /// é”™è¯¯ä¿¡æ¯
    pub error: Option<String>,
}

/// å¼•æ“çŠ¶æ€
#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct EngineStatus {
    /// æ˜¯å¦æ­£åœ¨è¿è¡Œ
    pub is_running: bool,
    /// å¾…æ‰§è¡Œä»»åŠ¡æ•°
    pub pending_tasks: usize,
    /// æ‰§è¡Œä¸­ä»»åŠ¡æ•°
    pub executing_tasks: usize,
    /// å·²å®Œæˆä»»åŠ¡æ•°
    pub completed_tasks: usize,
    /// å¤±è´¥ä»»åŠ¡æ•°
    pub failed_tasks: usize,
    /// å¯ç”¨æ‰§è¡Œå®¹é‡
    pub available_capacity: usize,
    /// æ€»æ‰§è¡Œå®¹é‡
    pub total_capacity: usize,
}