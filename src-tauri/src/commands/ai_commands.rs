//! AIç›¸å…³å‘½ä»¤æ•´åˆæ¨¡å—
//!
//! æ•´åˆäº†æ™ºèƒ½è°ƒåº¦å™¨å’ŒAIåŠ©æ‰‹çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
//! - æ™ºèƒ½æŸ¥è¯¢è°ƒåº¦
//! - æ‰§è¡Œç›‘æ§
//! - æ¶æ„ç®¡ç†
//! - Agentç»Ÿè®¡

use crate::services::{AiServiceManager, database::{Database, DatabaseService}};
use crate::engines::plan_and_execute::engine_adapter::PlanAndExecuteEngine;
use crate::engines::llm_compiler::engine_adapter::LlmCompilerEngine;
use crate::engines::llm_compiler::types::LlmCompilerConfig;
use crate::engines::plan_and_execute::types::PlanAndExecuteConfig;  
use crate::engines::rewoo::engine_adapter::ReWooEngine;
use crate::engines::rewoo::rewoo_types::ReWOOConfig;
// use crate::engines::orchestrator::engine_adapter::OrchestratorEngineAdapter; // Orchestratorå·²åˆ é™¤
// use crate::engines::plan_and_execute::executor::ExecutionMode; // not needed directly
use crate::agents::traits::{ExecutionEngine, AgentTask, TaskPriority};
use sentinel_core::models::agent::{AgentTask as CoreAgentTask, TaskPriority as CoreTaskPriority, AgentExecutionResult as CoreAgentExecutionResult, SessionLog as CoreSessionLog};
use futures::StreamExt;
use sentinel_core::models::scenario_agent::{ScenarioAgentProfile, AgentEngine};

/// åˆ›å»ºAIåŠ©æ‰‹ä¼šè¯è®°å½•
async fn create_ai_assistant_session(
    db_service: &Arc<DatabaseService>,
    execution_id: &str,
    agent_name: &str,
    task_description: &str,
) -> Result<(), String> {
    use crate::services::database::Database;

    // åˆ›å»ºtask_id
    let task_id = format!("{}_task", execution_id);

    // å…ˆåˆ›å»ºagent_taskè®°å½•ï¼ˆå› ä¸ºagent_sessionsè¡¨æœ‰å¤–é”®çº¦æŸï¼‰
    let agent_task = crate::agents::traits::AgentTask {
        id: task_id.clone(),
        user_id: "ai_assistant".to_string(),
        description: task_description.to_string(),
        priority: crate::agents::traits::TaskPriority::Normal,
        target: None,
        parameters: std::collections::HashMap::new(),
        timeout: Some(300),
    };

    let db_task = CoreAgentTask {
        id: agent_task.id.clone(),
        description: agent_task.description.clone(),
        target: agent_task.target.clone(),
        parameters: agent_task.parameters.clone(),
        user_id: agent_task.user_id.clone(),
        priority: match agent_task.priority {
            TaskPriority::Low => CoreTaskPriority::Low,
            TaskPriority::Normal => CoreTaskPriority::Normal,
            TaskPriority::High => CoreTaskPriority::High,
            TaskPriority::Critical => CoreTaskPriority::Critical,
        },
        timeout: agent_task.timeout,
    };

    db_service.create_agent_task(&db_task).await
        .map_err(|e| format!("Failed to create agent task: {}", e))?;

    // ç„¶ååˆ›å»ºagent_sessionè®°å½•
    db_service.create_agent_session(execution_id, &task_id, agent_name).await
        .map_err(|e| format!("Failed to create agent session: {}", e))?;

    Ok(())
}

/// ä¿å­˜AIåŠ©æ‰‹æ‰§è¡Œè®°å½•åˆ°æ•°æ®åº“
async fn save_ai_assistant_execution(
    db_service: &Arc<DatabaseService>,
    execution_id: &str,
    _task_name: &str,
    architecture: &str,
    success: bool,
    error: Option<&str>,
    result: Option<&str>,
    started_at: u64,
    completed_at: u64,
    duration_ms: u64,
) -> Result<(), String> {
    use crate::services::database::Database;
use sentinel_core::models::workflow::WorkflowStepDetail;

    // ä¿å­˜æ‰§è¡Œæ­¥éª¤åˆ° agent_execution_steps è¡¨
    let step_detail = WorkflowStepDetail {
        step_id: "step_1".to_string(),
        step_name: format!("AI Assistant Task ({})", architecture),
        status: if success { "Completed".to_string() } else { "Failed".to_string() },
        started_at: Some(started_at.to_string()),
        completed_at: Some(completed_at.to_string()),
        duration_ms,
        result_data: result.map(|r| serde_json::json!(r)),
        error: error.map(|e| e.to_string()),
        retry_count: 0,
        dependencies: vec![],
        tool_result: None,
    };

    db_service.save_agent_execution_step(execution_id, &step_detail).await
        .map_err(|e| format!("Failed to save execution step: {}", e))?;

    // æ›´æ–°sessionçŠ¶æ€
    let status_str = if success { "Completed" } else { "Failed" };
    if let Err(e) = db_service.update_agent_session_status(execution_id, status_str).await {
        log::warn!("Failed to update agent session status: {}", e);
    }

    Ok(())
}



use tauri::{AppHandle, State, Emitter, Manager};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use std::collections::HashMap;
use uuid::Uuid;
use anyhow::Result;
use log::{info, warn};

/// å‘½ä»¤å“åº”åŒ…è£…å™¨
#[derive(Debug, Serialize)]
pub struct CommandResponse<T> {
    pub success: bool,
    pub data: Option<T>,
    pub error: Option<String>,
    pub timestamp: u64,
    pub request_id: String,
}

impl<T> CommandResponse<T> {
    pub fn success(data: T) -> Self {
        Self {
            success: true,
            data: Some(data),
            error: None,
            timestamp: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap_or_default()
                .as_secs(),
            request_id: Uuid::new_v4().to_string(),
        }
    }

    pub fn error(message: String) -> Self {
        Self {
            success: false,
            data: None,
            error: Some(message),
            timestamp: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap_or_default()
                .as_secs(),
            request_id: Uuid::new_v4().to_string(),
        }
    }
}

// ===== æ™ºèƒ½è°ƒåº¦å™¨ç›¸å…³ç»“æ„ä½“ =====


#[derive(Debug, Serialize)]
pub struct IntelligentQueryResponse {
    pub request_id: String,
    pub execution_id: String,
    pub selected_architecture: String,
    pub task_type: String,
    pub complexity: String,
    pub reasoning: String,
    pub confidence: f32,
    pub estimated_duration: Option<f64>,
    pub workflow_status: String,
    pub started_at: String,
}

#[derive(Debug, Deserialize)]
pub struct ExecutionStatusRequest {
    pub id: String,
    pub id_type: String,
}

#[derive(Debug, Serialize)]
pub struct ExecutionStatusResponse {
    pub execution_id: String,
    pub request_id: String,
    pub status: String,
    pub progress: f32,
    pub current_step: Option<String>,
    pub completed_steps: u32,
    pub total_steps: u32,
    pub started_at: String,
    pub completed_at: Option<String>,
    pub result: Option<serde_json::Value>,
    pub error: Option<String>,
}

#[derive(Debug, Deserialize)]
pub struct ExecutionHistoryRequest {
    pub user_id: Option<String>,
    pub architecture: Option<String>,
    pub status: Option<String>,
    pub page: Option<u32>,
    pub page_size: Option<u32>,
    pub start_time: Option<String>,
    pub end_time: Option<String>,
}

#[derive(Debug, Serialize)]
pub struct ExecutionHistoryResponse {
    pub records: Vec<ExecutionHistoryItem>,
    pub total: u32,
    pub page: u32,
    pub page_size: u32,
    pub total_pages: u32,
}

#[derive(Debug, Serialize)]
pub struct ExecutionHistoryItem {
    pub request_id: String,
    pub execution_id: String,
    pub user_input: String,
    pub architecture: String,
    pub task_type: String,
    pub complexity: String,
    pub status: String,
    pub execution_time: Option<f64>,
    pub success_rate: Option<f32>,
    pub started_at: String,
    pub completed_at: Option<String>,
}

#[derive(Debug, Serialize)]
pub struct DispatcherStatistics {
    pub total_requests: f64,
    pub successful_requests: f64,
    pub failed_requests: f64,
    pub average_execution_time: f64,
    pub architecture_usage: HashMap<String, f64>,
    pub uptime_seconds: f64,
}

// ===== AIåŠ©æ‰‹ç›¸å…³ç»“æ„ä½“ =====

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DispatchQueryRequest {
    pub query: String,
    pub architecture: String,
    pub agent_id: Option<String>,
    pub options: Option<HashMap<String, serde_json::Value>>,
    pub conversation_id: Option<String>,
    pub message_id: Option<String>,
}




#[derive(Debug, Serialize, Deserialize)]
pub struct DispatchResult {
    pub execution_id: String,
    pub initial_response: String,
    pub execution_plan: Option<ExecutionPlanView>,
    pub estimated_duration: u64,
    pub selected_architecture: String,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct ExecutionPlanView {
    pub id: String,
    pub name: String,
    pub description: String,
    pub steps: Vec<ExecutionStepView>,
    pub estimated_duration: u64,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct ExecutionStepView {
    pub id: String,
    pub name: String,
    pub description: String,
    pub status: String,
    pub estimated_duration: u64,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct AIAssistantSettings {
    #[serde(default)]
    pub auto_execute: bool,
    #[serde(default = "default_notification_enabled")]
    pub notification_enabled: bool,
}

fn default_notification_enabled() -> bool {
    true
}

// ===== åœºæ™¯ Agent Profileï¼ˆæœ€å°å¯ç”¨ç‰ˆæœ¬ï¼‰=====


// Expose tools catalog for agent configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SimpleToolInfo {
    pub name: String,
    pub title: Option<String>,
    pub category: Option<String>,
    pub description: Option<String>,
    pub available: bool,
    pub source: Option<String>,
    pub group: Option<String>,
}

#[tauri::command]
pub async fn list_unified_tools(
    tool_system: State<'_, Arc<crate::tools::ToolSystem>>,
) -> Result<Vec<SimpleToolInfo>, String> {
    let tools = tool_system.list_tools().await;
    let list = tools
        .into_iter()
        .map(|t| SimpleToolInfo {
            name: t.name,
            title: None, // ToolMetadata æ²¡æœ‰é€šç”¨ title å­—æ®µï¼Œè¿™é‡Œä¸ºç©º
            category: Some(t.category.to_string()),
            description: if t.description.is_empty() { None } else { Some(t.description) },
            available: t.available,
            source: {
                // ä¼˜å…ˆç”¨metadata.tagsåˆ¤æ–­mcpï¼Œå¦åˆ™fallback
                let tag_has_mcp = t.metadata.tags.iter().any(|x| x == "mcp");
                Some(if tag_has_mcp { "mcp".to_string() } else { "builtin".to_string() })
            },
            group: t.metadata.tags.iter()
                .find_map(|tag| tag.strip_prefix("connection:").map(|s| s.to_string())),
        })
        .collect();
    Ok(list)
}

// åˆ†ç»„è¿”å›ï¼šå†…ç½®å·¥å…· + MCPæŒ‰è¿æ¥åˆ†ç»„
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct McpToolGroup { pub connection: String, pub tools: Vec<SimpleToolInfo> }

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GroupedToolsResponse { pub builtin: Vec<SimpleToolInfo>, pub mcp: Vec<McpToolGroup> }

#[tauri::command]
pub async fn list_unified_tools_grouped(
    tool_system: State<'_, Arc<crate::tools::ToolSystem>>,
) -> Result<GroupedToolsResponse, String> {
    let tools = tool_system.list_tools().await;
    let mut builtin: Vec<SimpleToolInfo> = Vec::new();
    let mut groups: std::collections::HashMap<String, Vec<SimpleToolInfo>> = std::collections::HashMap::new();

    for t in tools.into_iter() {
        // è·³è¿‡æ’ä»¶å·¥å…·ï¼ˆåç§°ä»¥ plugin:: å¼€å¤´æˆ–åŒ…å« plugin æ ‡ç­¾ï¼‰
        // æ’ä»¶å·¥å…·åº”è¯¥é€šè¿‡ list_plugins æ¥å£å•ç‹¬ç®¡ç†
        let is_plugin = t.name.starts_with("plugin::") || t.metadata.tags.iter().any(|x| x == "plugin");
        if is_plugin {
            continue;
        }

        let is_mcp = t.metadata.tags.iter().any(|x| x == "mcp");
        let group = t.metadata.tags.iter()
            .find_map(|tag| tag.strip_prefix("connection:").map(|s| s.to_string()));
        let item = SimpleToolInfo {
            name: t.name,
            title: None,
            category: Some(t.category.to_string()),
            description: if t.description.is_empty() { None } else { Some(t.description) },
            available: t.available,
            source: Some(if is_mcp { "mcp".to_string() } else { "builtin".to_string() }),
            group: group.clone(),
        };

        if is_mcp {
            let key = group.unwrap_or_else(|| "unknown".to_string());
            groups.entry(key).or_default().push(item);
        } else {
            builtin.push(item);
        }
    }

    let mut mcp: Vec<McpToolGroup> = groups.into_iter()
        .map(|(k, v)| McpToolGroup { connection: k, tools: v })
        .collect();
    // ç¨³å®šæ’åºè¿æ¥å
    mcp.sort_by(|a, b| a.connection.cmp(&b.connection));

    Ok(GroupedToolsResponse { builtin, mcp })
}

#[tauri::command]
pub async fn list_scenario_agents(
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<Vec<ScenarioAgentProfile>, String> {
    db_service
        .list_scenario_agents()
        .await
        .map_err(|e| format!("Failed to load scenario agents: {}", e))
}

#[tauri::command]
pub async fn save_scenario_agent(
    profile: ScenarioAgentProfile,
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<(), String> {
    db_service
        .upsert_scenario_agent(&profile)
        .await
        .map_err(|e| format!("Failed to save scenario agent: {}", e))
}

#[tauri::command]
pub async fn delete_scenario_agent(
    id: String,
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<(), String> {
    db_service
        .delete_scenario_agent(&id)
        .await
        .map_err(|e| format!("Failed to delete scenario agent: {}", e))
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ScenarioTaskDispatchRequest {
    pub agent_id: String,
    pub query: String,
    pub options: Option<HashMap<String, serde_json::Value>>,
    pub conversation_id: Option<String>,
    pub message_id: Option<String>,
}

#[tauri::command]
pub async fn dispatch_scenario_task(
    request: ScenarioTaskDispatchRequest,
    db_service: State<'_, Arc<DatabaseService>>,
    ai_service_manager: State<'_, Arc<AiServiceManager>>,
    execution_manager: State<'_, Arc<crate::managers::ExecutionManager>>,
    app_handle: AppHandle,
) -> Result<DispatchResult, String> {
    // è¯»å– Agent Profile
    let agents = list_scenario_agents(db_service.clone()).await?;
    let Some(profile) = agents.into_iter().find(|p| p.id == request.agent_id && p.enabled) else {
        return Err(format!("Scenario agent not found or disabled: {}", request.agent_id));
    };

    // é€‰æ¶æ„
    let architecture = match profile.engine {
        AgentEngine::Travel => "travel",
        AgentEngine::PlanExecute => "plan-execute",
        AgentEngine::React => "react",
        AgentEngine::Rewoo => "rewoo",
        AgentEngine::LlmCompiler => "llm-compiler",
        AgentEngine::Auto => "auto",
    }.to_string();

    let mut options = request.options.unwrap_or_default();
    options.insert("agent_id".to_string(), serde_json::Value::String(request.agent_id.clone()));

    // ä» options ä¸­æå– conversation_id å’Œ message_idï¼ˆå‘åå…¼å®¹å‰ç«¯æŠŠå®ƒä»¬æ”¾åœ¨ options é‡Œçš„æƒ…å†µï¼‰
    let conversation_id = request.conversation_id.clone()
        .or_else(|| options.get("conversation_id").and_then(|v| v.as_str()).map(|s| s.to_string()));
    let message_id = request.message_id.clone()
        .or_else(|| options.get("message_id").and_then(|v| v.as_str()).map(|s| s.to_string()));

    if let Some(conv_id) = conversation_id.as_ref() {
        if !conv_id.is_empty() {
            let user_msg = sentinel_core::models::database::AiMessage {
                id: uuid::Uuid::new_v4().to_string(),
                conversation_id: conv_id.clone(),
                role: "user".to_string(),
                content: request.query.clone(),
                metadata: None,
                token_count: Some(request.query.len() as i32),
                cost: None,
                tool_calls: None,
                attachments: None,
                timestamp: chrono::Utc::now(),
                architecture_type: None,
                architecture_meta: None,
                structured_data: None,
            };
            let _ = db_service.create_message(&user_msg).await;
        }
    }

    // è·å–å½“å‰è§’è‰²æç¤ºè¯å¹¶æ·»åŠ åˆ°optionsä¸­
    if let Ok(Some(current_role)) = db_service.get_current_ai_role().await {
        if !current_role.prompt.trim().is_empty() {
            options.insert("role_prompt".to_string(), serde_json::Value::String(current_role.prompt));
            tracing::info!("Added role prompt from: {}", current_role.title);
        }
    }

    // é€ä¼ å·²ç»‘å®šçš„æç¤ºè¯æ¨¡æ¿IDï¼Œä¾›å¼•æ“æˆ–æ‰§è¡Œå±‚ä½¿ç”¨
    if let Some(pids) = &profile.prompt_ids {
        options.insert("prompt_ids".to_string(), serde_json::json!({
            "system": pids.system,
            "planner": pids.planner,
            "executor": pids.executor,
            "replanner": pids.replanner,
            "evaluator": pids.evaluator,
        }));
    }
    // é€ä¼ ç»Ÿä¸€æç¤ºè¯ç³»ç»Ÿç­–ç•¥ã€åˆ†ç»„ã€æ–‡æœ¬è¦†ç›–åŠç‰ˆæœ¬å›ºå®š
    if let Some(strategy) = &profile.prompt_strategy {
        options.insert("prompt_strategy".to_string(), serde_json::Value::String(strategy.clone()));
    }
    if let Some(gid) = profile.group_id {
        options.insert("group_id".to_string(), serde_json::json!(gid));
    }
    {
        let prompts = &profile.prompts;
        options.insert("prompts".to_string(), serde_json::json!({
            "system": prompts.system,
            "planner": prompts.planner,
            "executor": prompts.executor,
            "replanner": prompts.replanner,
            "evaluator": prompts.evaluator,
        }));
    }
    if let Some(pinned) = &profile.pinned_versions {
        options.insert("pinned_versions".to_string(), serde_json::to_value(pinned).unwrap_or_else(|_| serde_json::json!({})));
    }

    // å·¥å…·ç™½åå•/é»‘åå•ç­–ç•¥ï¼ˆç”¨äºæ‰§è¡ŒæœŸè¿‡æ»¤ï¼‰
    // è¦æ±‚ï¼šSystem prompt ä¸­çš„å·¥å…·æ¸…å•åº”ä¸¥æ ¼ä¾æ® AgentManager.vue ä¸­â€œå¯ç”¨+å·²é€‰â€çš„é›†åˆã€‚
    // è¯­ä¹‰ï¼š
    // - è‹¥å‰ç«¯é…ç½®å­˜åœ¨ï¼ˆprofile.tools æœ‰å€¼ï¼‰ï¼šæŒ‰ allow/deny é€ä¼ ï¼›
    // - è‹¥å‰ç«¯æœªé…ç½®ï¼ˆprofile.tools ä¸º Noneï¼‰ï¼šä¹Ÿè¦æ˜¾å¼ä¼ å…¥ç©ºç™½åå•ï¼Œè¡¨ç¤ºâ€œæœªé€‰æ‹©ä»»ä½•å·¥å…· â‡’ ç¦ç”¨æ‰€æœ‰å·¥å…·â€ã€‚
    //   è¿™æ · ReAct/Planner åœ¨æ„å»ºå·¥å…·æ¸…å•æ—¶ä¸ä¼šé€€å›åˆ°â€œå…è®¸æ‰€æœ‰â€ã€‚
    {
        let tool_policy = &profile.tools;
        log::info!("Agent tools policy - allow: {:?}, deny: {:?}", tool_policy.allow, tool_policy.deny);
        options.insert(
            "tools_allow".to_string(),
            serde_json::json!(tool_policy.allow.clone())
        );
        if let Some(deny) = &tool_policy.deny {
            options.insert("tools_deny".to_string(), serde_json::json!(deny.clone()));
        }
    }

    // æ‰§è¡Œç­–ç•¥ï¼ˆè¶…æ—¶/é‡è¯•/ä¸¥æ ¼æ¨¡å¼/å¹¶å‘ï¼‰
    {
        let exec = &profile.execution;
        if let Some(timeout) = exec.timeout_sec {
            options.insert("execution_timeout_sec".to_string(), serde_json::json!(timeout));
        }
        let retry = &exec.retry;
        options.insert("execution_retry_max".to_string(), serde_json::json!(retry.max_retries));
        options.insert("execution_retry_backoff".to_string(), serde_json::json!(retry.backoff.clone()));
        if let Some(iv) = retry.interval_ms { options.insert("execution_retry_interval_ms".to_string(), serde_json::json!(iv)); }
        if let Some(conc) = exec.concurrency { options.insert("execution_concurrency".to_string(), serde_json::json!(conc)); }
        if let Some(strict) = exec.strict_mode { options.insert("execution_strict_mode".to_string(), serde_json::json!(strict)); }
    }

    // LLMé…ç½®ï¼ˆç”¨äºè¦†ç›–é˜¶æ®µé»˜è®¤æ¨¡å‹ï¼‰
    // ç›´æ¥ä¼ é€’å®Œæ•´ç»“æ„ï¼Œä¾¿äºåç»­è§£æ
    options.insert(
        "llm".to_string(),
        serde_json::json!({
            "default": {
                "provider": profile.llm.default.provider,
                "model": profile.llm.default.model,
                "temperature": profile.llm.default.temperature,
                "max_tokens": profile.llm.default.max_tokens,
            }
        })
    );

    // ä»¥ä¸‹æ˜¯åŸ dispatch_intelligent_query çš„é€»è¾‘
    // æå–ä»»åŠ¡æ¨¡å¼æ ‡è¯†å’Œç›¸å…³ä¿¡æ¯
    let is_task_mode = options.get("task_mode")
        .and_then(|v| v.as_bool())
        .unwrap_or(false);

    // conversation_id å’Œ message_id å·²ç»åœ¨ä¸Šé¢ä» request æˆ– options ä¸­æå–
    // è¿™é‡Œä¸éœ€è¦å†æ¬¡æå–ï¼Œç›´æ¥ä½¿ç”¨ä¹‹å‰çš„å˜é‡

    let execution_id = options.get("execution_id")
        .and_then(|v| v.as_str())
        .map(|s| s.to_string())
        .unwrap_or_else(|| uuid::Uuid::new_v4().to_string());

    // åˆ›å»ºagent_sessionè®°å½•ç”¨äºç»Ÿä¸€çš„å·¥ä½œæµç›‘æ§
    if let Err(e) = create_ai_assistant_session(
        &db_service,
        &execution_id,
        &profile.name,
        &request.query,
    ).await {
        log::warn!("Failed to create AI assistant session: {}", e);
    }

    // æå–ä¼šè¯IDï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
    if let Some(ref conv_id) = conversation_id {
        if !conv_id.is_empty() {
            info!("Processing request for conversation: {}", conv_id);
        }
    }

    // å¦‚æœæ˜¯ä»»åŠ¡æ¨¡å¼ä¸”æ¶æ„ä¸º"auto"ï¼Œè¿›è¡Œæ™ºèƒ½é€‰æ‹©
    let selected_architecture = if is_task_mode && architecture == "auto" {
        let auto_selected = select_best_architecture(&request.query).await
            .map_err(|e| format!("Failed to select architecture: {}", e))?;

        info!("Auto-selected architecture: {} for query: {}", auto_selected, request.query);

        auto_selected
    } else {
        architecture.clone()
    };

    // åˆ›å»º DispatchQueryRequest
    let dispatch_req = DispatchQueryRequest {
        query: request.query,
        architecture: selected_architecture.clone(),
        agent_id: Some(profile.id),
        options: Some(options),
        conversation_id: conversation_id.clone(),
        message_id: message_id.clone(),
    };

    let app_clone = app_handle.clone();
    // æ ¹æ®é€‰æ‹©çš„æ¶æ„åˆ›å»ºè°ƒåº¦å™¨
    let result = match selected_architecture.as_str() {
        "plan-execute" => {
            dispatch_with_plan_execute(
                execution_id.clone(),
                dispatch_req,
                (*ai_service_manager).clone(),
                (*db_service).clone(),
                (*execution_manager).clone(),
                app_handle.clone(),
            ).await
        },
        "react" => {
            dispatch_with_react(
                execution_id.clone(),
                dispatch_req,
                (*ai_service_manager).clone(),
                (*db_service).clone(),
                (*execution_manager).clone(),
                app_clone.clone(),
            ).await
        },
        "rewoo" => {
            dispatch_with_rewoo(
                execution_id.clone(),
                dispatch_req,
                (*ai_service_manager).clone(),
                (*db_service).clone(),
                (*execution_manager).clone(),
                app_clone.clone(),
            ).await
        },
        "llm-compiler" => {
            dispatch_with_llm_compiler(
                execution_id.clone(),
                dispatch_req,
                (*ai_service_manager).clone(),
                (*db_service).clone(),
                (*execution_manager).clone(),
                app_clone.clone(),
            ).await
        },
        "auto" => {
            dispatch_with_auto(
                execution_id.clone(),
                dispatch_req,
                (*ai_service_manager).clone(),
                (*db_service).clone(),
                (*execution_manager).clone(),
                app_clone.clone(),
            ).await
        }
        "travel" => {
            dispatch_with_travel(
                execution_id.clone(),
                dispatch_req,
                (*ai_service_manager).clone(),
                (*db_service).clone(),
                (*execution_manager).clone(),
                app_clone.clone(),
            ).await
        }
        _ => {
            Err(format!("Unsupported architecture: {}", selected_architecture))
        }
    };

    // å¦‚æœè°ƒåº¦æˆåŠŸï¼ŒæŒ‰æ¶æ„å†³å®šæ˜¯å¦éœ€è¦å¼‚æ­¥å¼€å§‹"çœŸå®æ‰§è¡Œ"
    if let Ok(ref dispatch_result) = result {
        // ä»…å¯¹éœ€è¦ register_execution çš„æ¶æ„è§¦å‘åç»­æ‰§è¡Œï¼ˆå¦‚ plan-execute / llm-compilerï¼‰
        // æ³¨æ„ï¼štravel å’Œ react æ¶æ„åœ¨ dispatch å‡½æ•°ä¸­ç›´æ¥æ‰§è¡Œï¼Œä¸éœ€è¦å¼‚æ­¥æ‰§è¡Œ
        let arch_for_exec = selected_architecture.clone();
        if matches!(arch_for_exec.as_str(), "plan-execute" | "llm-compiler" | "auto") {
            let execution_id_clone = dispatch_result.execution_id.clone();
            let app_clone = app_handle.clone();

            // å¼‚æ­¥å¼€å§‹æ‰§è¡Œï¼Œä¸é˜»å¡è°ƒåº¦å“åº”
            tokio::spawn(async move {
                info!("Starting real engine execution: {}", execution_id_clone);

                // ä»åº”ç”¨çŠ¶æ€è·å–æ‰§è¡Œç®¡ç†å™¨
                let execution_manager = app_clone.state::<Arc<crate::managers::ExecutionManager>>();
                let execution_manager_clone = execution_manager.inner().clone();
                let app_inner = app_clone.clone();
                let execution_id_inner = execution_id_clone.clone();
                let db_service_clone = app_clone.state::<Arc<DatabaseService>>().inner().clone();

                tokio::spawn(async move {
                    // è·å–æ‰§è¡Œä¸Šä¸‹æ–‡
                    let context = match execution_manager_clone.get_execution_context(&execution_id_inner).await {
                        Some(ctx) => ctx,
                        None => {
                            // å¯¹äºä¸è¯¥è§¦å‘çš„æƒ…å†µå·²åœ¨å¤–å±‚è¿‡æ»¤ï¼Œè¿™é‡Œè‹¥ä»ç„¶ç¼ºå¤±ï¼Œå¯èƒ½æ˜¯è¢«å¤–éƒ¨å–æ¶ˆæˆ–è¿‡æœŸæ¸…ç†
                            log::error!("Execution context not found: {}", execution_id_inner);
                            return;
                        }
                    };

                log::info!("Starting real execution for: {} with engine: {:?}", execution_id_inner, context.engine_type);

                // ä»ä»»åŠ¡å‚æ•°ä¸­æå–æ¶ˆæ¯IDå’Œä¼šè¯ID
                let message_id = context.task.parameters.get("message_id").and_then(|v| v.as_str()).map(|s| s.to_string());
                let conversation_id = context.task.parameters.get("conversation_id").and_then(|v| v.as_str()).map(|s| s.to_string());

                // å‘é€ PlanUpdate äº‹ä»¶ç»™å‰ç«¯å±•ç¤ºæ‰§è¡Œè®¡åˆ’ï¼ˆé¢„ç•™ï¼‰
                let _plan_json = serde_json::json!({
                    "id": context.plan.id,
                    "name": context.plan.name,
                    "estimated_duration": context.plan.estimated_duration,
                    "resource_requirements": context.plan.resource_requirements,
                    "steps": context
                        .plan
                        .steps
                        .iter()
                        .enumerate()
                        .map(|(i, s)| serde_json::json!({
                            "index": i + 1,
                            "id": s.id,
                            "name": s.name,
                            "description": s.description,
                            "type": format!("{:?}", s.step_type),
                            "dependencies": s.dependencies,
                            "parameters": s.parameters
                        }))
                        .collect::<Vec<_>>()
                });

                // Emit plan as a PlanInfo message chunk to frontend
                if let Ok(plan_str) = serde_json::to_string(&_plan_json) {
                    crate::utils::ordered_message::emit_message_chunk_arc(
                        &Arc::new(app_inner.clone()),
                        &execution_id_inner,
                        message_id.as_deref().unwrap_or(&execution_id_inner),
                        conversation_id.as_deref(),
                        crate::utils::ordered_message::ChunkType::PlanInfo,
                        &plan_str,
                        false,
                        Some("planner"),
                        None,
                        None,
                        None,
                    );
                }

                // Emit a one-shot Meta message with execution configuration
                let _meta_json = {
                    let params = &context.task.parameters;
                    serde_json::json!({
                        "engine": format!("{:?}", context.engine_type),
                        "agent_id": params.get("agent_id").and_then(|v| v.as_str()),
                        "prompt_ids": params.get("prompt_ids"),
                        "prompt_strategy": params.get("prompt_strategy").and_then(|v| v.as_str()),
                        "group_id": params.get("group_id"),
                        "pinned_versions": params.get("pinned_versions"),
                    })
                };

                // è®°å½•æ‰§è¡Œå¼€å§‹æ—¶é—´
                let execution_start_time = std::time::SystemTime::now();

                // æ‰§è¡ŒçœŸå®çš„å¼•æ“è®¡åˆ’
                let exec_result = execution_manager_clone.execute_plan(&execution_id_inner).await;

                // è®°å½•æ‰§è¡Œå®Œæˆæ—¶é—´
                let execution_end_time = std::time::SystemTime::now();

                // ä¿å­˜æ‰§è¡Œç»“æœåˆ°æ•°æ®åº“
                let task_name = context.task.description.clone();
                let architecture = format!("{:?}", context.engine_type);
                let started_at = execution_start_time.duration_since(std::time::UNIX_EPOCH).unwrap_or_default().as_secs();
                let completed_at = execution_end_time.duration_since(std::time::UNIX_EPOCH).unwrap_or_default().as_secs();
                let duration_ms = execution_end_time.duration_since(execution_start_time).unwrap_or_default().as_millis() as u64;

                let success = exec_result.is_ok();
                let error = if let Err(ref e) = exec_result { Some(e.to_string()) } else { None };
                let result = if success { Some("Task completed successfully".to_string()) } else { None };

                // åªæœ‰éPlan-and-Executeæ¶æ„æ‰ä¿å­˜é€šç”¨çš„AIåŠ©æ‰‹æ‰§è¡Œæ­¥éª¤
                // Plan-and-Executeå¼•æ“ä¼šè‡ªå·±ä¿å­˜è¯¦ç»†çš„æ­¥éª¤ä¿¡æ¯
                if !architecture.contains("PlanExecute") {
                    if let Err(e) = save_ai_assistant_execution(
                        &db_service_clone,
                        &execution_id_inner,
                        &task_name,
                        &architecture,
                        success,
                        error.as_deref(),
                        result.as_deref(),
                        started_at,
                        completed_at,
                        duration_ms,
                    ).await {
                        log::warn!("Failed to save AI assistant execution: {}", e);
                    }
                } else {
                    // å¯¹äºPlan-and-Executeæ¶æ„ï¼Œåªæ›´æ–°sessionçŠ¶æ€
                    use crate::services::database::Database;
                    let status_str = if success { "Completed" } else { "Failed" };
                    if let Err(e) = db_service_clone.update_agent_session_status(&execution_id_inner, status_str).await {
                        log::warn!("Failed to update agent session status: {}", e);
                    }
                }

                match exec_result {
                    Ok(_result) => {
                        log::info!("Execution completed successfully: {}", execution_id_inner);
                        // ç§»é™¤åŸå§‹äº‹ä»¶ï¼Œåªä½¿ç”¨ai_stream_message
                    }
                    Err(e) => {
                        log::error!("Execution failed: {}: {}", execution_id_inner, e);

                        // ä½¿ç”¨æ›´å‹å¥½çš„é”™è¯¯æ¶ˆæ¯æ ¼å¼
                        let error_message = format!(
                            "ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {}\n\nå¦‚éœ€å¸®åŠ©ï¼Œè¯·æ£€æŸ¥æ‰§è¡Œé…ç½®æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚",
                            e.to_string()
                        );

                        // ä½¿ç”¨æœ‰åºæ¶ˆæ¯å—å‘é€é”™è¯¯
                        crate::utils::ordered_message::emit_message_chunk_arc(
                            &Arc::new(app_inner.clone()),
                            &execution_id_inner,
                            message_id.as_deref().unwrap_or(&execution_id_inner),
                            conversation_id.as_deref(),
                            crate::utils::ordered_message::ChunkType::Error,
                            &error_message,
                            true, // ç¡®ä¿æ ‡è®°ä¸ºæœ€ç»ˆæ¶ˆæ¯
                            None,
                            None,
                            None,
                            None,
                        );

                        // ç¡®ä¿å‘é€ä¸€ä¸ªå†…å®¹å—æ¥æ­£å¼ç»“æŸä¼šè¯
                        crate::utils::ordered_message::emit_message_chunk_arc(
                            &Arc::new(app_inner.clone()),
                            &execution_id_inner,
                            message_id.as_deref().unwrap_or(&execution_id_inner),
                            conversation_id.as_deref(),
                            crate::utils::ordered_message::ChunkType::Content,
                            "", // ç©ºå†…å®¹ï¼Œä»…ç”¨äºç»“æŸæµ
                            true, // æœ€ç»ˆæ¶ˆæ¯
                            Some("error_termination"),
                            None,
                            None,
                            None,
                        );
                    }
                }

                    // æ¸…ç†æ‰§è¡Œä¸Šä¸‹æ–‡
                    execution_manager_clone.cleanup_execution(&execution_id_inner).await;
                });
            });
        } else {
            // ReAct ç­‰æ¶æ„å·²åœ¨è°ƒåº¦é˜¶æ®µå®Œæˆæ‰§è¡Œï¼Œè¿™é‡Œä¸å†é‡å¤è§¦å‘
            info!("Architecture '{}' completes within dispatch; ", arch_for_exec);
        }
    }

    // æ›´æ–°è¿”å›ç»“æœä¸­çš„æ¶æ„ä¿¡æ¯
    result.map(|mut dispatch_result| {
        // å½“å¤–å±‚é€‰æ‹©ä¸º "auto" æ—¶ï¼Œä¸è¦†ç›–å…·ä½“è°ƒåº¦å™¨è¿”å›çš„æ¶æ„ä¿¡æ¯
        if selected_architecture != "auto" {
            dispatch_result.selected_architecture = selected_architecture.clone();
        }
        dispatch_result
    })
}

#[derive(Debug, Serialize, Deserialize)]
pub struct AgentStatistics {
    pub active_count: u32,
    pub total_tasks: u32,
    pub successful_tasks: u32,
    pub failed_tasks: u32,
    pub average_execution_time: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CustomAgent {
    pub id: String,
    pub name: String,
    pub description: String,
    #[serde(rename = "type")]
    pub r#type: String,
    pub status: String,
    pub tasks_completed: u32,
}



/// åœæ­¢æ‰§è¡Œ
#[tauri::command(rename_all = "snake_case")]
pub async fn stop_execution(
    execution_id: String,
    app: AppHandle,
) -> Result<(), String> {
    info!("ğŸ›‘ Stopping execution: {}", execution_id);

    // 1. âœ… å–æ¶ˆCancellationTokenï¼ˆå¯¹ReActæ¶æ„æœ‰æ•ˆï¼‰
    use crate::managers::cancellation_manager;
    let cancelled_by_token = cancellation_manager::cancel_execution(&execution_id).await;
    if cancelled_by_token {
        log::info!("âœ… Cancelled execution via CancellationToken: {}", execution_id);
    }

    // 2. å°è¯•åœæ­¢æ‰§è¡Œç®¡ç†å™¨ä¸­çš„ä»»åŠ¡ï¼ˆå¯¹Plan-Execute/LLMCompileræœ‰æ•ˆï¼‰
    let execution_manager = app.state::<Arc<crate::managers::ExecutionManager>>();
    let manager = execution_manager.inner().clone();
    if let Err(e) = manager.stop_execution(&execution_id).await {
        log::warn!("Failed to stop execution via ExecutionManager {}: {}", execution_id, e);
    } else {
        log::info!("âœ… Stopped execution via ExecutionManager: {}", execution_id);
    }

    // 3. å¦‚æœexecution_idçœ‹èµ·æ¥åƒä¼šè¯IDï¼Œä¹Ÿå°è¯•å–æ¶ˆå¯¹åº”çš„æµ
    // è¿™æ ·å¯ä»¥å¤„ç†ç”¨ä¼šè¯IDè°ƒç”¨stopçš„æƒ…å†µ
    if execution_id.starts_with("conv_") || execution_id.len() == 36 {
        // å¯èƒ½æ˜¯ä¼šè¯IDæˆ–UUIDæ ¼å¼
        use crate::commands::ai::cancel_conversation_stream;
        cancel_conversation_stream(&execution_id);
        log::info!("âœ… Cancelled stream for conversation: {}", execution_id);
    }

    // 4. å‘é€åœæ­¢äº‹ä»¶ï¼ˆç»Ÿä¸€äº‹ä»¶åç§°ï¼‰
    if let Err(e) = app.emit("execution_stopped", serde_json::json!({
        "execution_id": execution_id,
        "message": "Execution stopped by user"
    })) {
        log::warn!("Failed to emit execution_stopped event: {}", e);
    }

    log::info!("âœ… Stop execution completed: {}", execution_id);

    info!("Execution stop completed: {}", execution_id);
    Ok(())
}

/// è·å–AIåŠ©æ‰‹è®¾ç½®
#[tauri::command]
pub async fn get_ai_assistant_settings(
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<AIAssistantSettings, String> {
    // ä»æ•°æ®åº“åŠ è½½è®¾ç½®ï¼Œä½¿ç”¨ä¸“é—¨çš„keyå­˜å‚¨AIAssistantSettings
    match db_service.get_config("ai_assistant", "assistant_settings").await {
        Ok(Some(json_str)) => {
            serde_json::from_str::<AIAssistantSettings>(&json_str)
                .map_err(|e| format!("Failed to parse AI assistant settings: {}", e))
        }
        Ok(None) => {
            // è¿”å›é»˜è®¤è®¾ç½®
            let default_settings = AIAssistantSettings {
                auto_execute: false,
                notification_enabled: true,
            };
            info!("Using default AI assistant settings");
            Ok(default_settings)
        }
        Err(e) => Err(format!("Failed to load AI assistant settings: {}", e)),
    }
}

/// ä¿å­˜AIåŠ©æ‰‹è®¾ç½®
#[tauri::command]
pub async fn save_ai_assistant_settings(
    settings: AIAssistantSettings,
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<(), String> {
    info!("Saving AI assistant settings: {:?}", settings);
    let json = serde_json::to_string(&settings)
        .map_err(|e| format!("Failed to serialize settings: {}", e))?;
    db_service
        .set_config(
            "ai_assistant",
            "assistant_settings",
            &json,
            None,
        )
        .await
        .map_err(|e| format!("Failed to save AI assistant settings: {}", e))
}

/// è·å–Agentç»Ÿè®¡ä¿¡æ¯
#[tauri::command]
pub async fn get_agent_statistics(
    manager: State<'_, crate::commands::agent_commands::GlobalAgentManager>,
) -> Result<AgentStatistics, String> {
    let manager_guard = manager.read().await;

    let agent_manager = match manager_guard.as_ref() {
        Some(manager) => manager,
        None => {
            // Agentç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œè¿”å›é»˜è®¤å€¼
            return Ok(AgentStatistics {
                active_count: 0,
                total_tasks: 0,
                successful_tasks: 0,
                failed_tasks: 0,
                average_execution_time: 0.0,
            });
        }
    };

    // ä»Agentç®¡ç†å™¨è·å–çœŸå®ç»Ÿè®¡æ•°æ®
    let stats = agent_manager.get_statistics().await;
    let sessions = agent_manager.get_all_sessions().await;

    // ç»Ÿè®¡æ´»è·ƒä¼šè¯æ•°
    let active_count = sessions.iter().filter(|(_, info)| {
        matches!(
            info.status,
            crate::agents::traits::AgentSessionStatus::Planning |
            crate::agents::traits::AgentSessionStatus::Executing
        )
    }).count();

    Ok(AgentStatistics {
        active_count: active_count as u32,
        total_tasks: stats.total_tasks as u32,
        successful_tasks: stats.successful_tasks as u32,
        failed_tasks: stats.failed_tasks as u32,
        average_execution_time: stats.average_execution_time_ms / 1000.0, // è½¬æ¢ä¸ºç§’
    })
}

/// è·å–å¯ç”¨æ¶æ„åˆ—è¡¨
#[tauri::command]
pub async fn get_available_architectures() -> Result<Vec<serde_json::Value>, String> {
    Ok(vec![
        serde_json::json!({
            "id": "auto",
            "name": "Auto",
            "description": "è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¶æ„",
            "suitable_for": ["æ‰€æœ‰ä»»åŠ¡"],
            "performance": "è‡ªåŠ¨",
            "status": "stable"
        }),
        serde_json::json!({
            "id": "plan-execute",
            "name": "Plan-and-Execute",
            "description": "åŸºäºè§„åˆ’å’Œæ‰§è¡Œçš„æ™ºèƒ½Agentæ¶æ„",
            "suitable_for": ["å¤æ‚ä»»åŠ¡", "å¤šæ­¥éª¤æµç¨‹", "éœ€è¦é‡è§„åˆ’çš„ä»»åŠ¡"],
            "performance": "ç¨³å®š",
            "status": "stable"
        }),
        serde_json::json!({
            "id": "rewoo",
            "name": "ReWOO",
            "description": "æ¨ç†è€Œéè§‚å¯Ÿçš„å·¥ä½œæµæ¶æ„",
            "suitable_for": ["æ¨ç†å¯†é›†å‹ä»»åŠ¡", "åˆ†æç±»ä»»åŠ¡"],
            "performance": "é«˜æ•ˆ",
            "status": "beta"
        }),
        serde_json::json!({
            "id": "llm-compiler",
            "name": "LLMCompiler",
            "description": "å¹¶è¡Œæ‰§è¡Œå¼•æ“",
            "suitable_for": ["å¹¶è¡Œä»»åŠ¡", "ç‹¬ç«‹çš„å¤šä¸ªå­ä»»åŠ¡"],
            "performance": "å¿«é€Ÿ",
            "status": "experimental"
        }),

    ])
}

/// è·å–è‡ªå®šä¹‰Agentåˆ—è¡¨
#[tauri::command]
pub async fn get_ai_assistant_agents(
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<Vec<CustomAgent>, String> {
    match db_service.get_config("ai_assistant", "custom_agents").await {
        Ok(Some(json_str)) => serde_json::from_str::<Vec<CustomAgent>>(&json_str)
            .map_err(|e| format!("Failed to parse custom agents: {}", e)),
        Ok(None) => Ok(vec![]),
        Err(e) => Err(format!("Failed to load custom agents: {}", e)),
    }
}

/// ä¿å­˜è‡ªå®šä¹‰Agentåˆ—è¡¨
#[tauri::command]
pub async fn save_ai_assistant_agents(
    agents: Vec<CustomAgent>,
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<(), String> {
    let json = serde_json::to_string(&agents)
        .map_err(|e| format!("Failed to serialize custom agents: {}", e))?;
    db_service
        .set_config(
            "ai_assistant",
            "custom_agents",
            &json,
            None,
        )
        .await
        .map_err(|e| format!("Failed to save custom agents: {}", e))
}

/// è·å–æ¶æ„å¯ç”¨åå¥½ï¼ˆè¿”å›å¯ç”¨çš„æ¶æ„IDåˆ—è¡¨ï¼‰
#[tauri::command]
pub async fn get_ai_architecture_prefs(
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<Vec<String>, String> {
    match db_service.get_config("ai_assistant", "enabled_architectures").await {
        Ok(Some(json_str)) => serde_json::from_str::<Vec<String>>(&json_str)
            .map_err(|e| format!("Failed to parse architecture prefs: {}", e)),
        Ok(None) => Ok(vec![
            "plan-execute".to_string(),
            "rewoo".to_string(),
            "llm-compiler".to_string(),
        ]),
        Err(e) => Err(format!("Failed to load architecture prefs: {}", e)),
    }
}

/// ä¿å­˜æ¶æ„å¯ç”¨åå¥½
#[tauri::command]
pub async fn save_ai_architecture_prefs(
    enabled_architectures: Vec<String>,
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<(), String> {
    let json = serde_json::to_string(&enabled_architectures)
        .map_err(|e| format!("Failed to serialize architecture prefs: {}", e))?;
    db_service
        .set_config(
            "ai_assistant",
            "enabled_architectures",
            &json,
            None,
        )
        .await
        .map_err(|e| format!("Failed to save architecture prefs: {}", e))
}

// ===== è¾…åŠ©å‡½æ•°å’Œç»“æ„ä½“ =====

#[derive(Debug, Deserialize)]
pub struct TaskSubmissionRequest {
    pub user_input: String,
    pub user_id: String,
    pub priority: Option<String>,
    pub estimated_duration: Option<f64>,
    pub metadata: Option<HashMap<String, serde_json::Value>>,
}

#[derive(Debug, Deserialize)]
pub struct NodeRegistrationRequest {
    pub name: String,
    pub capacity: NodeCapacityRequest,
}

#[derive(Debug, Deserialize)]
pub struct NodeCapacityRequest {
    pub cpu_cores: u32,
    pub memory_gb: u32,
    pub network_mbps: f32,
    pub storage_gb: u32,
    pub max_concurrent_tasks: u32,
}



/// æ™ºèƒ½é€‰æ‹©æœ€ä½³æ¶æ„
async fn select_best_architecture(user_input: &str) -> Result<String, String> {
    // ç®€å•çš„è§„åˆ™åŸºç¡€æ¶æ„é€‰æ‹©
    let input_lower = user_input.to_lowercase();

    // åˆ†æä»»åŠ¡ç‰¹å¾
    let has_complex_analysis = input_lower.contains("åˆ†æ") || input_lower.contains("analysis");
    let has_scanning = input_lower.contains("æ‰«æ") || input_lower.contains("scan");
    let has_monitoring = input_lower.contains("ç›‘æ§") || input_lower.contains("monitor");
    let has_multiple_steps = input_lower.contains("æ­¥éª¤") || input_lower.contains("å¤šä¸ª") || input_lower.contains("multiple");
    let has_parallel_tasks = input_lower.contains("åŒæ—¶") || input_lower.contains("å¹¶è¡Œ") || input_lower.contains("parallel");

    // æ¶æ„é€‰æ‹©é€»è¾‘
    if has_parallel_tasks || (has_scanning && has_multiple_steps) {
        Ok("llm-compiler".to_string())
    } else if has_complex_analysis {
        Ok("rewoo".to_string())
    } else if has_monitoring || input_lower.len() > 100 {
        Ok("plan-execute".to_string())
    } else {
        // å¯¹äºä¸€èˆ¬ä»»åŠ¡ï¼Œä½¿ç”¨plan-execute
        Ok("plan-execute".to_string())
    }
}



async fn dispatch_with_auto(
    execution_id: String,
    request: DispatchQueryRequest,
    ai_service_manager: Arc<AiServiceManager>,
    db_service: Arc<DatabaseService>,
    execution_manager: Arc<crate::managers::ExecutionManager>,
    app: AppHandle,
) -> Result<DispatchResult, String> {
    let architecture = select_best_architecture(&request.query).await?;
    match architecture.as_str() {
        "plan-execute" => dispatch_with_plan_execute(execution_id, request, ai_service_manager, db_service, execution_manager, app).await,
        "rewoo" => dispatch_with_rewoo(execution_id, request, ai_service_manager, db_service, execution_manager, app).await,
        "llm-compiler" => dispatch_with_llm_compiler(execution_id, request, ai_service_manager, db_service, execution_manager, app).await,
        "travel" => Err("Travel architecture dispatch not yet implemented".to_string()),
        _ => Err(format!("Unsupported architecture: {}", architecture)),
    }
}

async fn dispatch_with_plan_execute(
    execution_id: String,
    request: DispatchQueryRequest,
    ai_service_manager: Arc<AiServiceManager>,
    db_service: Arc<DatabaseService>,
    execution_manager: Arc<crate::managers::ExecutionManager>,
    app: AppHandle,
) -> Result<DispatchResult, String> {

    // åˆ›å»ºPlan-and-Executeå¼•æ“é…ç½®
    let config = PlanAndExecuteConfig::default();

    // åˆ›å»ºPlan-and-Executeå¼•æ“
    let mut engine = PlanAndExecuteEngine::new_with_dependencies(
        ai_service_manager.clone(),
        config,
        db_service.clone(),
        Some(Arc::new(app.clone())),
    ).await.map_err(|e| format!("Failed to create Plan-and-Execute engine: {}", e))?;

    // åˆ›å»ºAgentä»»åŠ¡
    let mut parameters = request.options.unwrap_or_default();
    // ç»Ÿä¸€ä½¿ç”¨ snake_case keysï¼Œå…¼å®¹å¯èƒ½ä¼ å…¥çš„ camelCase
    if let Some(v) = parameters.remove("executionId") { parameters.insert("execution_id".to_string(), v); }
    if let Some(v) = parameters.remove("messageId") { parameters.insert("message_id".to_string(), v); }
    if let Some(v) = parameters.remove("conversationId") { parameters.insert("conversation_id".to_string(), v); }
    if let Some(v) = parameters.remove("taskMode") { parameters.insert("task_mode".to_string(), v); }
    // ç»Ÿä¸€æç¤ºè¯IDå­—æ®µï¼ˆå…¼å®¹ camelCase -> snake_caseï¼‰
    if let Some(v) = parameters.remove("promptIds") { parameters.insert("prompt_ids".to_string(), v); }
    parameters.insert("execution_id".to_string(), serde_json::Value::String(execution_id.clone()));

    let task = AgentTask {
        id: Uuid::new_v4().to_string(), // The internal task ID can be unique
        user_id: "system".to_string(),
        description: request.query.clone(),
        priority: TaskPriority::Normal,
        target: None,
        parameters,
        timeout: Some(600), // 10 minute timeout
    };

    // å°†å‚æ•°æ³¨å…¥å¼•æ“ï¼Œä¾¿äºæ‰§è¡Œé˜¶æ®µè®¿é—®ï¼ˆå¦‚ prompt_ids ï¼‰
    engine.set_runtime_params(task.parameters.clone());

    // Create execution plan
    let plan = engine.create_plan(&task).await
        .map_err(|e| format!("Failed to create execution plan: {}", e))?;

    // Register execution context and engine instance to execution manager
    let engine_instance = crate::managers::EngineInstance::PlanExecute(engine);
    execution_manager.register_execution(
        execution_id.clone(),
        crate::managers::EngineType::PlanExecute,
        plan.clone(),
        task,
        engine_instance,
    ).await.map_err(|e| format!("Failed to register execution: {}", e))?;

    let execution_plan = ExecutionPlanView {
        id: plan.id.clone(),
        name: plan.name.clone(),
        description: format!("Plan-and-Executeä»»åŠ¡: {}", request.query),
        steps: plan.steps.iter().map(|step| ExecutionStepView {
            id: step.id.clone(),
            name: step.name.clone(),
            description: step.description.clone(),
            status: "pending".to_string(),
            estimated_duration: 60,
        }).collect(),
        estimated_duration: plan.estimated_duration,
    };

    Ok(DispatchResult {
        execution_id,
        initial_response: "å·²åˆ›å»ºPlan-and-Executeæ‰§è¡Œè®¡åˆ’ï¼Œå¼•æ“å®ä¾‹å·²æ³¨å†Œï¼Œå‡†å¤‡çœŸå®æ‰§è¡Œ...".to_string(),
        execution_plan: Some(execution_plan),
        estimated_duration: plan.estimated_duration,
        selected_architecture: "Plan-and-Execute".to_string(),
    })
}

async fn dispatch_with_react(
    execution_id: String,
    request: DispatchQueryRequest,
    ai_service_manager: Arc<AiServiceManager>,
    db_service: Arc<DatabaseService>,
    _execution_manager: Arc<crate::managers::ExecutionManager>,
    app: AppHandle,
) -> Result<DispatchResult, String> {
    use crate::engines::react::{ReactEngine, ReactConfig};
    use std::collections::HashMap;
    use crate::agents::traits::{AgentTask, TaskPriority};
    use crate::managers::cancellation_manager;

    info!("Creating ReAct dispatch for: {}", request.query);

    // âœ… æ³¨å†Œå–æ¶ˆä»¤ç‰Œ
    let cancellation_token = cancellation_manager::register_cancellation_token(execution_id.clone()).await;

    // ä» options ä¸­æå–é…ç½®
    let options = request.options.unwrap_or_default();
    let mut config = ReactConfig::default();
    let max_iterations = config.max_iterations; // ä¿å­˜ç”¨äºè¶…æ—¶è®¡ç®—

    if let Some(max_iter) = options.get("max_iterations").and_then(|v| v.as_u64()) {
        config.max_iterations = max_iter as u32;
    }
    if let Some(temp) = options.get("temperature").and_then(|v| v.as_f64()) {
        config.temperature = Some(temp as f32);
    }
    if let Some(max_tok) = options.get("max_tokens").and_then(|v| v.as_u64()) {
        config.max_tokens = Some(max_tok as u32);
    }
    if let Some(rag) = options.get("enable_rag").and_then(|v| v.as_bool()) {
        config.enable_rag = rag;
    }
    if let Some(verbose) = options.get("verbose").and_then(|v| v.as_bool()) {
        config.verbose = verbose;
    }

    // **å…³é”®ä¿®å¤**: ä» options ä¸­è¯»å– tools_allow å¹¶è®¾ç½®åˆ° ReactConfig.allowed_tools
    // è¿™æ · ReAct executor çš„ build_tools_information æ‰èƒ½è¯»å–åˆ°æ­£ç¡®çš„å·¥å…·ç™½åå•
    if let Some(tools_allow) = options.get("tools_allow") {
        if let Some(arr) = tools_allow.as_array() {
            let tool_names: Vec<String> = arr.iter()
                .filter_map(|v| v.as_str().map(|s| s.to_string()))
                .collect();
            log::info!("ReAct dispatch: è®¾ç½® allowed_tools = {:?}", tool_names);
            config.allowed_tools = Some(tool_names);
        }
    }

    // è·å–é»˜è®¤ AI æœåŠ¡
    let ai_service = match ai_service_manager.get_default_chat_model().await {
        Ok(Some((provider, model))) => {
            match ai_service_manager.get_provider_config(&provider).await {
                Ok(Some(mut provider_config)) => {
                    provider_config.model = model;
                    let mcp_service = ai_service_manager.get_mcp_service();
                    let ai_svc = crate::services::ai::AiService::new(
                        provider_config,
                        db_service.clone(),
                        Some(app.clone()),
                        mcp_service.clone(),
                    );
                    Arc::new(ai_svc)
                }
                _ => {
                    // Provideré…ç½®è·å–å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ "default" æœåŠ¡
                    log::warn!("Failed to get provider config for '{}', falling back to 'default' service", provider);
                    match ai_service_manager.get_service("default") {
                        Some(service) => Arc::new(service),
                        None => {
                            return Err(format!("Failed to get AI provider config for '{}' and no default service available", provider));
                        }
                    }
                }
            }
        }
        _ => {
            // æ²¡æœ‰é…ç½®é»˜è®¤æ¨¡å‹ï¼Œå°è¯•ä½¿ç”¨ "default" æœåŠ¡
            log::warn!("No default chat model configured, trying to use 'default' service");
            match ai_service_manager.get_service("default") {
                Some(service) => Arc::new(service),
                None => {
                    return Err("No default AI model configured and no default service available".to_string());
                }
            }
        }
    };

    // åºåˆ—åŒ– config
    let config_json = serde_json::to_value(&config).map_err(|e| e.to_string())?;

    // åˆ›å»º ReactEngine
    let engine = ReactEngine::new(config).with_services(
        ai_service,
        ai_service_manager.get_mcp_service(),
        Some(db_service.clone()),
        Some(app.clone()),
    );

    // åˆ›å»º AgentTask
    let task = AgentTask {
        id: execution_id.clone(),
        description: request.query.clone(),
        target: None,
        parameters: {
            let mut map = HashMap::new();
            map.insert("query".to_string(), serde_json::json!(request.query));
            map.insert("config".to_string(), config_json);

            // **å…³é”®ä¿®å¤**: å°† tools_allow å’Œ tools_deny ä» options é€ä¼ åˆ° task.parameters é¡¶å±‚
            // ReAct executor çš„ build_tools_information ä¼šä»è¿™é‡Œè¯»å–
            if let Some(tools_allow) = options.get("tools_allow") {
                log::info!("ReAct dispatch: é€ä¼  tools_allow åˆ° task.parameters");
                map.insert("tools_allow".to_string(), tools_allow.clone());
            }
            if let Some(tools_deny) = options.get("tools_deny") {
                log::info!("ReAct dispatch: é€ä¼  tools_deny åˆ° task.parameters");
                map.insert("tools_deny".to_string(), tools_deny.clone());
            }

            // æ·»åŠ  conversation_id å’Œ message_id åˆ° parametersï¼Œè®© ReAct å¼•æ“èƒ½å¤Ÿæå–
            if let Some(conv_id) = &request.conversation_id {
                map.insert("conversation_id".to_string(), serde_json::json!(conv_id));
            }
            if let Some(msg_id) = &request.message_id {
                map.insert("message_id".to_string(), serde_json::json!(msg_id));
            }
            map
        },
        user_id: "default".to_string(),
        priority: TaskPriority::Normal,
        timeout: Some(max_iterations as u64 * 30000), // 30s per iteration
    };

    // åˆ›å»º dummy session ç”¨äºæ‰§è¡Œ
    use crate::agents::traits::{AgentSession, AgentSessionStatus, LogLevel, AgentExecutionResult, SessionLog};
    struct DummySession {
        task: AgentTask,
        status: AgentSessionStatus,
        logs: Vec<SessionLog>,
        result: Option<AgentExecutionResult>,
    }

    #[async_trait::async_trait]
    impl AgentSession for DummySession {
        fn get_session_id(&self) -> &str { "dummy" }
        fn get_task(&self) -> &AgentTask { &self.task }
        fn get_status(&self) -> AgentSessionStatus { self.status.clone() }
        async fn update_status(&mut self, status: AgentSessionStatus) -> anyhow::Result<()> {
            self.status = status;
            Ok(())
        }
        async fn add_log(&mut self, level: LogLevel, message: String) -> anyhow::Result<()> {
            self.logs.push(SessionLog {
                level,
                message,
                timestamp: chrono::Utc::now(),
                source: "react".to_string(),
            });
            Ok(())
        }
        fn get_logs(&self) -> &[SessionLog] { &self.logs }
        async fn set_result(&mut self, result: AgentExecutionResult) -> anyhow::Result<()> {
            self.result = Some(result);
            Ok(())
        }
        fn get_result(&self) -> Option<&AgentExecutionResult> { self.result.as_ref() }
    }

    let mut session = DummySession {
        task,
        status: AgentSessionStatus::Executing,
        logs: Vec::new(),
        result: None,
    };

    // æ‰§è¡Œä»»åŠ¡ - å…ˆå…‹éš† task é¿å…å€Ÿç”¨å†²çª
    let task_clone = session.task.clone();
    let start_time = std::time::Instant::now();
    match engine.execute(&task_clone, &mut session).await {
        Ok(result) => {
            let duration_ms = start_time.elapsed().as_millis() as u64;
            // ä» result.data ä¸­æå–å“åº”æ–‡æœ¬
            let response = if let Some(data) = &result.data {
                data.as_str().unwrap_or("").to_string()
            } else {
                "ReAct execution completed".to_string()
            };

            Ok(DispatchResult {
                execution_id,
                initial_response: response,
                execution_plan: None,
                estimated_duration: duration_ms,
                selected_architecture: "ReAct".to_string(),
            })
        }
        Err(e) => Err(format!("ReAct execution failed: {}", e))
    }
}

async fn dispatch_with_rewoo(
    execution_id: String,
    request: DispatchQueryRequest,
    ai_service_manager: Arc<AiServiceManager>,
    db_service: Arc<DatabaseService>,
    _execution_manager: Arc<crate::managers::ExecutionManager>,
    app: AppHandle,
) -> Result<DispatchResult, String> {
    log::info!("Creating ReWOO dispatch for: {}", request.query);

    // åˆ›å»ºReWOOå¼•æ“é…ç½®
    let config = ReWOOConfig::default();

    // åˆ›å»ºReWOOå¼•æ“
    let mut engine = ReWooEngine::new_with_dependencies(
        ai_service_manager.clone(),
        config,
        db_service.clone(),
    ).await.map_err(|e| format!("Failed to create ReWOO engine: {}", e))?;

    // è®¾ç½®app_handleç”¨äºæ¨é€æ‰§è¡Œç»“æœåˆ°å‰ç«¯
    engine.set_app_handle(app.clone());

    // åˆ›å»ºAgentä»»åŠ¡
    let mut task_params = request.options.unwrap_or_default();

    // æ·»åŠ  conversation_id å’Œ message_id åˆ° parameters
    if let Some(conv_id) = &request.conversation_id {
        task_params.insert("conversation_id".to_string(), serde_json::json!(conv_id));
    }
    if let Some(msg_id) = &request.message_id {
        task_params.insert("message_id".to_string(), serde_json::json!(msg_id));
    }
    task_params.insert("execution_id".to_string(), serde_json::json!(execution_id));

    let task = AgentTask {
        id: execution_id.clone(),
        user_id: "system".to_string(),
        description: request.query.clone(),
        priority: TaskPriority::Normal,
        target: None,
        parameters: task_params.clone(),
        timeout: Some(300), // 5åˆ†é’Ÿè¶…æ—¶
    };

    // è®¾ç½®è¿è¡Œæ—¶å‚æ•°
    engine.set_runtime_params(task_params);

    // æ‰§è¡ŒReWOOæµç¨‹
    let start_time = std::time::Instant::now();
    match engine.execute(&task).await {
        Ok(result) => {
            let duration_ms = start_time.elapsed().as_millis() as u64;

            // ä» result.data ä¸­æå–å“åº”æ–‡æœ¬
            let response = if let Some(data) = &result.data {
                if let Some(result_str) = data.get("result").and_then(|v| v.as_str()) {
                    result_str.to_string()
                } else {
                    data.to_string()
                }
            } else {
                "ReWOO execution completed".to_string()
            };

            Ok(DispatchResult {
                execution_id,
                initial_response: response,
                execution_plan: None,
                estimated_duration: duration_ms,
                selected_architecture: "ReWOO".to_string(),
            })
        }
        Err(e) => Err(format!("ReWOO execution failed: {}", e))
    }
}

async fn dispatch_with_llm_compiler(
    execution_id: String,
    request: DispatchQueryRequest,
    ai_service_manager: Arc<AiServiceManager>,
    db_service: Arc<DatabaseService>,
    execution_manager: Arc<crate::managers::ExecutionManager>,
    app: AppHandle,
) -> Result<DispatchResult, String> {
    // info!("Creating LLMCompiler dispatch for: {}", request.query);

    // åˆ›å»ºLLMCompilerå¼•æ“é…ç½®
    let config = LlmCompilerConfig::default();

    // åˆ›å»ºLLMCompilerå¼•æ“
    let mut engine = LlmCompilerEngine::new_with_dependencies(
        ai_service_manager.clone(),
        config,
        db_service.clone(),
    ).await.map_err(|e| format!("Failed to create LLMCompiler engine: {}", e))?;

    // âœ… è®¾ç½®app_handleç”¨äºæ¨é€å·¥å…·æ‰§è¡Œç»“æœåˆ°å‰ç«¯
    engine.set_app_handle(app.clone());

    // åˆ›å»ºAgentä»»åŠ¡
    let task = AgentTask {
        id: execution_id.clone(),
        user_id: "system".to_string(),
        description: request.query.clone(),
        priority: TaskPriority::High, // LLMCompileré€‚åˆé«˜ä¼˜å…ˆçº§ä»»åŠ¡
        target: None,
        parameters: request.options.unwrap_or_default(),
        timeout: Some(240), // 4åˆ†é’Ÿè¶…æ—¶
    };

    // âœ… æ³¨å…¥è¿è¡ŒæœŸå‚æ•°ï¼ŒåŒ…æ‹¬ç”¨æˆ·çš„ä»»åŠ¡æè¿°
    let mut runtime_params = task.parameters.clone();
    runtime_params.insert(
        "task_description".to_string(),
        serde_json::Value::String(task.description.clone())
    );
    engine.set_runtime_params(runtime_params);

    // åˆ›å»ºæ‰§è¡Œè®¡åˆ’
    let plan = engine.create_plan(&task).await
        .map_err(|e| format!("Failed to create LLMCompiler plan: {}", e))?;

    // æ³¨å†Œæ‰§è¡Œä¸Šä¸‹æ–‡å’Œå¼•æ“å®ä¾‹åˆ°æ‰§è¡Œç®¡ç†å™¨
    let engine_instance = crate::managers::EngineInstance::LLMCompiler(engine);
    execution_manager.register_execution(
        execution_id.clone(),
        crate::managers::EngineType::LLMCompiler,
        plan.clone(),
        task,
        engine_instance,
    ).await.map_err(|e| format!("Failed to register execution: {}", e))?;

    let execution_plan = ExecutionPlanView {
        id: plan.id.clone(),
        name: plan.name.clone(),
        description: format!("LLMCompilerå¹¶è¡Œä»»åŠ¡: {}", request.query),
        steps: plan.steps.iter().map(|step| ExecutionStepView {
            id: step.id.clone(),
            name: step.name.clone(),
            description: step.description.clone(),
            status: "pending".to_string(),
            estimated_duration: 30, // LLMCompileræ­¥éª¤é€šå¸¸æ›´å¿«
        }).collect(),
        estimated_duration: plan.estimated_duration,
    };

    Ok(DispatchResult {
        execution_id,
        initial_response: "å·²å¯åŠ¨LLMCompilerå¹¶è¡Œæ‰§è¡Œå¼•æ“ï¼Œå¼•æ“å®ä¾‹å·²æ³¨å†Œï¼Œå‡†å¤‡çœŸå®æ‰§è¡Œ...".to_string(),
        execution_plan: Some(execution_plan),
        estimated_duration: plan.estimated_duration,
        selected_architecture: "LLMCompiler".to_string(),
    })
}


/// Travelæ¶æ„è°ƒåº¦
async fn dispatch_with_travel(
    execution_id: String,
    request: DispatchQueryRequest,
    ai_service_manager: Arc<AiServiceManager>,
    db_service: Arc<DatabaseService>,
    _execution_manager: Arc<crate::managers::ExecutionManager>,
    app: AppHandle,
) -> Result<DispatchResult, String> {
    use crate::engines::travel::{TravelEngine, TravelConfig};
    use std::collections::HashMap;
    use crate::agents::traits::{AgentTask, TaskPriority};
    use crate::managers::cancellation_manager;

    info!("Creating Travel dispatch for: {}", request.query);

    // æ³¨å†Œå–æ¶ˆä»¤ç‰Œ
    let _cancellation_token = cancellation_manager::register_cancellation_token(execution_id.clone()).await;

    // ä» options ä¸­æå–é…ç½®
    let options = request.options.unwrap_or_default();
    let mut config = TravelConfig::default();

    // æå–Travelç‰¹å®šé…ç½®
    if let Some(max_cycles) = options.get("max_ooda_cycles").and_then(|v| v.as_u64()) {
        config.max_ooda_cycles = max_cycles as u32;
    }
    if let Some(strict_mode) = options.get("guardrail_strict_mode").and_then(|v| v.as_bool()) {
        config.guardrail_config.strict_mode = strict_mode;
    }
    if let Some(enable_rag) = options.get("enable_threat_intel_rag").and_then(|v| v.as_bool()) {
        config.threat_intel_config.enable_rag = enable_rag;
    }
    if let Some(enable_cve) = options.get("enable_threat_intel_cve").and_then(|v| v.as_bool()) {
        config.threat_intel_config.enable_cve_tool = enable_cve;
    }

    // å·¥å…·ç™½åå•/é»‘åå•
    if let Some(tools_allow) = options.get("tools_allow") {
        if let Some(arr) = tools_allow.as_array() {
            let tool_names: Vec<String> = arr.iter()
                .filter_map(|v| v.as_str().map(|s| s.to_string()))
                .collect();
            log::info!("Travel dispatch: è®¾ç½® allowed_tools = {:?}", tool_names);
            // Travelçš„å·¥å…·ç™½åå•å°†é€šè¿‡task parametersä¼ é€’
        }
    }

    // è·å–é»˜è®¤ AI æœåŠ¡
    let ai_service = match ai_service_manager.get_default_chat_model().await {
        Ok(Some((provider, model))) => {
            match ai_service_manager.get_provider_config(&provider).await {
                Ok(Some(mut provider_config)) => {
                    provider_config.model = model;
                    let mcp_service = ai_service_manager.get_mcp_service();
                    let ai_svc = crate::services::ai::AiService::new(
                        provider_config,
                        db_service.clone(),
                        Some(app.clone()),
                        mcp_service.clone(),
                    );
                    Arc::new(ai_svc)
                }
                _ => {
                    log::warn!("Failed to get provider config for '{}', falling back to 'default' service", provider);
                    match ai_service_manager.get_service("default") {
                        Some(service) => Arc::new(service),
                        None => {
                            return Err(format!("Failed to get AI provider config for '{}' and no default service available", provider));
                        }
                    }
                }
            }
        }
        _ => {
            log::warn!("No default chat model configured, trying to use 'default' service");
            match ai_service_manager.get_service("default") {
                Some(service) => Arc::new(service),
                None => {
                    return Err("No default AI model configured and no default service available".to_string());
                }
            }
        }
    };

    // åˆ›å»º PromptRepository
    let prompt_repo = Arc::new(crate::services::prompt_db::PromptRepository::new(
        db_service.get_pool().map_err(|e| e.to_string())?.clone()
    ));
    
    // è·å– FrameworkToolAdapter - ä»å…¨å±€å·¥å…·ç³»ç»ŸåŠ¨æ€è·å–ï¼ˆç¡®ä¿åŒ…å«æœ€æ–°æ³¨å†Œçš„å·¥å…·ï¼‰
    let framework_adapter: Option<std::sync::Arc<dyn crate::tools::FrameworkToolAdapter>> = 
        if let Ok(tool_system) = crate::tools::get_global_tool_system() {
            let tool_manager = tool_system.get_manager();
            // åˆ›å»ºæ–°çš„ LLMCompilerAdapterï¼Œä½¿ç”¨å½“å‰çš„ tool_managerï¼ˆåŒ…å«æ‰€æœ‰å·²æ³¨å†Œçš„å·¥å…·ï¼‰
            let adapter = crate::tools::framework_adapters::LLMCompilerAdapter::new(tool_manager);
            log::info!("Travel dispatch: Created LLMCompilerAdapter for TravelEngine");
            Some(std::sync::Arc::new(adapter))
        } else {
            log::warn!("Travel dispatch: Global tool system not available, framework_adapter will be None");
            None
        };

    // è·å– MCP æœåŠ¡ï¼ˆç”¨äº VisionExplorerï¼‰
    let mcp_service = ai_service_manager.get_mcp_service();
    
    // åˆ›å»º TravelEngine å¹¶è®¾ç½®ä¾èµ–
    let mut engine = TravelEngine::new(config)
        .with_ai_service(ai_service.clone())
        .with_prompt_repo(prompt_repo)
        .with_app_handle(app.clone());
    
    // è®¾ç½® MCP æœåŠ¡ï¼ˆç”¨äº VisionExplorerï¼‰
    if let Some(mcp) = mcp_service {
        engine = engine.with_mcp_service(mcp);
        log::info!("Travel dispatch: MCP service configured for VisionExplorer");
    } else {
        log::warn!("Travel dispatch: MCP service not available, VisionExplorer will be disabled");
    }
    
    // è®¾ç½® PassiveScanStateï¼ˆç”¨äº VisionExplorer å¯åŠ¨ä»£ç†ï¼‰
    if let Some(passive_state) = app.try_state::<crate::commands::passive_scan_commands::PassiveScanState>() {
        let passive_state_arc = Arc::new(passive_state.inner().clone());
        engine = engine.with_passive_scan_state(passive_state_arc.clone());
        log::info!("Travel dispatch: PassiveScanState configured for VisionExplorer");
        
        // è·å– PassiveDatabaseServiceï¼ˆç”¨äº VisionExplorer è·å–ä»£ç†è¯·æ±‚ï¼‰
        match passive_state.get_db_service().await {
            Ok(db) => {
                engine = engine.with_passive_db(db);
                log::info!("Travel dispatch: PassiveDatabaseService configured for VisionExplorer");
            }
            Err(e) => {
                log::warn!("Travel dispatch: Failed to get PassiveDatabaseService: {}", e);
            }
        }
    } else {
        log::warn!("Travel dispatch: PassiveScanState not available, VisionExplorer won't auto-start proxy");
    }
    
    // è®¾ç½® framework_adapterï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if let Some(adapter) = framework_adapter {
        engine = engine.with_framework_adapter(adapter);
    }

    // ä½¿ç”¨ LLM ä» query ä¸­æ™ºèƒ½æå–ç›®æ ‡ä¿¡æ¯å’Œä»»åŠ¡ç±»å‹
    let (target_info, task_type, target_type) = extract_target_with_llm(&request.query, &ai_service).await;
    
    log::info!("Travel dispatch: ä»»åŠ¡ç±»å‹={}, ç›®æ ‡={:?}, ç›®æ ‡ç±»å‹={}", task_type, target_info, target_type);
    
    // åˆ›å»º AgentTask
    let task = AgentTask {
        id: execution_id.clone(),
        description: request.query.clone(),
        target: target_info.clone(),
        parameters: {
            let mut map = HashMap::new();
            map.insert("query".to_string(), serde_json::json!(request.query));

            // é€ä¼ å·¥å…·ç™½åå•/é»‘åå•
            if let Some(tools_allow) = options.get("tools_allow") {
                map.insert("tools_allow".to_string(), tools_allow.clone());
            }
            if let Some(tools_deny) = options.get("tools_deny") {
                map.insert("tools_deny".to_string(), tools_deny.clone());
            }

            // æ·»åŠ  conversation_id å’Œ message_id
            if let Some(conv_id) = &request.conversation_id {
                map.insert("conversation_id".to_string(), serde_json::json!(conv_id));
            }
            if let Some(msg_id) = &request.message_id {
                map.insert("message_id".to_string(), serde_json::json!(msg_id));
            }

            // æ·»åŠ ç›®æ ‡ä¿¡æ¯å’Œä»»åŠ¡ç±»å‹
            if let Some(target) = options.get("target") {
                map.insert("target".to_string(), target.clone());
            } else if let Some(target) = &target_info {
                // å¦‚æœ options ä¸­æ²¡æœ‰ targetï¼Œä½¿ç”¨ä» query ä¸­æå–çš„ç›®æ ‡
                map.insert("target".to_string(), serde_json::json!(target));
            }
            
            // æ·»åŠ ä»»åŠ¡ç±»å‹å’Œç›®æ ‡ç±»å‹
            map.insert("task_type".to_string(), serde_json::json!(task_type));
            map.insert("target_type".to_string(), serde_json::json!(target_type));

            // æ·»åŠ æˆæƒä¿¡æ¯
            if let Some(authorized) = options.get("authorized") {
                map.insert("authorized".to_string(), authorized.clone());
            } else {
                // é»˜è®¤æˆæƒï¼ˆç”¨äºæµ‹è¯•ï¼‰
                map.insert("authorized".to_string(), serde_json::json!(true));
            }

            map
        },
        user_id: "default".to_string(),
        priority: TaskPriority::Normal,
        timeout: Some(300000), // 5 minutes default timeout
    };

    // åˆ›å»º dummy session
    use crate::agents::traits::{AgentSession, AgentSessionStatus, LogLevel, AgentExecutionResult, SessionLog};
    struct DummySession {
        task: AgentTask,
        status: AgentSessionStatus,
        logs: Vec<SessionLog>,
        result: Option<AgentExecutionResult>,
    }

    #[async_trait::async_trait]
    impl AgentSession for DummySession {
        fn get_session_id(&self) -> &str { "dummy" }
        fn get_task(&self) -> &AgentTask { &self.task }
        fn get_status(&self) -> AgentSessionStatus { self.status.clone() }
        async fn update_status(&mut self, status: AgentSessionStatus) -> anyhow::Result<()> {
            self.status = status;
            Ok(())
        }
        async fn add_log(&mut self, level: LogLevel, message: String) -> anyhow::Result<()> {
            self.logs.push(SessionLog {
                level,
                message,
                timestamp: chrono::Utc::now(),
                source: "travel".to_string(),
            });
            Ok(())
        }
        fn get_logs(&self) -> &[SessionLog] { &self.logs }
        async fn set_result(&mut self, result: AgentExecutionResult) -> anyhow::Result<()> {
            self.result = Some(result);
            Ok(())
        }
        fn get_result(&self) -> Option<&AgentExecutionResult> { self.result.as_ref() }
    }

    let mut session = DummySession {
        task,
        status: AgentSessionStatus::Executing,
        logs: Vec::new(),
        result: None,
    };

    // æ‰§è¡Œä»»åŠ¡
    let task_clone = session.task.clone();
    let start_time = std::time::Instant::now();
    match engine.execute(&task_clone, &mut session).await {
        Ok(result) => {
            let duration_ms = start_time.elapsed().as_millis() as u64;
            
            // ä» result.data ä¸­æå–å“åº”
            let response = if let Some(data) = &result.data {
                if let Some(output) = data.get("output") {
                    serde_json::to_string_pretty(output).unwrap_or_else(|_| "Travel execution completed".to_string())
                } else {
                    serde_json::to_string_pretty(data).unwrap_or_else(|_| "Travel execution completed".to_string())
                }
            } else {
                "Travel OODA execution completed".to_string()
            };

            Ok(DispatchResult {
                execution_id,
                initial_response: response,
                execution_plan: None,
                estimated_duration: duration_ms,
                selected_architecture: "Travel".to_string(),
            })
        }
        Err(e) => Err(format!("Travel execution failed: {}", e))
    }
}

/// ä½¿ç”¨ LLM ä»æŸ¥è¯¢æ–‡æœ¬ä¸­æå–ç›®æ ‡ä¿¡æ¯å’Œä»»åŠ¡ç±»å‹
async fn extract_target_with_llm(
    query: &str,
    ai_service: &Arc<crate::services::ai::AiService>,
) -> (Option<String>, String, String) {
    let system_prompt = r#"ä½ æ˜¯ä¸€ä¸ªå®‰å…¨æµ‹è¯•ä»»åŠ¡åˆ†æä¸“å®¶ã€‚è¯·åˆ†æç”¨æˆ·è¾“å…¥ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼ˆåªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼‰ï¼š
{
  "task_type": "ä»»åŠ¡ç±»å‹",
  "target": "ç›®æ ‡å¯¹è±¡",
  "target_type": "ç›®æ ‡ç±»å‹"
}

**ä»»åŠ¡ç±»å‹(task_type)é€‰é¡¹ï¼š**
- web_pentest: Webæ¸—é€æµ‹è¯•ï¼ˆç½‘ç«™å®‰å…¨æµ‹è¯•ã€æ¼æ´æ‰«æï¼‰
- api_pentest: APIå®‰å…¨æµ‹è¯•ï¼ˆREST APIã€GraphQLæµ‹è¯•ï¼‰
- code_audit: ä»£ç å®¡è®¡ï¼ˆæºç å®¡è®¡ã€SASTã€ä»£ç æ‰«æï¼‰
- ctf: CTFå¤ºæ——èµ›ï¼ˆè§£é¢˜ã€challengeï¼‰
- reverse_engineering: é€†å‘å·¥ç¨‹ï¼ˆäºŒè¿›åˆ¶åˆ†æã€åç¼–è¯‘ï¼‰
- forensics: æ•°å­—å–è¯ï¼ˆæ—¥å¿—åˆ†æã€äº‹ä»¶è°ƒæŸ¥ï¼‰
- mobile_security: ç§»åŠ¨åº”ç”¨å®‰å…¨ï¼ˆAndroid/iOSæµ‹è¯•ï¼‰
- cloud_security: äº‘å®‰å…¨è¯„ä¼°ï¼ˆAWS/Azure/GCPé…ç½®å®¡è®¡ï¼‰
- iot_security: ç‰©è”ç½‘/å·¥æ§å®‰å…¨ï¼ˆæ™ºèƒ½è®¾å¤‡ã€SCADAï¼‰
- network_pentest: ç½‘ç»œæ¸—é€ï¼ˆå†…ç½‘æ¸—é€ã€ç«¯å£æ‰«æï¼‰
- social_engineering: ç¤¾ä¼šå·¥ç¨‹å­¦ï¼ˆé’“é±¼æµ‹è¯•ï¼‰
- other: å…¶ä»–å®‰å…¨æµ‹è¯•

**ç›®æ ‡ç±»å‹(target_type)é€‰é¡¹ï¼š**
- url: HTTP/HTTPSç½‘å€
- file_path: æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„
- github_repo: GitHubä»“åº“ï¼ˆowner/repoæ ¼å¼ï¼‰
- ip_address: IPåœ°å€æˆ–IPæ®µï¼ˆCIDRï¼‰
- domain: åŸŸå
- binary_file: äºŒè¿›åˆ¶æ–‡ä»¶
- mobile_app: ç§»åŠ¨åº”ç”¨ï¼ˆåŒ…åæˆ–APK/IPAï¼‰
- cloud_resource: äº‘èµ„æºæ ‡è¯†
- none: æ— æ˜ç¡®ç›®æ ‡

**æå–è§„åˆ™ï¼š**
1. è¯†åˆ«æŸ¥è¯¢ä¸­çš„å…³é”®è¯ï¼Œåˆ¤æ–­ä»»åŠ¡ç±»å‹
2. æå–å…·ä½“çš„ç›®æ ‡å¯¹è±¡ï¼ˆURLã€è·¯å¾„ã€ä»“åº“ç­‰ï¼‰
3. å¦‚æœæ²¡æœ‰æ˜ç¡®ç›®æ ‡ï¼Œtargetè®¾ä¸ºnull
4. ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ï¼Œç¡®ä¿å¯è§£æ

ç¤ºä¾‹ï¼š
- "å¯¹ http://example.com è¿›è¡Œæ¸—é€æµ‹è¯•" â†’ {"task_type":"web_pentest","target":"http://example.com","target_type":"url"}
- "å®¡è®¡ /path/to/code çš„ä»£ç " â†’ {"task_type":"code_audit","target":"/path/to/code","target_type":"file_path"}
- "è§£è¿™é“CTFé¢˜" â†’ {"task_type":"ctf","target":null,"target_type":"none"}"#;

    let user_prompt = format!(r#"ç”¨æˆ·è¾“å…¥ï¼š"{}"

è¯·æå–ä»»åŠ¡ç±»å‹ã€ç›®æ ‡å’Œç›®æ ‡ç±»å‹ï¼Œè¿”å›JSONæ ¼å¼ã€‚"#, query);

    // ä½¿ç”¨ç»Ÿä¸€çš„ LlmClient
    let llm_client = crate::engines::create_client(&ai_service);
    
    match llm_client.completion(Some(system_prompt), &user_prompt).await {
        Ok(response) => {
            log::debug!("LLM extraction response: {}", response);
            
            // å°è¯•ä»å“åº”ä¸­æå–JSONï¼ˆå¯èƒ½åŒ…å«markdownä»£ç å—ï¼‰
            let json_str: String = if response.contains("```json") {
                // æå– ```json ... ``` ä¸­çš„å†…å®¹
                if let Some(start) = response.find("```json") {
                    let json_start = start + 7; // "```json".len()
                    if let Some(end_pos) = response[json_start..].find("```") {
                        response[json_start..json_start + end_pos].trim().to_string()
                    } else {
                        response.trim().to_string()
                    }
                } else {
                    response.trim().to_string()
                }
            } else if response.contains("```") {
                // æå– ``` ... ``` ä¸­çš„å†…å®¹
                if let Some(start) = response.find("```") {
                    let content_start = start + 3;
                    if let Some(end_pos) = response[content_start..].find("```") {
                        response[content_start..content_start + end_pos].trim().to_string()
                    } else {
                        response.trim().to_string()
                    }
                } else {
                    response.trim().to_string()
                }
            } else {
                response.trim().to_string()
            };
            
            // è§£æ JSON
            if let Ok(json) = serde_json::from_str::<serde_json::Value>(&json_str) {
                let task_type = json.get("task_type")
                    .and_then(|v| v.as_str())
                    .unwrap_or("other")
                    .to_string();
                
                let target = json.get("target")
                    .and_then(|v| {
                        if v.is_null() {
                            None
                        } else {
                            v.as_str().map(|s| s.to_string())
                        }
                    });
                
                let target_type = json.get("target_type")
                    .and_then(|v| v.as_str())
                    .unwrap_or("none")
                    .to_string();
                
                log::info!("âœ… LLM extraction - task_type: {}, target: {:?}, target_type: {}", 
                    task_type, target, target_type);
                
                return (target, task_type, target_type);
            } else {
                log::warn!("Failed to parse LLM response as JSON: {}", json_str);
            }
        }
        Err(e) => {
            log::error!("Failed to call LLM for target extraction: {}", e);
        }
    }
    
    // é™çº§ï¼šä½¿ç”¨ç®€å•çš„æ­£åˆ™æå–
    log::info!("âš ï¸ Falling back to regex-based extraction");
    fallback_extract_target(query)
}

/// é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–ç›®æ ‡
fn fallback_extract_target(query: &str) -> (Option<String>, String, String) {
    let query_lower = query.to_lowercase();
    
    // 1. å°è¯•æå– URL
    if let Ok(url_regex) = regex::Regex::new(r"https?://[^\s]+") {
        if let Some(m) = url_regex.find(query) {
            let url = m.as_str().to_string();
            let task_type = if query_lower.contains("api") {
                "api_pentest"
            } else {
                "web_pentest"
            };
            return (Some(url), task_type.to_string(), "url".to_string());
        }
    }
    
    // 2. å°è¯•æå–æ–‡ä»¶è·¯å¾„
    let path_patterns = vec![
        r"/[^\s]+",                 // Unix è·¯å¾„
        r"[A-Z]:\\[^\s]+",          // Windows è·¯å¾„
        r"\./[^\s]+",               // ç›¸å¯¹è·¯å¾„
        r"~/[^\s]+",                // Home è·¯å¾„
    ];
    
    for pattern in path_patterns {
        if let Ok(regex) = regex::Regex::new(pattern) {
            if let Some(m) = regex.find(query) {
                let path = m.as_str().to_string();
                let task_type = if query_lower.contains("ä»£ç ") || query_lower.contains("code") || query_lower.contains("å®¡è®¡") {
                    "code_audit"
                } else if query_lower.contains("ctf") || query_lower.contains("é¢˜") {
                    "ctf"
                } else if query_lower.contains("é€†å‘") || query_lower.contains("reverse") {
                    "reverse_engineering"
                } else if query_lower.contains("å–è¯") || query_lower.contains("forensics") || query_lower.contains("æ—¥å¿—") {
                    "forensics"
                } else {
                    "other"
                };
                return (Some(path), task_type.to_string(), "file_path".to_string());
            }
        }
    }
    
    // 3. å°è¯•æå– GitHub ä»“åº“
    if let Ok(regex) = regex::Regex::new(r"github\.com/([a-zA-Z0-9_-]+/[a-zA-Z0-9_-]+)") {
        if let Some(captures) = regex.captures(query) {
            if let Some(repo) = captures.get(1) {
                return (
                    Some(repo.as_str().to_string()),
                    "code_audit".to_string(),
                    "github_repo".to_string()
                );
            }
        }
    }
    
    // 4. å°è¯•æå– IP åœ°å€
    if let Ok(regex) = regex::Regex::new(r"\b(?:\d{1,3}\.){3}\d{1,3}(?:/\d{1,2})?\b") {
        if let Some(m) = regex.find(query) {
            return (
                Some(m.as_str().to_string()),
                "network_pentest".to_string(),
                "ip_address".to_string()
            );
        }
    }
    
    // 5. æ ¹æ®å…³é”®è¯æ¨æ–­ä»»åŠ¡ç±»å‹
    let task_type = if query_lower.contains("ä»£ç ") || query_lower.contains("code") || query_lower.contains("å®¡è®¡") {
        "code_audit"
    } else if query_lower.contains("ctf") || query_lower.contains("å¤ºæ——") {
        "ctf"
    } else if query_lower.contains("é€†å‘") || query_lower.contains("reverse") {
        "reverse_engineering"
    } else if query_lower.contains("å–è¯") || query_lower.contains("forensics") {
        "forensics"
    } else if query_lower.contains("api") {
        "api_pentest"
    } else if query_lower.contains("ç§»åŠ¨") || query_lower.contains("mobile") || query_lower.contains("android") || query_lower.contains("ios") {
        "mobile_security"
    } else if query_lower.contains("äº‘") || query_lower.contains("cloud") || query_lower.contains("aws") || query_lower.contains("azure") {
        "cloud_security"
    } else if query_lower.contains("ç½‘ç»œ") || query_lower.contains("network") || query_lower.contains("å†…ç½‘") {
        "network_pentest"
    } else {
        "other"
    };
    
    // æ²¡æœ‰æ‰¾åˆ°æ˜ç¡®ç›®æ ‡
    (None, task_type.to_string(), "none".to_string())
}

// ============================================================================
// è‡ªå®šä¹‰ AI æä¾›å•†ç›¸å…³å‘½ä»¤
// ============================================================================

/// æµ‹è¯•è‡ªå®šä¹‰æä¾›å•†è¯·æ±‚å‚æ•°
#[derive(Debug, Serialize, Deserialize)]
pub struct TestCustomProviderRequest {
    pub name: String,
    pub api_key: Option<String>,
    pub api_base: String,
    pub model_id: String,
    pub compat_mode: String, // openai, anthropic, rig_openai, rig_anthropic
    pub extra_headers: Option<std::collections::HashMap<String, String>>,
    pub timeout: Option<u64>,
}

/// æµ‹è¯•è‡ªå®šä¹‰æä¾›å•†å“åº”
#[derive(Debug, Serialize, Deserialize)]
pub struct TestCustomProviderResponse {
    pub success: bool,
    pub message: String,
}

/// æ·»åŠ è‡ªå®šä¹‰æä¾›å•†è¯·æ±‚å‚æ•°
#[derive(Debug, Serialize, Deserialize)]
pub struct AddCustomProviderRequest {
    pub name: String,
    pub display_name: String,
    pub api_key: Option<String>,
    pub api_base: String,
    pub model_id: String,
    pub compat_mode: String,
    pub extra_headers: Option<std::collections::HashMap<String, String>>,
    pub timeout: Option<u64>,
    pub max_retries: Option<u32>,
}

/// æµ‹è¯•è‡ªå®šä¹‰ AI æä¾›å•†è¿æ¥
#[tauri::command]
pub async fn test_custom_provider(
    request: TestCustomProviderRequest,
) -> Result<TestCustomProviderResponse, String> {
    info!("Testing custom provider: {} (mode: {})", request.name, request.compat_mode);
    
    // ä½¿ç”¨ rig-core æµ‹è¯•æ‰€æœ‰æä¾›å•†
    let result = test_with_rig(&request).await;
    
    match result {
        Ok(msg) => Ok(TestCustomProviderResponse {
            success: true,
            message: msg,
        }),
        Err(e) => Ok(TestCustomProviderResponse {
            success: false,
            message: format!("Connection test failed: {}", e),
        }),
    }
}

/// ä½¿ç”¨ rig-core æµ‹è¯•è¿æ¥
async fn test_with_rig(request: &TestCustomProviderRequest) -> Result<String, String> {
    use rig::client::{CompletionClient, ProviderClient};
    use rig::completion::Prompt;
    
    let provider = if request.compat_mode == "rig_anthropic" {
        "anthropic"
    } else {
        "openai"
    };
    
    // è®¾ç½®ç¯å¢ƒå˜é‡
    if let Some(api_key) = &request.api_key {
        match provider {
            "anthropic" => {
                std::env::set_var("ANTHROPIC_API_KEY", api_key);
                std::env::set_var("ANTHROPIC_API_BASE", &request.api_base);
            }
            _ => {
                std::env::set_var("OPENAI_API_KEY", api_key);
                std::env::set_var("OPENAI_API_BASE", &request.api_base);
                std::env::set_var("OPENAI_BASE_URL", &request.api_base);
            }
        }
    }
    
    let timeout = std::time::Duration::from_secs(request.timeout.unwrap_or(30));
    
    // æ ¹æ® provider åˆ›å»º agent
    let response = if provider == "anthropic" {
        use rig::providers::anthropic;
        let client = anthropic::Client::from_env();
        let agent = client.agent(&request.model_id).max_tokens(1024).build();
        tokio::time::timeout(timeout, agent.prompt("Hello, respond with 'OK' if you receive this."))
            .await
            .map_err(|_| "Request timeout".to_string())?
            .map_err(|e| format!("Request failed: {}", e))?
    } else {
        use rig::providers::openai;
        let client = openai::Client::from_env();
        let agent = client.agent(&request.model_id).build();
        tokio::time::timeout(timeout, agent.prompt("Hello, respond with 'OK' if you receive this."))
            .await
            .map_err(|_| "Request timeout".to_string())?
            .map_err(|e| format!("Request failed: {}", e))?
    };
    
    Ok(format!("Connection successful! Response: {}", response.chars().take(100).collect::<String>()))
}

/// æ·»åŠ è‡ªå®šä¹‰ AI æä¾›å•†
#[tauri::command]
pub async fn add_custom_provider(
    request: AddCustomProviderRequest,
    db_service: State<'_, Arc<DatabaseService>>,
    ai_manager: State<'_, Arc<AiServiceManager>>,
) -> Result<(), String> {
    info!("Adding custom provider: {} ({})", request.name, request.display_name);
    
    // è·å–ç°æœ‰çš„ providers_config
    let mut providers: serde_json::Map<String, serde_json::Value> = 
        match db_service.get_config("ai", "providers_config").await {
            Ok(Some(json_str)) => {
                serde_json::from_str(&json_str).unwrap_or_default()
            }
            _ => serde_json::Map::new(),
        };
    
    // æ„å»ºæ–°æä¾›å•†é…ç½®
    let provider_id = request.name.to_lowercase().replace(" ", "_");
    let new_provider = serde_json::json!({
        "id": provider_id,
        "provider": provider_id,
        "name": request.display_name,
        "enabled": true,
        "api_key": request.api_key,
        "api_base": request.api_base,
        "organization": null,
        "default_model": request.model_id,
        "compat_mode": request.compat_mode,
        "extra_headers": request.extra_headers,
        "timeout": request.timeout.unwrap_or(120),
        "max_retries": request.max_retries.unwrap_or(3),
        "is_custom": true,
        "models": [{
            "id": request.model_id,
            "name": request.model_id,
            "description": format!("Custom model from {}", request.display_name),
            "context_length": 4096,
            "supports_streaming": true,
            "supports_tools": false,
            "supports_vision": false,
            "is_available": true
        }]
    });
    
    // æ·»åŠ åˆ°é…ç½®
    providers.insert(request.name.clone(), new_provider);
    
    // ä¿å­˜åˆ°æ•°æ®åº“
    let config_str = serde_json::to_string(&providers)
        .map_err(|e| format!("Failed to serialize providers config: {}", e))?;
    
    db_service
        .set_config(
            "ai",
            "providers_config",
            &config_str,
            Some("AI providers configuration"),
        )
        .await
        .map_err(|e| format!("Failed to save providers config: {}", e))?;
    
    // å¦‚æœæœ‰ API Keyï¼Œå•ç‹¬ä¿å­˜ï¼ˆåŠ å¯†å­˜å‚¨ï¼‰
    if let Some(api_key) = &request.api_key {
        if !api_key.is_empty() {
            let key_name = format!("api_key_{}", provider_id);
            db_service
                .set_config("ai", &key_name, api_key, Some(&format!("{} API key", request.display_name)))
                .await
                .map_err(|e| format!("Failed to save API key: {}", e))?;
        }
    }
    
    // é‡æ–°åŠ è½½ AI æœåŠ¡
    if let Err(e) = ai_manager.reload_services().await {
        warn!("Failed to reload AI services after adding custom provider: {}", e);
    }
    
    info!("Custom provider '{}' added successfully", request.name);
    Ok(())
}

// ============================================================================
// Aliyun DashScope Commands
// ============================================================================

/// æµ‹è¯•é˜¿é‡Œäº‘ DashScope è¿æ¥
#[tauri::command]
pub async fn test_aliyun_dashscope_connection(
    api_key: String,
    model: String,
) -> Result<bool, String> {
    use crate::utils::aliyun_oss::test_dashscope_connection;
    
    info!("Testing Aliyun DashScope connection with model: {}", model);
    
    test_dashscope_connection(&api_key, &model)
        .await
        .map_err(|e| format!("Connection test failed: {}", e))
}

/// ä¸Šä¼ æ–‡ä»¶åˆ°é˜¿é‡Œäº‘ OSS
#[tauri::command]
pub async fn upload_file_to_aliyun(
    api_key: String,
    model: String,
    file_path: String,
) -> Result<crate::utils::aliyun_oss::UploadResult, String> {
    use crate::utils::aliyun_oss::upload_file_and_get_url;
    use std::path::Path;
    
    info!("Uploading file to Aliyun OSS: {}", file_path);
    
    let path = Path::new(&file_path);
    if !path.exists() {
        return Err(format!("File not found: {}", file_path));
    }
    
    upload_file_and_get_url(&api_key, &model, path)
        .await
        .map_err(|e| format!("Upload failed: {}", e))
}

/// ä½¿ç”¨æ•°æ®åº“é…ç½®ä¸Šä¼ æ–‡ä»¶åˆ°é˜¿é‡Œäº‘ OSS
#[tauri::command]
pub async fn upload_file_to_aliyun_with_config(
    db: tauri::State<'_, Arc<DatabaseService>>,
    file_path: String,
) -> Result<crate::utils::aliyun_oss::UploadResult, String> {
    use crate::utils::aliyun_oss::upload_file_and_get_url;
    use crate::services::database::Database;
    use std::path::Path;
    
    // ä»æ•°æ®åº“è¯»å–é…ç½®
    let api_key = db.get_config("ai", "aliyun_dashscope_api_key")
        .await
        .map_err(|e| format!("Failed to get API key: {}", e))?
        .ok_or("Aliyun DashScope API key not configured")?;
    
    let model = db.get_config("ai", "aliyun_dashscope_model")
        .await
        .map_err(|e| format!("Failed to get model: {}", e))?
        .unwrap_or_else(|| "qwen-vl-plus".to_string());
    
    info!("Uploading file to Aliyun OSS with saved config: {}", file_path);
    
    let path = Path::new(&file_path);
    if !path.exists() {
        return Err(format!("File not found: {}", file_path));
    }
    
    upload_file_and_get_url(&api_key, &model, path)
        .await
        .map_err(|e| format!("Upload failed: {}", e))
}
