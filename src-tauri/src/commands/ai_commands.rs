//! AIç›¸å…³å‘½ä»¤æ•´åˆæ¨¡å—
//! 
//! æ•´åˆäº†æ™ºèƒ½è°ƒåº¦å™¨å’ŒAIåŠ©æ‰‹çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
//! - æ™ºèƒ½æŸ¥è¯¢è°ƒåº¦
//! - æ‰§è¡Œç›‘æ§
//! - æ¶æ„ç®¡ç†
//! - Agentç»Ÿè®¡

use crate::services::{AiServiceManager, database::{Database, DatabaseService}};
use crate::engines::plan_and_execute::engine_adapter::PlanAndExecuteEngine;
use crate::engines::llm_compiler::engine_adapter::LlmCompilerEngine;
use crate::engines::llm_compiler::types::LlmCompilerConfig;
use crate::engines::plan_and_execute::types::PlanAndExecuteConfig;
// use crate::engines::plan_and_execute::executor::ExecutionMode; // not needed directly
use crate::agents::traits::{ExecutionEngine, AgentTask, TaskPriority};

/// åˆ›å»ºAIåŠ©æ‰‹ä¼šè¯è®°å½•
async fn create_ai_assistant_session(
    db_service: &Arc<DatabaseService>,
    execution_id: &str,
    agent_name: &str,
    task_description: &str,
) -> Result<(), String> {
    use crate::services::database::Database;
    
    // åˆ›å»ºtask_id
    let task_id = format!("{}_task", execution_id);
    
    // å…ˆåˆ›å»ºagent_taskè®°å½•ï¼ˆå› ä¸ºagent_sessionsè¡¨æœ‰å¤–é”®çº¦æŸï¼‰
    let agent_task = crate::agents::traits::AgentTask {
        id: task_id.clone(),
        user_id: "ai_assistant".to_string(),
        description: task_description.to_string(),
        priority: crate::agents::traits::TaskPriority::Normal,
        target: None,
        parameters: std::collections::HashMap::new(),
        timeout: Some(300),
    };
    
    db_service.create_agent_task(&agent_task).await
        .map_err(|e| format!("Failed to create agent task: {}", e))?;
    
    // ç„¶ååˆ›å»ºagent_sessionè®°å½•
    db_service.create_agent_session(execution_id, &task_id, agent_name).await
        .map_err(|e| format!("Failed to create agent session: {}", e))?;
    
    Ok(())
}

/// ä¿å­˜AIåŠ©æ‰‹æ‰§è¡Œè®°å½•åˆ°æ•°æ®åº“
async fn save_ai_assistant_execution(
    db_service: &Arc<DatabaseService>,
    execution_id: &str,
    _task_name: &str,
    architecture: &str,
    success: bool,
    error: Option<&str>,
    result: Option<&str>,
    started_at: u64,
    completed_at: u64,
    duration_ms: u64,
) -> Result<(), String> {
    use crate::services::database::Database;
    use crate::commands::agent_commands::WorkflowStepDetail;
    
    // ä¿å­˜æ‰§è¡Œæ­¥éª¤åˆ° agent_execution_steps è¡¨
    let step_detail = WorkflowStepDetail {
        step_id: "step_1".to_string(),
        step_name: format!("AI Assistant Task ({})", architecture),
        status: if success { "Completed".to_string() } else { "Failed".to_string() },
        started_at: Some(started_at.to_string()),
        completed_at: Some(completed_at.to_string()),
        duration_ms,
        result_data: result.map(|r| serde_json::json!(r)),
        error: error.map(|e| e.to_string()),
        retry_count: 0,
        dependencies: vec![],
        tool_result: None,
    };
    
    db_service.save_agent_execution_step(execution_id, &step_detail).await
        .map_err(|e| format!("Failed to save execution step: {}", e))?;
    
    // æ›´æ–°sessionçŠ¶æ€
    let status_str = if success { "Completed" } else { "Failed" };
    if let Err(e) = db_service.update_agent_session_status(execution_id, status_str).await {
        log::warn!("Failed to update agent session status: {}", e);
    }
    
    Ok(())
}
 


use tauri::{AppHandle, State, Emitter, Manager};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use std::collections::HashMap;
use uuid::Uuid;
use anyhow::Result;
use log::{info};

/// å‘½ä»¤å“åº”åŒ…è£…å™¨
#[derive(Debug, Serialize)]
pub struct CommandResponse<T> {
    pub success: bool,
    pub data: Option<T>,
    pub error: Option<String>,
    pub timestamp: u64,
    pub request_id: String,
}

impl<T> CommandResponse<T> {
    pub fn success(data: T) -> Self {
        Self {
            success: true,
            data: Some(data),
            error: None,
            timestamp: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap_or_default()
                .as_secs(),
            request_id: Uuid::new_v4().to_string(),
        }
    }
    
    pub fn error(message: String) -> Self {
        Self {
            success: false,
            data: None,
            error: Some(message),
            timestamp: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap_or_default()
                .as_secs(),
            request_id: Uuid::new_v4().to_string(),
        }
    }
}

// ===== æ™ºèƒ½è°ƒåº¦å™¨ç›¸å…³ç»“æ„ä½“ =====


#[derive(Debug, Serialize)]
pub struct IntelligentQueryResponse {
    pub request_id: String,
    pub execution_id: String,
    pub selected_architecture: String,
    pub task_type: String,
    pub complexity: String,
    pub reasoning: String,
    pub confidence: f32,
    pub estimated_duration: Option<f64>,
    pub workflow_status: String,
    pub started_at: String,
}

#[derive(Debug, Deserialize)]
pub struct ExecutionStatusRequest {
    pub id: String,
    pub id_type: String,
}

#[derive(Debug, Serialize)]
pub struct ExecutionStatusResponse {
    pub execution_id: String,
    pub request_id: String,
    pub status: String,
    pub progress: f32,
    pub current_step: Option<String>,
    pub completed_steps: u32,
    pub total_steps: u32,
    pub started_at: String,
    pub completed_at: Option<String>,
    pub result: Option<serde_json::Value>,
    pub error: Option<String>,
}

#[derive(Debug, Deserialize)]
pub struct ExecutionHistoryRequest {
    pub user_id: Option<String>,
    pub architecture: Option<String>,
    pub status: Option<String>,
    pub page: Option<u32>,
    pub page_size: Option<u32>,
    pub start_time: Option<String>,
    pub end_time: Option<String>,
}

#[derive(Debug, Serialize)]
pub struct ExecutionHistoryResponse {
    pub records: Vec<ExecutionHistoryItem>,
    pub total: u32,
    pub page: u32,
    pub page_size: u32,
    pub total_pages: u32,
}

#[derive(Debug, Serialize)]
pub struct ExecutionHistoryItem {
    pub request_id: String,
    pub execution_id: String,
    pub user_input: String,
    pub architecture: String,
    pub task_type: String,
    pub complexity: String,
    pub status: String,
    pub execution_time: Option<f64>,
    pub success_rate: Option<f32>,
    pub started_at: String,
    pub completed_at: Option<String>,
}

#[derive(Debug, Serialize)]
pub struct DispatcherStatistics {
    pub total_requests: f64,
    pub successful_requests: f64,
    pub failed_requests: f64,
    pub average_execution_time: f64,
    pub architecture_usage: HashMap<String, f64>,
    pub uptime_seconds: f64,
}

// ===== AIåŠ©æ‰‹ç›¸å…³ç»“æ„ä½“ =====

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DispatchQueryRequest {
    pub query: String,
    pub architecture: String,
    pub agent_id: Option<String>,
    pub options: Option<HashMap<String, serde_json::Value>>,
    pub conversation_id: Option<String>,
    pub message_id: Option<String>,
}




#[derive(Debug, Serialize, Deserialize)]
pub struct DispatchResult {
    pub execution_id: String,
    pub initial_response: String,
    pub execution_plan: Option<ExecutionPlanView>,
    pub estimated_duration: u64,
    pub selected_architecture: String,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct ExecutionPlanView {
    pub id: String,
    pub name: String,
    pub description: String,
    pub steps: Vec<ExecutionStepView>,
    pub estimated_duration: u64,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct ExecutionStepView {
    pub id: String,
    pub name: String,
    pub description: String,
    pub status: String,
    pub estimated_duration: u64,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct AIAssistantSettings {
    #[serde(default)]
    pub auto_execute: bool,
    #[serde(default = "default_notification_enabled")]
    pub notification_enabled: bool,
}

fn default_notification_enabled() -> bool {
    true
}

// ===== åœºæ™¯ Agent Profileï¼ˆæœ€å°å¯ç”¨ç‰ˆæœ¬ï¼‰=====

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "kebab-case")]
pub enum AgentEngine { 
    PlanExecute, 
    React,
    Rewoo, 
    LlmCompiler, 
    Auto 
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LlmId { pub provider: String, pub model: String, pub temperature: Option<f32>, pub max_tokens: Option<u32> }

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LlmConfigBundle { pub default: LlmId }

// Optional extended configs for scenario agents
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerStageLlm { pub planner: Option<LlmId>, pub executor: Option<LlmId>, pub replanner: Option<LlmId>, pub evaluator: Option<LlmId> }

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PromptBundle { pub system: Option<String>, pub planner: Option<String>, pub executor: Option<String>, pub replanner: Option<String>, pub evaluator: Option<String> }

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ToolPolicy { pub allow: Vec<String>, pub deny: Option<Vec<String>> }

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct RetryPolicy { pub max_retries: u32, pub backoff: String, pub interval_ms: Option<f64> }

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExecutionPolicy { pub timeout_sec: Option<f64>, pub retry: Option<RetryPolicy>, pub concurrency: Option<u32>, pub strict_mode: Option<bool> }

// Prompt template IDs bound to agent (from PromptManagement)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PromptIds {
    pub system: Option<i64>,
    pub planner: Option<i64>,
    pub executor: Option<i64>,
    pub replanner: Option<i64>,
    pub evaluator: Option<i64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ScenarioAgentProfile {
    pub id: String,
    pub name: String,
    pub description: Option<String>,
    pub enabled: bool,
    pub version: Option<String>,
    pub engine: AgentEngine,
    pub llm: LlmConfigBundle,
    #[serde(default)]
    pub prompts: Option<PromptBundle>,
    #[serde(default)]
    pub tools: Option<ToolPolicy>,
    #[serde(default)]
    pub execution: Option<ExecutionPolicy>,
    #[serde(default)]
    pub prompt_ids: Option<PromptIds>,
    // Unified prompt system fields
    #[serde(default)]
    pub prompt_strategy: Option<String>,
    #[serde(default)]
    pub group_id: Option<i64>,
    #[serde(default)]
    pub pinned_versions: Option<std::collections::HashMap<i64, String>>,    
    #[serde(default)]
    pub pre_hooks: Option<Vec<String>>,
    #[serde(default)]
    pub post_hooks: Option<Vec<String>>,
    pub created_at: Option<String>,
    pub updated_at: Option<String>,
}

// Expose tools catalog for agent configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SimpleToolInfo { 
    pub name: String, 
    pub title: Option<String>, 
    pub category: Option<String>, 
    pub description: Option<String>,
    pub available: bool,
    pub source: Option<String>,
    pub group: Option<String>,
}

#[tauri::command]
pub async fn list_unified_tools(
    tool_system: State<'_, Arc<crate::tools::ToolSystem>>,
) -> Result<Vec<SimpleToolInfo>, String> {
    let tools = tool_system.list_tools().await;
    let list = tools
        .into_iter()
        .map(|t| SimpleToolInfo {
            name: t.name,
            title: None, // ToolMetadata æ²¡æœ‰é€šç”¨ title å­—æ®µï¼Œè¿™é‡Œä¸ºç©º
            category: Some(t.category.to_string()),
            description: if t.description.is_empty() { None } else { Some(t.description) },
            available: t.available,
            source: {
                // ä¼˜å…ˆç”¨metadata.tagsåˆ¤æ–­mcpï¼Œå¦åˆ™fallback
                let tag_has_mcp = t.metadata.tags.iter().any(|x| x == "mcp");
                Some(if tag_has_mcp { "mcp".to_string() } else { "builtin".to_string() })
            },
            group: t.metadata.tags.iter()
                .find_map(|tag| tag.strip_prefix("connection:").map(|s| s.to_string())),
        })
        .collect();
    Ok(list)
}

// åˆ†ç»„è¿”å›ï¼šå†…ç½®å·¥å…· + MCPæŒ‰è¿æ¥åˆ†ç»„
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct McpToolGroup { pub connection: String, pub tools: Vec<SimpleToolInfo> }

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GroupedToolsResponse { pub builtin: Vec<SimpleToolInfo>, pub mcp: Vec<McpToolGroup> }

#[tauri::command]
pub async fn list_unified_tools_grouped(
    tool_system: State<'_, Arc<crate::tools::ToolSystem>>,
) -> Result<GroupedToolsResponse, String> {
    let tools = tool_system.list_tools().await;
    let mut builtin: Vec<SimpleToolInfo> = Vec::new();
    let mut groups: std::collections::HashMap<String, Vec<SimpleToolInfo>> = std::collections::HashMap::new();

    for t in tools.into_iter() {
        // è·³è¿‡æ’ä»¶å·¥å…·ï¼ˆåç§°ä»¥ plugin:: å¼€å¤´æˆ–åŒ…å« plugin æ ‡ç­¾ï¼‰
        // æ’ä»¶å·¥å…·åº”è¯¥é€šè¿‡ list_plugins æ¥å£å•ç‹¬ç®¡ç†
        let is_plugin = t.name.starts_with("plugin::") || t.metadata.tags.iter().any(|x| x == "plugin");
        if is_plugin {
            continue;
        }
        
        let is_mcp = t.metadata.tags.iter().any(|x| x == "mcp");
        let group = t.metadata.tags.iter()
            .find_map(|tag| tag.strip_prefix("connection:").map(|s| s.to_string()));
        let item = SimpleToolInfo {
            name: t.name,
            title: None,
            category: Some(t.category.to_string()),
            description: if t.description.is_empty() { None } else { Some(t.description) },
            available: t.available,
            source: Some(if is_mcp { "mcp".to_string() } else { "builtin".to_string() }),
            group: group.clone(),
        };

        if is_mcp {
            let key = group.unwrap_or_else(|| "unknown".to_string());
            groups.entry(key).or_default().push(item);
        } else {
            builtin.push(item);
        }
    }

    let mut mcp: Vec<McpToolGroup> = groups.into_iter()
        .map(|(k, v)| McpToolGroup { connection: k, tools: v })
        .collect();
    // ç¨³å®šæ’åºè¿æ¥å
    mcp.sort_by(|a, b| a.connection.cmp(&b.connection));

    Ok(GroupedToolsResponse { builtin, mcp })
}

#[tauri::command]
pub async fn list_scenario_agents(
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<Vec<ScenarioAgentProfile>, String> {
    db_service
        .list_scenario_agents()
        .await
        .map_err(|e| format!("Failed to load scenario agents: {}", e))
}

#[tauri::command]
pub async fn save_scenario_agent(
    profile: ScenarioAgentProfile,
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<(), String> {
    db_service
        .upsert_scenario_agent(&profile)
        .await
        .map_err(|e| format!("Failed to save scenario agent: {}", e))
}

#[tauri::command]
pub async fn delete_scenario_agent(
    id: String,
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<(), String> {
    db_service
        .delete_scenario_agent(&id)
        .await
        .map_err(|e| format!("Failed to delete scenario agent: {}", e))
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ScenarioTaskDispatchRequest {
    pub agent_id: String,
    pub query: String,
    pub options: Option<HashMap<String, serde_json::Value>>,
    pub conversation_id: Option<String>,
    pub message_id: Option<String>,
}

#[tauri::command]
pub async fn dispatch_scenario_task(
    request: ScenarioTaskDispatchRequest,
    db_service: State<'_, Arc<DatabaseService>>,
    ai_service_manager: State<'_, Arc<AiServiceManager>>,
    execution_manager: State<'_, Arc<crate::managers::ExecutionManager>>,
    app_handle: AppHandle,
) -> Result<DispatchResult, String> {
    // è¯»å– Agent Profile
    let agents = list_scenario_agents(db_service.clone()).await?;
    let Some(profile) = agents.into_iter().find(|p| p.id == request.agent_id && p.enabled) else {
        return Err(format!("Scenario agent not found or disabled: {}", request.agent_id));
    };

    // é€‰æ¶æ„
    let architecture = match profile.engine {
        AgentEngine::PlanExecute => "plan-execute",
        AgentEngine::React => "react",
        AgentEngine::Rewoo => "rewoo",
        AgentEngine::LlmCompiler => "llm-compiler",
        AgentEngine::Auto => "auto",
    }.to_string();

    let mut options = request.options.unwrap_or_default();
    options.insert("agent_id".to_string(), serde_json::Value::String(request.agent_id.clone()));
    
    // ä» options ä¸­æå– conversation_id å’Œ message_idï¼ˆå‘åå…¼å®¹å‰ç«¯æŠŠå®ƒä»¬æ”¾åœ¨ options é‡Œçš„æƒ…å†µï¼‰
    let conversation_id = request.conversation_id.clone()
        .or_else(|| options.get("conversation_id").and_then(|v| v.as_str()).map(|s| s.to_string()));
    let message_id = request.message_id.clone()
        .or_else(|| options.get("message_id").and_then(|v| v.as_str()).map(|s| s.to_string()));
    
    // è·å–å½“å‰è§’è‰²æç¤ºè¯å¹¶æ·»åŠ åˆ°optionsä¸­
    if let Ok(Some(current_role)) = db_service.get_current_ai_role().await {
        if !current_role.prompt.trim().is_empty() {
            options.insert("role_prompt".to_string(), serde_json::Value::String(current_role.prompt));
            tracing::info!("Added role prompt from: {}", current_role.title);
        }
    }
    
    // é€ä¼ å·²ç»‘å®šçš„æç¤ºè¯æ¨¡æ¿IDï¼Œä¾›å¼•æ“æˆ–æ‰§è¡Œå±‚ä½¿ç”¨
    if let Some(pids) = &profile.prompt_ids {
        options.insert("prompt_ids".to_string(), serde_json::json!({
            "system": pids.system,
            "planner": pids.planner,
            "executor": pids.executor,
            "replanner": pids.replanner,
            "evaluator": pids.evaluator,
        }));
    }
    // é€ä¼ ç»Ÿä¸€æç¤ºè¯ç³»ç»Ÿç­–ç•¥ã€åˆ†ç»„ã€æ–‡æœ¬è¦†ç›–åŠç‰ˆæœ¬å›ºå®š
    if let Some(strategy) = &profile.prompt_strategy {
        options.insert("prompt_strategy".to_string(), serde_json::Value::String(strategy.clone()));
    }
    if let Some(gid) = profile.group_id {
        options.insert("group_id".to_string(), serde_json::json!(gid));
    }
    if let Some(prompts) = &profile.prompts {
        options.insert("prompts".to_string(), serde_json::json!({
            "system": prompts.system,
            "planner": prompts.planner,
            "executor": prompts.executor,
            "replanner": prompts.replanner,
            "evaluator": prompts.evaluator,
        }));
    }
    if let Some(pinned) = &profile.pinned_versions {
        options.insert("pinned_versions".to_string(), serde_json::to_value(pinned).unwrap_or_else(|_| serde_json::json!({})));
    }

    // å·¥å…·ç™½åå•/é»‘åå•ç­–ç•¥ï¼ˆç”¨äºæ‰§è¡ŒæœŸè¿‡æ»¤ï¼‰
    // è¦æ±‚ï¼šSystem prompt ä¸­çš„å·¥å…·æ¸…å•åº”ä¸¥æ ¼ä¾æ® AgentManager.vue ä¸­â€œå¯ç”¨+å·²é€‰â€çš„é›†åˆã€‚
    // è¯­ä¹‰ï¼š
    // - è‹¥å‰ç«¯é…ç½®å­˜åœ¨ï¼ˆprofile.tools æœ‰å€¼ï¼‰ï¼šæŒ‰ allow/deny é€ä¼ ï¼›
    // - è‹¥å‰ç«¯æœªé…ç½®ï¼ˆprofile.tools ä¸º Noneï¼‰ï¼šä¹Ÿè¦æ˜¾å¼ä¼ å…¥ç©ºç™½åå•ï¼Œè¡¨ç¤ºâ€œæœªé€‰æ‹©ä»»ä½•å·¥å…· â‡’ ç¦ç”¨æ‰€æœ‰å·¥å…·â€ã€‚
    //   è¿™æ · ReAct/Planner åœ¨æ„å»ºå·¥å…·æ¸…å•æ—¶ä¸ä¼šé€€å›åˆ°â€œå…è®¸æ‰€æœ‰â€ã€‚
    if let Some(tool_policy) = &profile.tools {
        log::info!("Agent tools policy - allow: {:?}, deny: {:?}", tool_policy.allow, tool_policy.deny);
        // å…è®¸åˆ—è¡¨ï¼ˆå¯èƒ½ä¸ºç©ºï¼Œä½†é”®ä¸€å®šå­˜åœ¨ï¼‰
        options.insert(
            "tools_allow".to_string(),
            serde_json::json!(tool_policy.allow.clone())
        );
        // ç¦æ­¢åˆ—è¡¨ï¼ˆå¯ç©ºï¼‰
        if let Some(deny) = &tool_policy.deny {
            options.insert("tools_deny".to_string(), serde_json::json!(deny.clone()));
        }
    } else {
        // æ˜¾å¼è®¾ç½®ç©ºç™½åå•ï¼šä¸å‰ç«¯â€œæœªé€‰æ‹©ä»»ä½•å·¥å…·â€ä¸€è‡´ï¼Œé˜²æ­¢å¼•æ“å›é€€åˆ°â€œå…¨é‡å¯ç”¨â€ã€‚
        log::warn!("Agent has no tools policy configured! Falling back to strict: tools_allow = []");
        options.insert("tools_allow".to_string(), serde_json::json!([] as [String; 0]));
    }

    // æ‰§è¡Œç­–ç•¥ï¼ˆè¶…æ—¶/é‡è¯•/ä¸¥æ ¼æ¨¡å¼/å¹¶å‘ï¼‰
    if let Some(exec) = &profile.execution {
        if let Some(timeout) = exec.timeout_sec {
            options.insert("execution_timeout_sec".to_string(), serde_json::json!(timeout));
        }
        if let Some(retry) = &exec.retry {
            options.insert("execution_retry_max".to_string(), serde_json::json!(retry.max_retries));
            options.insert("execution_retry_backoff".to_string(), serde_json::json!(retry.backoff.clone()));
            if let Some(iv) = retry.interval_ms { options.insert("execution_retry_interval_ms".to_string(), serde_json::json!(iv)); }
        }
        if let Some(conc) = exec.concurrency { options.insert("execution_concurrency".to_string(), serde_json::json!(conc)); }
        if let Some(strict) = exec.strict_mode { options.insert("execution_strict_mode".to_string(), serde_json::json!(strict)); }
    }

    // LLMé…ç½®ï¼ˆç”¨äºè¦†ç›–é˜¶æ®µé»˜è®¤æ¨¡å‹ï¼‰
    // ç›´æ¥ä¼ é€’å®Œæ•´ç»“æ„ï¼Œä¾¿äºåç»­è§£æ
    options.insert(
        "llm".to_string(),
        serde_json::json!({
            "default": {
                "provider": profile.llm.default.provider,
                "model": profile.llm.default.model,
                "temperature": profile.llm.default.temperature,
                "max_tokens": profile.llm.default.max_tokens,
            }
        })
    );

    // ä»¥ä¸‹æ˜¯åŸ dispatch_intelligent_query çš„é€»è¾‘
    // æå–ä»»åŠ¡æ¨¡å¼æ ‡è¯†å’Œç›¸å…³ä¿¡æ¯
    let is_task_mode = options.get("task_mode")
        .and_then(|v| v.as_bool())
        .unwrap_or(false);
    
    // conversation_id å’Œ message_id å·²ç»åœ¨ä¸Šé¢ä» request æˆ– options ä¸­æå–
    // è¿™é‡Œä¸éœ€è¦å†æ¬¡æå–ï¼Œç›´æ¥ä½¿ç”¨ä¹‹å‰çš„å˜é‡
    
    let execution_id = options.get("execution_id")
        .and_then(|v| v.as_str())
        .map(|s| s.to_string())
        .unwrap_or_else(|| uuid::Uuid::new_v4().to_string());
    
    // åˆ›å»ºagent_sessionè®°å½•ç”¨äºç»Ÿä¸€çš„å·¥ä½œæµç›‘æ§
    if let Err(e) = create_ai_assistant_session(
        &db_service,
        &execution_id,
        &profile.name,
        &request.query,
    ).await {
        log::warn!("Failed to create AI assistant session: {}", e);
    }
    
    // æå–ä¼šè¯IDï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
    if let Some(ref conv_id) = conversation_id {
        if !conv_id.is_empty() {
            info!("Processing request for conversation: {}", conv_id);
        }
    }
    
    // å¦‚æœæ˜¯ä»»åŠ¡æ¨¡å¼ä¸”æ¶æ„ä¸º"auto"ï¼Œè¿›è¡Œæ™ºèƒ½é€‰æ‹©
    let selected_architecture = if is_task_mode && architecture == "auto" {
        let auto_selected = select_best_architecture(&request.query).await
            .map_err(|e| format!("Failed to select architecture: {}", e))?;
        
        info!("Auto-selected architecture: {} for query: {}", auto_selected, request.query);
        
        auto_selected
    } else {
        architecture.clone()
    };
    
    // åˆ›å»º DispatchQueryRequest
    let dispatch_req = DispatchQueryRequest {
        query: request.query,
        architecture: selected_architecture.clone(),
        agent_id: Some(profile.id),
        options: Some(options),
        conversation_id: conversation_id.clone(),
        message_id: message_id.clone(),
    };
    
    let app_clone = app_handle.clone();
    // æ ¹æ®é€‰æ‹©çš„æ¶æ„åˆ›å»ºè°ƒåº¦å™¨
    let result = match selected_architecture.as_str() {
        "plan-execute" => {
            dispatch_with_plan_execute(
                execution_id.clone(),
                dispatch_req,
                (*ai_service_manager).clone(),
                (*db_service).clone(),
                (*execution_manager).clone(),
                app_handle.clone(),
            ).await
        },
        "react" => {
            dispatch_with_react(
                execution_id.clone(),
                dispatch_req,
                (*ai_service_manager).clone(),
                (*db_service).clone(),
                (*execution_manager).clone(),
                app_clone.clone(),
            ).await
        },
        "rewoo" => {
            dispatch_with_rewoo(
                execution_id.clone(),
                dispatch_req,
                (*ai_service_manager).clone(),
                (*db_service).clone(),
                (*execution_manager).clone(),
                app_clone.clone(),
            ).await
        },
        "llm-compiler" => {
            dispatch_with_llm_compiler(
                execution_id.clone(),
                dispatch_req,
                (*ai_service_manager).clone(),
                (*db_service).clone(),
                (*execution_manager).clone(),
                app_clone.clone(),
            ).await
        },
        "auto" => {
            dispatch_with_auto(
                execution_id.clone(),
                dispatch_req,
                (*ai_service_manager).clone(),
                (*db_service).clone(),
                (*execution_manager).clone(),
                app_clone.clone(),
            ).await
        }
        _ => {
            Err(format!("Unsupported architecture: {}", selected_architecture))
        }
    };
    
    // å¦‚æœè°ƒåº¦æˆåŠŸï¼ŒæŒ‰æ¶æ„å†³å®šæ˜¯å¦éœ€è¦å¼‚æ­¥å¼€å§‹â€œçœŸå®æ‰§è¡Œâ€
    if let Ok(ref dispatch_result) = result {
        // ä»…å¯¹éœ€è¦ register_execution çš„æ¶æ„è§¦å‘åç»­æ‰§è¡Œï¼ˆå¦‚ plan-execute / llm-compilerï¼‰
        let arch_for_exec = selected_architecture.clone();
        if matches!(arch_for_exec.as_str(), "plan-execute" | "llm-compiler" | "auto") {
            let execution_id_clone = dispatch_result.execution_id.clone();
            let app_clone = app_handle.clone();
            
            // å¼‚æ­¥å¼€å§‹æ‰§è¡Œï¼Œä¸é˜»å¡è°ƒåº¦å“åº”
            tokio::spawn(async move {
                info!("Starting real engine execution: {}", execution_id_clone);
                
                // ä»åº”ç”¨çŠ¶æ€è·å–æ‰§è¡Œç®¡ç†å™¨
                let execution_manager = app_clone.state::<Arc<crate::managers::ExecutionManager>>();
                let execution_manager_clone = execution_manager.inner().clone();
                let app_inner = app_clone.clone();
                let execution_id_inner = execution_id_clone.clone();
                let db_service_clone = app_clone.state::<Arc<DatabaseService>>().inner().clone();
                
                tokio::spawn(async move {
                    // è·å–æ‰§è¡Œä¸Šä¸‹æ–‡
                    let context = match execution_manager_clone.get_execution_context(&execution_id_inner).await {
                        Some(ctx) => ctx,
                        None => {
                            // å¯¹äºä¸è¯¥è§¦å‘çš„æƒ…å†µå·²åœ¨å¤–å±‚è¿‡æ»¤ï¼Œè¿™é‡Œè‹¥ä»ç„¶ç¼ºå¤±ï¼Œå¯èƒ½æ˜¯è¢«å¤–éƒ¨å–æ¶ˆæˆ–è¿‡æœŸæ¸…ç†
                            log::error!("Execution context not found: {}", execution_id_inner);
                            return;
                        }
                    };

                log::info!("Starting real execution for: {} with engine: {:?}", execution_id_inner, context.engine_type);

                // ä»ä»»åŠ¡å‚æ•°ä¸­æå–æ¶ˆæ¯IDå’Œä¼šè¯ID
                let message_id = context.task.parameters.get("message_id").and_then(|v| v.as_str()).map(|s| s.to_string());
                let conversation_id = context.task.parameters.get("conversation_id").and_then(|v| v.as_str()).map(|s| s.to_string());
                
                // å‘é€ PlanUpdate äº‹ä»¶ç»™å‰ç«¯å±•ç¤ºæ‰§è¡Œè®¡åˆ’ï¼ˆé¢„ç•™ï¼‰
                let _plan_json = serde_json::json!({
                    "id": context.plan.id,
                    "name": context.plan.name,
                    "estimated_duration": context.plan.estimated_duration,
                    "resource_requirements": context.plan.resource_requirements,
                    "steps": context
                        .plan
                        .steps
                        .iter()
                        .enumerate()
                        .map(|(i, s)| serde_json::json!({
                            "index": i + 1,
                            "id": s.id,
                            "name": s.name,
                            "description": s.description,
                            "type": format!("{:?}", s.step_type),
                            "dependencies": s.dependencies,
                            "parameters": s.parameters
                        }))
                        .collect::<Vec<_>>()
                });

                // Emit plan as a PlanInfo message chunk to frontend
                if let Ok(plan_str) = serde_json::to_string(&_plan_json) {
                    crate::utils::ordered_message::emit_message_chunk_arc(
                        &Arc::new(app_inner.clone()),
                        &execution_id_inner,
                        message_id.as_deref().unwrap_or(&execution_id_inner),
                        conversation_id.as_deref(),
                        crate::utils::ordered_message::ChunkType::PlanInfo,
                        &plan_str,
                        false,
                        Some("planner"),
                        None,
                    );
                }

                // Emit a one-shot Meta message with execution configuration
                let _meta_json = {
                    let params = &context.task.parameters;
                    serde_json::json!({
                        "engine": format!("{:?}", context.engine_type),
                        "agent_id": params.get("agent_id").and_then(|v| v.as_str()),
                        "prompt_ids": params.get("prompt_ids"),
                        "prompt_strategy": params.get("prompt_strategy").and_then(|v| v.as_str()),
                        "group_id": params.get("group_id"),
                        "pinned_versions": params.get("pinned_versions"),
                    })
                };

                // è®°å½•æ‰§è¡Œå¼€å§‹æ—¶é—´
                let execution_start_time = std::time::SystemTime::now();
                
                // æ‰§è¡ŒçœŸå®çš„å¼•æ“è®¡åˆ’
                let exec_result = execution_manager_clone.execute_plan(&execution_id_inner).await;
                
                // è®°å½•æ‰§è¡Œå®Œæˆæ—¶é—´
                let execution_end_time = std::time::SystemTime::now();
                
                // ä¿å­˜æ‰§è¡Œç»“æœåˆ°æ•°æ®åº“
                let task_name = context.task.description.clone();
                let architecture = format!("{:?}", context.engine_type);
                let started_at = execution_start_time.duration_since(std::time::UNIX_EPOCH).unwrap_or_default().as_secs();
                let completed_at = execution_end_time.duration_since(std::time::UNIX_EPOCH).unwrap_or_default().as_secs();
                let duration_ms = execution_end_time.duration_since(execution_start_time).unwrap_or_default().as_millis() as u64;
                
                let success = exec_result.is_ok();
                let error = if let Err(ref e) = exec_result { Some(e.to_string()) } else { None };
                let result = if success { Some("Task completed successfully".to_string()) } else { None };
                
                // åªæœ‰éPlan-and-Executeæ¶æ„æ‰ä¿å­˜é€šç”¨çš„AIåŠ©æ‰‹æ‰§è¡Œæ­¥éª¤
                // Plan-and-Executeå¼•æ“ä¼šè‡ªå·±ä¿å­˜è¯¦ç»†çš„æ­¥éª¤ä¿¡æ¯
                if !architecture.contains("PlanExecute") {
                    if let Err(e) = save_ai_assistant_execution(
                        &db_service_clone,
                        &execution_id_inner,
                        &task_name,
                        &architecture,
                        success,
                        error.as_deref(),
                        result.as_deref(),
                        started_at,
                        completed_at,
                        duration_ms,
                    ).await {
                        log::warn!("Failed to save AI assistant execution: {}", e);
                    }
                } else {
                    // å¯¹äºPlan-and-Executeæ¶æ„ï¼Œåªæ›´æ–°sessionçŠ¶æ€
                    use crate::services::database::Database;
                    let status_str = if success { "Completed" } else { "Failed" };
                    if let Err(e) = db_service_clone.update_agent_session_status(&execution_id_inner, status_str).await {
                        log::warn!("Failed to update agent session status: {}", e);
                    }
                }
                
                match exec_result {
                    Ok(_result) => {
                        log::info!("Execution completed successfully: {}", execution_id_inner);
                        // ç§»é™¤åŸå§‹äº‹ä»¶ï¼Œåªä½¿ç”¨ai_stream_message
                    }
                    Err(e) => {
                        log::error!("Execution failed: {}: {}", execution_id_inner, e);
                        
                        // ä½¿ç”¨æ›´å‹å¥½çš„é”™è¯¯æ¶ˆæ¯æ ¼å¼
                        let error_message = format!(
                            "ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {}\n\nå¦‚éœ€å¸®åŠ©ï¼Œè¯·æ£€æŸ¥æ‰§è¡Œé…ç½®æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚",
                            e.to_string()
                        );
                        
                        // ä½¿ç”¨æœ‰åºæ¶ˆæ¯å—å‘é€é”™è¯¯
                        crate::utils::ordered_message::emit_message_chunk_arc(
                            &Arc::new(app_inner.clone()),
                            &execution_id_inner,
                            message_id.as_deref().unwrap_or(&execution_id_inner),
                            conversation_id.as_deref(),
                            crate::utils::ordered_message::ChunkType::Error,
                            &error_message,
                            true, // ç¡®ä¿æ ‡è®°ä¸ºæœ€ç»ˆæ¶ˆæ¯
                            None,
                            None,
                        );
                        
                        // ç¡®ä¿å‘é€ä¸€ä¸ªå†…å®¹å—æ¥æ­£å¼ç»“æŸä¼šè¯
                        crate::utils::ordered_message::emit_message_chunk_arc(
                            &Arc::new(app_inner.clone()),
                            &execution_id_inner,
                            message_id.as_deref().unwrap_or(&execution_id_inner),
                            conversation_id.as_deref(),
                            crate::utils::ordered_message::ChunkType::Content,
                            "", // ç©ºå†…å®¹ï¼Œä»…ç”¨äºç»“æŸæµ
                            true, // æœ€ç»ˆæ¶ˆæ¯
                            Some("error_termination"),
                            None,
                        );
                    }
                }

                    // æ¸…ç†æ‰§è¡Œä¸Šä¸‹æ–‡
                    execution_manager_clone.cleanup_execution(&execution_id_inner).await;
                });
            });
        } else {
            // ReAct ç­‰æ¶æ„å·²åœ¨è°ƒåº¦é˜¶æ®µå®Œæˆæ‰§è¡Œï¼Œè¿™é‡Œä¸å†é‡å¤è§¦å‘
            info!("Architecture '{}' completes within dispatch; skipping real engine execution.", arch_for_exec);
        }
    }
    
    // æ›´æ–°è¿”å›ç»“æœä¸­çš„æ¶æ„ä¿¡æ¯
    result.map(|mut dispatch_result| {
        // å½“å¤–å±‚é€‰æ‹©ä¸º "auto" æ—¶ï¼Œä¸è¦†ç›–å…·ä½“è°ƒåº¦å™¨è¿”å›çš„æ¶æ„ä¿¡æ¯
        if selected_architecture != "auto" {
            dispatch_result.selected_architecture = selected_architecture.clone();
        }
        dispatch_result
    })
}

#[derive(Debug, Serialize, Deserialize)]
pub struct AgentStatistics {
    pub active_count: u32,
    pub total_tasks: u32,
    pub successful_tasks: u32,
    pub failed_tasks: u32,
    pub average_execution_time: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CustomAgent {
    pub id: String,
    pub name: String,
    pub description: String,
    #[serde(rename = "type")]
    pub r#type: String,
    pub status: String,
    pub tasks_completed: u32,
}



/// åœæ­¢æ‰§è¡Œ
#[tauri::command]
pub async fn stop_execution(
    execution_id: String,
    app: AppHandle,
) -> Result<(), String> {
    info!("ğŸ›‘ Stopping execution: {}", execution_id);

    // 1. âœ… å–æ¶ˆCancellationTokenï¼ˆå¯¹ReActæ¶æ„æœ‰æ•ˆï¼‰
    use crate::managers::cancellation_manager;
    let cancelled_by_token = cancellation_manager::cancel_execution(&execution_id).await;
    if cancelled_by_token {
        log::info!("âœ… Cancelled execution via CancellationToken: {}", execution_id);
    }

    // 2. å°è¯•åœæ­¢æ‰§è¡Œç®¡ç†å™¨ä¸­çš„ä»»åŠ¡ï¼ˆå¯¹Plan-Execute/LLMCompileræœ‰æ•ˆï¼‰
    let execution_manager = app.state::<Arc<crate::managers::ExecutionManager>>();
    let manager = execution_manager.inner().clone();
    if let Err(e) = manager.stop_execution(&execution_id).await {
        log::warn!("Failed to stop execution via ExecutionManager {}: {}", execution_id, e);
    } else {
        log::info!("âœ… Stopped execution via ExecutionManager: {}", execution_id);
    }

    // 3. å¦‚æœexecution_idçœ‹èµ·æ¥åƒä¼šè¯IDï¼Œä¹Ÿå°è¯•å–æ¶ˆå¯¹åº”çš„æµ
    // è¿™æ ·å¯ä»¥å¤„ç†ç”¨ä¼šè¯IDè°ƒç”¨stopçš„æƒ…å†µ
    if execution_id.starts_with("conv_") || execution_id.len() == 36 {
        // å¯èƒ½æ˜¯ä¼šè¯IDæˆ–UUIDæ ¼å¼
        use crate::commands::ai::cancel_conversation_stream;
        cancel_conversation_stream(&execution_id);
        log::info!("âœ… Cancelled stream for conversation: {}", execution_id);
    }

    // 4. å‘é€åœæ­¢äº‹ä»¶ï¼ˆç»Ÿä¸€äº‹ä»¶åç§°ï¼‰
    if let Err(e) = app.emit("execution_stopped", serde_json::json!({
        "execution_id": execution_id,
        "message": "Execution stopped by user"
    })) {
        log::warn!("Failed to emit execution_stopped event: {}", e);
    }
    
    log::info!("âœ… Stop execution completed: {}", execution_id);

    info!("Execution stop completed: {}", execution_id);
    Ok(())
}

/// è·å–AIåŠ©æ‰‹è®¾ç½®
#[tauri::command]
pub async fn get_ai_assistant_settings(
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<AIAssistantSettings, String> {
    // ä»æ•°æ®åº“åŠ è½½è®¾ç½®ï¼Œä½¿ç”¨ä¸“é—¨çš„keyå­˜å‚¨AIAssistantSettings
    match db_service.get_config("ai_assistant", "assistant_settings").await {
        Ok(Some(json_str)) => {
            serde_json::from_str::<AIAssistantSettings>(&json_str)
                .map_err(|e| format!("Failed to parse AI assistant settings: {}", e))
        }
        Ok(None) => {
            // è¿”å›é»˜è®¤è®¾ç½®
            let default_settings = AIAssistantSettings {
                auto_execute: false,
                notification_enabled: true,
            };
            info!("Using default AI assistant settings");
            Ok(default_settings)
        }
        Err(e) => Err(format!("Failed to load AI assistant settings: {}", e)),
    }
}

/// ä¿å­˜AIåŠ©æ‰‹è®¾ç½®
#[tauri::command]
pub async fn save_ai_assistant_settings(
    settings: AIAssistantSettings,
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<(), String> {
    info!("Saving AI assistant settings: {:?}", settings);
    let json = serde_json::to_string(&settings)
        .map_err(|e| format!("Failed to serialize settings: {}", e))?;
    db_service
        .set_config(
            "ai_assistant",
            "assistant_settings",
            &json,
            None,
        )
        .await
        .map_err(|e| format!("Failed to save AI assistant settings: {}", e))
}

/// è·å–Agentç»Ÿè®¡ä¿¡æ¯
#[tauri::command]
pub async fn get_agent_statistics() -> Result<AgentStatistics, String> {
    // ä»æ•°æ®åº“æˆ–ç›‘æ§ç³»ç»Ÿè·å–ç»Ÿè®¡ä¿¡æ¯
    Ok(AgentStatistics {
        active_count: 2,
        total_tasks: 156,
        successful_tasks: 142,
        failed_tasks: 14,
        average_execution_time: 180.5,
    })
}

/// è·å–å¯ç”¨æ¶æ„åˆ—è¡¨
#[tauri::command]
pub async fn get_available_architectures() -> Result<Vec<serde_json::Value>, String> {
    Ok(vec![
        serde_json::json!({
            "id": "auto",
            "name": "Auto",
            "description": "è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¶æ„",
            "suitable_for": ["æ‰€æœ‰ä»»åŠ¡"],
            "performance": "è‡ªåŠ¨",
            "status": "stable"
        }),
        serde_json::json!({
            "id": "plan-execute",
            "name": "Plan-and-Execute",
            "description": "åŸºäºè§„åˆ’å’Œæ‰§è¡Œçš„æ™ºèƒ½Agentæ¶æ„",
            "suitable_for": ["å¤æ‚ä»»åŠ¡", "å¤šæ­¥éª¤æµç¨‹", "éœ€è¦é‡è§„åˆ’çš„ä»»åŠ¡"],
            "performance": "ç¨³å®š",
            "status": "stable"
        }),
        serde_json::json!({
            "id": "rewoo",
            "name": "ReWOO",
            "description": "æ¨ç†è€Œéè§‚å¯Ÿçš„å·¥ä½œæµæ¶æ„",
            "suitable_for": ["æ¨ç†å¯†é›†å‹ä»»åŠ¡", "åˆ†æç±»ä»»åŠ¡"],
            "performance": "é«˜æ•ˆ",
            "status": "beta"
        }),
        serde_json::json!({
            "id": "llm-compiler",
            "name": "LLMCompiler",
            "description": "å¹¶è¡Œæ‰§è¡Œå¼•æ“",
            "suitable_for": ["å¹¶è¡Œä»»åŠ¡", "ç‹¬ç«‹çš„å¤šä¸ªå­ä»»åŠ¡"],
            "performance": "å¿«é€Ÿ",
            "status": "experimental"
        }),

    ])
}

/// è·å–è‡ªå®šä¹‰Agentåˆ—è¡¨
#[tauri::command]
pub async fn get_ai_assistant_agents(
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<Vec<CustomAgent>, String> {
    match db_service.get_config("ai_assistant", "custom_agents").await {
        Ok(Some(json_str)) => serde_json::from_str::<Vec<CustomAgent>>(&json_str)
            .map_err(|e| format!("Failed to parse custom agents: {}", e)),
        Ok(None) => Ok(vec![]),
        Err(e) => Err(format!("Failed to load custom agents: {}", e)),
    }
}

/// ä¿å­˜è‡ªå®šä¹‰Agentåˆ—è¡¨
#[tauri::command]
pub async fn save_ai_assistant_agents(
    agents: Vec<CustomAgent>,
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<(), String> {
    let json = serde_json::to_string(&agents)
        .map_err(|e| format!("Failed to serialize custom agents: {}", e))?;
    db_service
        .set_config(
            "ai_assistant",
            "custom_agents",
            &json,
            None,
        )
        .await
        .map_err(|e| format!("Failed to save custom agents: {}", e))
}

/// è·å–æ¶æ„å¯ç”¨åå¥½ï¼ˆè¿”å›å¯ç”¨çš„æ¶æ„IDåˆ—è¡¨ï¼‰
#[tauri::command]
pub async fn get_ai_architecture_prefs(
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<Vec<String>, String> {
    match db_service.get_config("ai_assistant", "enabled_architectures").await {
        Ok(Some(json_str)) => serde_json::from_str::<Vec<String>>(&json_str)
            .map_err(|e| format!("Failed to parse architecture prefs: {}", e)),
        Ok(None) => Ok(vec![
            "plan-execute".to_string(),
            "rewoo".to_string(),
            "llm-compiler".to_string(),
        ]),
        Err(e) => Err(format!("Failed to load architecture prefs: {}", e)),
    }
}

/// ä¿å­˜æ¶æ„å¯ç”¨åå¥½
#[tauri::command]
pub async fn save_ai_architecture_prefs(
    enabled_architectures: Vec<String>,
    db_service: State<'_, Arc<DatabaseService>>,
) -> Result<(), String> {
    let json = serde_json::to_string(&enabled_architectures)
        .map_err(|e| format!("Failed to serialize architecture prefs: {}", e))?;
    db_service
        .set_config(
            "ai_assistant",
            "enabled_architectures",
            &json,
            None,
        )
        .await
        .map_err(|e| format!("Failed to save architecture prefs: {}", e))
}

// ===== è¾…åŠ©å‡½æ•°å’Œç»“æ„ä½“ =====

#[derive(Debug, Deserialize)]
pub struct TaskSubmissionRequest {
    pub user_input: String,
    pub user_id: String,
    pub priority: Option<String>,
    pub estimated_duration: Option<f64>,
    pub metadata: Option<HashMap<String, serde_json::Value>>,
}

#[derive(Debug, Deserialize)]
pub struct NodeRegistrationRequest {
    pub name: String,
    pub capacity: NodeCapacityRequest,
}

#[derive(Debug, Deserialize)]
pub struct NodeCapacityRequest {
    pub cpu_cores: u32,
    pub memory_gb: u32,
    pub network_mbps: f32,
    pub storage_gb: u32,
    pub max_concurrent_tasks: u32,
}



/// æ™ºèƒ½é€‰æ‹©æœ€ä½³æ¶æ„
async fn select_best_architecture(user_input: &str) -> Result<String, String> {
    // ç®€å•çš„è§„åˆ™åŸºç¡€æ¶æ„é€‰æ‹©
    let input_lower = user_input.to_lowercase();
    
    // åˆ†æä»»åŠ¡ç‰¹å¾
    let has_complex_analysis = input_lower.contains("åˆ†æ") || input_lower.contains("analysis");
    let has_scanning = input_lower.contains("æ‰«æ") || input_lower.contains("scan");
    let has_monitoring = input_lower.contains("ç›‘æ§") || input_lower.contains("monitor");
    let has_multiple_steps = input_lower.contains("æ­¥éª¤") || input_lower.contains("å¤šä¸ª") || input_lower.contains("multiple");
    let has_parallel_tasks = input_lower.contains("åŒæ—¶") || input_lower.contains("å¹¶è¡Œ") || input_lower.contains("parallel");
    
    // æ¶æ„é€‰æ‹©é€»è¾‘
    if has_parallel_tasks || (has_scanning && has_multiple_steps) {
        Ok("llm-compiler".to_string())
    } else if has_complex_analysis {
        Ok("rewoo".to_string())
    } else if has_monitoring || input_lower.len() > 100 {
        Ok("plan-execute".to_string())
    } else {
        // å¯¹äºä¸€èˆ¬ä»»åŠ¡ï¼Œä½¿ç”¨plan-execute
        Ok("plan-execute".to_string())
    }
}



async fn dispatch_with_auto(
    execution_id: String,
    request: DispatchQueryRequest,
    ai_service_manager: Arc<AiServiceManager>,
    db_service: Arc<DatabaseService>,
    execution_manager: Arc<crate::managers::ExecutionManager>,
    app: AppHandle,
) -> Result<DispatchResult, String> {
    let architecture = select_best_architecture(&request.query).await?;
    match architecture.as_str() {
        "plan-execute" => dispatch_with_plan_execute(execution_id, request, ai_service_manager, db_service, execution_manager, app).await,
        "rewoo" => dispatch_with_rewoo(execution_id, request, ai_service_manager, db_service, execution_manager, app).await,
        "llm-compiler" => dispatch_with_llm_compiler(execution_id, request, ai_service_manager, db_service, execution_manager, app).await,
        _ => Err(format!("Unsupported architecture: {}", architecture)),
    }
}   

async fn dispatch_with_plan_execute(
    execution_id: String,
    request: DispatchQueryRequest,
    ai_service_manager: Arc<AiServiceManager>,
    db_service: Arc<DatabaseService>,
    execution_manager: Arc<crate::managers::ExecutionManager>,
    app: AppHandle,
) -> Result<DispatchResult, String> {
    
    // åˆ›å»ºPlan-and-Executeå¼•æ“é…ç½®
    let config = PlanAndExecuteConfig::default();
    
    // åˆ›å»ºPlan-and-Executeå¼•æ“
    let mut engine = PlanAndExecuteEngine::new_with_dependencies(
        ai_service_manager.clone(),
        config,
        db_service.clone(),
        Some(Arc::new(app.clone())),
    ).await.map_err(|e| format!("Failed to create Plan-and-Execute engine: {}", e))?;
    
    // åˆ›å»ºAgentä»»åŠ¡
    let mut parameters = request.options.unwrap_or_default();
    // ç»Ÿä¸€ä½¿ç”¨ snake_case keysï¼Œå…¼å®¹å¯èƒ½ä¼ å…¥çš„ camelCase
    if let Some(v) = parameters.remove("executionId") { parameters.insert("execution_id".to_string(), v); }
    if let Some(v) = parameters.remove("messageId") { parameters.insert("message_id".to_string(), v); }
    if let Some(v) = parameters.remove("conversationId") { parameters.insert("conversation_id".to_string(), v); }
    if let Some(v) = parameters.remove("taskMode") { parameters.insert("task_mode".to_string(), v); }
    // ç»Ÿä¸€æç¤ºè¯IDå­—æ®µï¼ˆå…¼å®¹ camelCase -> snake_caseï¼‰
    if let Some(v) = parameters.remove("promptIds") { parameters.insert("prompt_ids".to_string(), v); }
    parameters.insert("execution_id".to_string(), serde_json::Value::String(execution_id.clone()));

    let task = AgentTask {
        id: Uuid::new_v4().to_string(), // The internal task ID can be unique
        user_id: "system".to_string(),
        description: request.query.clone(),
        priority: TaskPriority::Normal,
        target: None,
        parameters,
        timeout: Some(600), // 10 minute timeout
    };
    
    // å°†å‚æ•°æ³¨å…¥å¼•æ“ï¼Œä¾¿äºæ‰§è¡Œé˜¶æ®µè®¿é—®ï¼ˆå¦‚ prompt_ids ï¼‰
    engine.set_runtime_params(task.parameters.clone());

    // Create execution plan
    let plan = engine.create_plan(&task).await
        .map_err(|e| format!("Failed to create execution plan: {}", e))?;

    // Register execution context and engine instance to execution manager
    let engine_instance = crate::managers::EngineInstance::PlanExecute(engine);
    execution_manager.register_execution(
        execution_id.clone(),
        crate::managers::EngineType::PlanExecute,
        plan.clone(),
        task,
        engine_instance,
    ).await.map_err(|e| format!("Failed to register execution: {}", e))?;
    
    let execution_plan = ExecutionPlanView {
        id: plan.id.clone(),
        name: plan.name.clone(),
        description: format!("Plan-and-Executeä»»åŠ¡: {}", request.query),
        steps: plan.steps.iter().map(|step| ExecutionStepView {
            id: step.id.clone(),
            name: step.name.clone(),
            description: step.description.clone(),
            status: "pending".to_string(),
            estimated_duration: 60,
        }).collect(),
        estimated_duration: plan.estimated_duration,
    };
    
    Ok(DispatchResult {
        execution_id,
        initial_response: "å·²åˆ›å»ºPlan-and-Executeæ‰§è¡Œè®¡åˆ’ï¼Œå¼•æ“å®ä¾‹å·²æ³¨å†Œï¼Œå‡†å¤‡çœŸå®æ‰§è¡Œ...".to_string(),
        execution_plan: Some(execution_plan),
        estimated_duration: plan.estimated_duration,
        selected_architecture: "Plan-and-Execute".to_string(),
    })
}

async fn dispatch_with_react(
    execution_id: String,
    request: DispatchQueryRequest,
    ai_service_manager: Arc<AiServiceManager>,
    db_service: Arc<DatabaseService>,
    _execution_manager: Arc<crate::managers::ExecutionManager>,
    app: AppHandle,
) -> Result<DispatchResult, String> {
    use crate::engines::react::{ReactEngine, ReactConfig};
    use std::collections::HashMap;
    use crate::agents::traits::{AgentTask, TaskPriority};
    use crate::managers::cancellation_manager;
    
    info!("Creating ReAct dispatch for: {}", request.query);
    
    // âœ… æ³¨å†Œå–æ¶ˆä»¤ç‰Œ
    let cancellation_token = cancellation_manager::register_cancellation_token(execution_id.clone()).await;
    
    // ä» options ä¸­æå–é…ç½®
    let options = request.options.unwrap_or_default();
    let mut config = ReactConfig::default();
    let max_iterations = config.max_iterations; // ä¿å­˜ç”¨äºè¶…æ—¶è®¡ç®—
    
    if let Some(max_iter) = options.get("max_iterations").and_then(|v| v.as_u64()) {
        config.max_iterations = max_iter as u32;
    }
    if let Some(temp) = options.get("temperature").and_then(|v| v.as_f64()) {
        config.temperature = Some(temp as f32);
    }
    if let Some(max_tok) = options.get("max_tokens").and_then(|v| v.as_u64()) {
        config.max_tokens = Some(max_tok as u32);
    }
    if let Some(rag) = options.get("enable_rag").and_then(|v| v.as_bool()) {
        config.enable_rag = rag;
    }
    if let Some(verbose) = options.get("verbose").and_then(|v| v.as_bool()) {
        config.verbose = verbose;
    }
    
    // **å…³é”®ä¿®å¤**: ä» options ä¸­è¯»å– tools_allow å¹¶è®¾ç½®åˆ° ReactConfig.allowed_tools
    // è¿™æ · ReAct executor çš„ build_tools_information æ‰èƒ½è¯»å–åˆ°æ­£ç¡®çš„å·¥å…·ç™½åå•
    if let Some(tools_allow) = options.get("tools_allow") {
        if let Some(arr) = tools_allow.as_array() {
            let tool_names: Vec<String> = arr.iter()
                .filter_map(|v| v.as_str().map(|s| s.to_string()))
                .collect();
            log::info!("ReAct dispatch: è®¾ç½® allowed_tools = {:?}", tool_names);
            config.allowed_tools = Some(tool_names);
        }
    }
    
    // è·å–é»˜è®¤ AI æœåŠ¡
    let ai_service = match ai_service_manager.get_default_chat_model().await {
        Ok(Some((provider, model))) => {
            match ai_service_manager.get_provider_config(&provider).await {
                Ok(Some(mut provider_config)) => {
                    provider_config.model = model;
                    let mcp_service = ai_service_manager.get_mcp_service();
                    let ai_svc = crate::services::ai::AiService::new(
                        provider_config,
                        db_service.clone(),
                        Some(app.clone()),
                        mcp_service.clone(),
                    );
                    Arc::new(ai_svc)
                }
                _ => {
                    return Err("Failed to get AI provider config".to_string());
                }
            }
        }
        _ => {
            return Err("No default AI model configured".to_string());
        }
    };
    
    // åºåˆ—åŒ– config
    let config_json = serde_json::to_value(&config).map_err(|e| e.to_string())?;
    
    // åˆ›å»º ReactEngine
    let engine = ReactEngine::new(config).with_services(
        ai_service,
        ai_service_manager.get_mcp_service(),
        Some(db_service.clone()),
        Some(app.clone()),
    );
    
    // åˆ›å»º AgentTask
    let task = AgentTask {
        id: execution_id.clone(),
        description: request.query.clone(),
        target: None,
        parameters: {
            let mut map = HashMap::new();
            map.insert("query".to_string(), serde_json::json!(request.query));
            map.insert("config".to_string(), config_json);
            
            // **å…³é”®ä¿®å¤**: å°† tools_allow å’Œ tools_deny ä» options é€ä¼ åˆ° task.parameters é¡¶å±‚
            // ReAct executor çš„ build_tools_information ä¼šä»è¿™é‡Œè¯»å–
            if let Some(tools_allow) = options.get("tools_allow") {
                log::info!("ReAct dispatch: é€ä¼  tools_allow åˆ° task.parameters");
                map.insert("tools_allow".to_string(), tools_allow.clone());
            }
            if let Some(tools_deny) = options.get("tools_deny") {
                log::info!("ReAct dispatch: é€ä¼  tools_deny åˆ° task.parameters");
                map.insert("tools_deny".to_string(), tools_deny.clone());
            }
            
            // æ·»åŠ  conversation_id å’Œ message_id åˆ° parametersï¼Œè®© ReAct å¼•æ“èƒ½å¤Ÿæå–
            if let Some(conv_id) = &request.conversation_id {
                map.insert("conversation_id".to_string(), serde_json::json!(conv_id));
            }
            if let Some(msg_id) = &request.message_id {
                map.insert("message_id".to_string(), serde_json::json!(msg_id));
            }
            map
        },
        user_id: "default".to_string(),
        priority: TaskPriority::Normal,
        timeout: Some(max_iterations as u64 * 30000), // 30s per iteration
    };
    
    // åˆ›å»º dummy session ç”¨äºæ‰§è¡Œ
    use crate::agents::traits::{AgentSession, AgentSessionStatus, LogLevel, AgentExecutionResult, SessionLog};
    struct DummySession {
        task: AgentTask,
        status: AgentSessionStatus,
        logs: Vec<SessionLog>,
        result: Option<AgentExecutionResult>,
    }
    
    #[async_trait::async_trait]
    impl AgentSession for DummySession {
        fn get_session_id(&self) -> &str { "dummy" }
        fn get_task(&self) -> &AgentTask { &self.task }
        fn get_status(&self) -> AgentSessionStatus { self.status.clone() }
        async fn update_status(&mut self, status: AgentSessionStatus) -> anyhow::Result<()> {
            self.status = status;
            Ok(())
        }
        async fn add_log(&mut self, level: LogLevel, message: String) -> anyhow::Result<()> {
            self.logs.push(SessionLog {
                level,
                message,
                timestamp: chrono::Utc::now(),
                source: "react".to_string(),
            });
            Ok(())
        }
        fn get_logs(&self) -> &[SessionLog] { &self.logs }
        async fn set_result(&mut self, result: AgentExecutionResult) -> anyhow::Result<()> {
            self.result = Some(result);
            Ok(())
        }
        fn get_result(&self) -> Option<&AgentExecutionResult> { self.result.as_ref() }
    }
    
    let mut session = DummySession {
        task,
        status: AgentSessionStatus::Executing,
        logs: Vec::new(),
        result: None,
    };
    
    // æ‰§è¡Œä»»åŠ¡ - å…ˆå…‹éš† task é¿å…å€Ÿç”¨å†²çª
    let task_clone = session.task.clone();
    let start_time = std::time::Instant::now();
    match engine.execute(&task_clone, &mut session).await {
        Ok(result) => {
            let duration_ms = start_time.elapsed().as_millis() as u64;
            // ä» result.data ä¸­æå–å“åº”æ–‡æœ¬
            let response = if let Some(data) = &result.data {
                data.as_str().unwrap_or("").to_string()
            } else {
                "ReAct execution completed".to_string()
            };
            
            Ok(DispatchResult {
                execution_id,
                initial_response: response,
                execution_plan: None,
                estimated_duration: duration_ms,
                selected_architecture: "ReAct".to_string(),
            })
        }
        Err(e) => Err(format!("ReAct execution failed: {}", e))
    }
}

async fn dispatch_with_rewoo(
    _execution_id: String,
    _request: DispatchQueryRequest,
    _ai_service_manager: Arc<AiServiceManager>,
    _db_service: Arc<DatabaseService>,
    _execution_manager: Arc<crate::managers::ExecutionManager>,
    _app: AppHandle,
) -> Result<DispatchResult, String> {
    // DISABLED: ReWOO engine needs Rig refactor
    Err("ReWOO engine disabled - needs Rig refactor".to_string())
}

async fn dispatch_with_llm_compiler(
    execution_id: String,
    request: DispatchQueryRequest,
    ai_service_manager: Arc<AiServiceManager>,
    db_service: Arc<DatabaseService>,
    execution_manager: Arc<crate::managers::ExecutionManager>,
    app: AppHandle,
) -> Result<DispatchResult, String> {
    // info!("Creating LLMCompiler dispatch for: {}", request.query);
    
    // åˆ›å»ºLLMCompilerå¼•æ“é…ç½®
    let config = LlmCompilerConfig::default();
    
    // åˆ›å»ºLLMCompilerå¼•æ“
    let mut engine = LlmCompilerEngine::new_with_dependencies(
        ai_service_manager.clone(),
        config,
        db_service.clone(),
    ).await.map_err(|e| format!("Failed to create LLMCompiler engine: {}", e))?;
    
    // âœ… è®¾ç½®app_handleç”¨äºæ¨é€å·¥å…·æ‰§è¡Œç»“æœåˆ°å‰ç«¯
    engine.set_app_handle(app.clone());
    
    // åˆ›å»ºAgentä»»åŠ¡
    let task = AgentTask {
        id: execution_id.clone(),
        user_id: "system".to_string(),
        description: request.query.clone(),
        priority: TaskPriority::High, // LLMCompileré€‚åˆé«˜ä¼˜å…ˆçº§ä»»åŠ¡
        target: None,
        parameters: request.options.unwrap_or_default(),
        timeout: Some(240), // 4åˆ†é’Ÿè¶…æ—¶
    };
    
    // âœ… æ³¨å…¥è¿è¡ŒæœŸå‚æ•°ï¼ŒåŒ…æ‹¬ç”¨æˆ·çš„ä»»åŠ¡æè¿°
    let mut runtime_params = task.parameters.clone();
    runtime_params.insert(
        "task_description".to_string(), 
        serde_json::Value::String(task.description.clone())
    );
    engine.set_runtime_params(runtime_params);
    
    // åˆ›å»ºæ‰§è¡Œè®¡åˆ’
    let plan = engine.create_plan(&task).await
        .map_err(|e| format!("Failed to create LLMCompiler plan: {}", e))?;
    
    // æ³¨å†Œæ‰§è¡Œä¸Šä¸‹æ–‡å’Œå¼•æ“å®ä¾‹åˆ°æ‰§è¡Œç®¡ç†å™¨
    let engine_instance = crate::managers::EngineInstance::LLMCompiler(engine);
    execution_manager.register_execution(
        execution_id.clone(),
        crate::managers::EngineType::LLMCompiler,
        plan.clone(),
        task,
        engine_instance,
    ).await.map_err(|e| format!("Failed to register execution: {}", e))?;
    
    let execution_plan = ExecutionPlanView {
        id: plan.id.clone(),
        name: plan.name.clone(),
        description: format!("LLMCompilerå¹¶è¡Œä»»åŠ¡: {}", request.query),
        steps: plan.steps.iter().map(|step| ExecutionStepView {
            id: step.id.clone(),
            name: step.name.clone(),
            description: step.description.clone(),
            status: "pending".to_string(),
            estimated_duration: 30, // LLMCompileræ­¥éª¤é€šå¸¸æ›´å¿«
        }).collect(),
        estimated_duration: plan.estimated_duration,
    };
    
    Ok(DispatchResult {
        execution_id,
        initial_response: "å·²å¯åŠ¨LLMCompilerå¹¶è¡Œæ‰§è¡Œå¼•æ“ï¼Œå¼•æ“å®ä¾‹å·²æ³¨å†Œï¼Œå‡†å¤‡çœŸå®æ‰§è¡Œ...".to_string(),
        execution_plan: Some(execution_plan),
        estimated_duration: plan.estimated_duration,
        selected_architecture: "LLMCompiler".to_string(),
    })
}
